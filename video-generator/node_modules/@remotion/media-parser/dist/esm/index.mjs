// src/errors.ts
class IsAGifError extends Error {
  mimeType;
  sizeInBytes;
  fileName;
  constructor({
    message,
    mimeType,
    sizeInBytes,
    fileName
  }) {
    super(message);
    this.fileName = "IsAGifError";
    this.mimeType = mimeType;
    this.sizeInBytes = sizeInBytes;
    this.fileName = fileName;
    if (Error.captureStackTrace) {
      Error.captureStackTrace(this, IsAGifError);
    }
  }
}

class IsAnImageError extends Error {
  imageType;
  dimensions;
  mimeType;
  sizeInBytes;
  fileName;
  constructor({
    dimensions,
    imageType,
    message,
    mimeType,
    sizeInBytes,
    fileName
  }) {
    super(message);
    this.name = "IsAnImageError";
    this.imageType = imageType;
    this.dimensions = dimensions;
    this.mimeType = mimeType;
    this.sizeInBytes = sizeInBytes;
    this.fileName = fileName;
    if (Error.captureStackTrace) {
      Error.captureStackTrace(this, IsAnImageError);
    }
  }
}

class IsAPdfError extends Error {
  mimeType;
  sizeInBytes;
  fileName;
  constructor({
    message,
    mimeType,
    sizeInBytes,
    fileName
  }) {
    super(message);
    this.name = "IsAPdfError";
    this.mimeType = mimeType;
    this.sizeInBytes = sizeInBytes;
    this.fileName = fileName;
    if (Error.captureStackTrace) {
      Error.captureStackTrace(this, IsAPdfError);
    }
  }
}

class IsAnUnsupportedFileTypeError extends Error {
  mimeType;
  sizeInBytes;
  fileName;
  constructor({
    message,
    mimeType,
    sizeInBytes,
    fileName
  }) {
    super(message);
    this.name = "IsAnUnsupportedFileTypeError";
    this.mimeType = mimeType;
    this.sizeInBytes = sizeInBytes;
    this.fileName = fileName;
    if (Error.captureStackTrace) {
      Error.captureStackTrace(this, IsAnUnsupportedFileTypeError);
    }
  }
}

class IsAnUnsupportedAudioTypeError extends Error {
  mimeType;
  sizeInBytes;
  fileName;
  audioType;
  constructor({
    message,
    mimeType,
    sizeInBytes,
    fileName,
    audioType
  }) {
    super(message);
    this.name = "IsAnUnsupportedAudioTypeError";
    this.mimeType = mimeType;
    this.sizeInBytes = sizeInBytes;
    this.fileName = fileName;
    this.audioType = audioType;
    if (Error.captureStackTrace) {
      Error.captureStackTrace(this, IsAnUnsupportedAudioTypeError);
    }
  }
}

class MediaParserAbortError extends Error {
  constructor(message) {
    super(message);
    this.name = "MediaParserAbortError";
    this.cause = undefined;
  }
}
var hasBeenAborted = (error) => {
  return error instanceof MediaParserAbortError;
};

// src/readers/from-fetch.ts
function parseContentRange(input) {
  const matches = input.match(/^(\w+) ((\d+)-(\d+)|\*)\/(\d+|\*)$/);
  if (!matches)
    return null;
  const [, unit, , start, end, size] = matches;
  const range = {
    unit,
    start: start != null ? Number(start) : null,
    end: end != null ? Number(end) : null,
    size: size === "*" ? null : Number(size)
  };
  if (range.start === null && range.end === null && range.size === null) {
    return null;
  }
  return range;
}
var validateContentRangeAndDetectIfSupported = (actualRange, parsedContentRange, statusCode) => {
  if (statusCode === 206) {
    return { supportsContentRange: true };
  }
  if (typeof actualRange === "number" && parsedContentRange?.start !== actualRange) {
    if (actualRange === 0) {
      return { supportsContentRange: false };
    }
    throw new Error(`Range header (${actualRange}) does not match content-range header (${parsedContentRange?.start})`);
  }
  if (actualRange !== null && typeof actualRange !== "number" && (parsedContentRange?.start !== actualRange[0] || parsedContentRange?.end !== actualRange[1])) {
    throw new Error(`Range header (${actualRange}) does not match content-range header (${parsedContentRange?.start})`);
  }
  return { supportsContentRange: true };
};
var fetchReader = {
  read: async ({ src, range, controller }) => {
    if (typeof src !== "string") {
      throw new Error("src must be a string when using `fetchReader`");
    }
    const resolvedUrl = typeof window !== "undefined" && typeof window.location !== "undefined" ? new URL(src, window.location.origin).toString() : src;
    if (!resolvedUrl.startsWith("https://") && !resolvedUrl.startsWith("blob:") && !resolvedUrl.startsWith("http://")) {
      return Promise.reject(new Error(resolvedUrl + " is not a URL - needs to start with http:// or https:// or blob:. If you want to read a local file, pass `reader: nodeReader` to parseMedia()."));
    }
    const ownController = new AbortController;
    const cache = typeof navigator !== "undefined" && navigator.userAgent.includes("Cloudflare-Workers") ? undefined : "no-store";
    const actualRange = range === null ? 0 : range;
    const res = await fetch(resolvedUrl, {
      headers: typeof actualRange === "number" ? {
        Range: `bytes=${actualRange}-`
      } : {
        Range: `bytes=${`${actualRange[0]}-${actualRange[1]}`}`
      },
      signal: ownController.signal,
      cache
    });
    const contentRange = res.headers.get("content-range");
    const parsedContentRange = contentRange ? parseContentRange(contentRange) : null;
    const { supportsContentRange } = validateContentRangeAndDetectIfSupported(actualRange, parsedContentRange, res.status);
    controller._internals.signal.addEventListener("abort", () => {
      ownController.abort(new MediaParserAbortError("Aborted by user"));
    }, { once: true });
    if (res.status.toString().startsWith("4") || res.status.toString().startsWith("5")) {
      throw new Error(`Server returned status code ${res.status} for ${src} and range ${actualRange}`);
    }
    if (!res.body) {
      throw new Error("No body");
    }
    const length = res.headers.get("content-length");
    const contentLength = length === null ? null : parseInt(length, 10);
    const contentDisposition = res.headers.get("content-disposition");
    const name = contentDisposition?.match(/filename="([^"]+)"/)?.[1];
    const fallbackName = src.split("/").pop();
    const reader = res.body.getReader();
    if (controller) {
      controller._internals.signal.addEventListener("abort", () => {
        reader.cancel().catch(() => {
        });
      }, { once: true });
    }
    return {
      reader: {
        reader,
        abort: () => {
          ownController.abort();
        }
      },
      contentLength,
      contentType: res.headers.get("content-type"),
      name: name ?? fallbackName,
      supportsContentRange
    };
  },
  getLength: async (src) => {
    if (typeof src !== "string") {
      throw new Error("src must be a string when using `fetchReader`");
    }
    const res = await fetch(src, {
      method: "HEAD"
    });
    if (!res.body) {
      throw new Error("No body");
    }
    const length = res.headers.get("content-length");
    if (!length) {
      throw new Error("No content-length");
    }
    return parseInt(length, 10);
  }
};

// src/aac-codecprivate.ts
var getSampleRateFromSampleFrequencyIndex = (samplingFrequencyIndex) => {
  switch (samplingFrequencyIndex) {
    case 0:
      return 96000;
    case 1:
      return 88200;
    case 2:
      return 64000;
    case 3:
      return 48000;
    case 4:
      return 44100;
    case 5:
      return 32000;
    case 6:
      return 24000;
    case 7:
      return 22050;
    case 8:
      return 16000;
    case 9:
      return 12000;
    case 10:
      return 11025;
    case 11:
      return 8000;
    case 12:
      return 7350;
    default:
      throw new Error(`Unexpected sampling frequency index ${samplingFrequencyIndex}`);
  }
};
var getConfigForSampleRate = (sampleRate) => {
  if (sampleRate === 96000) {
    return 0;
  }
  if (sampleRate === 88200) {
    return 1;
  }
  if (sampleRate === 64000) {
    return 2;
  }
  if (sampleRate === 48000) {
    return 3;
  }
  if (sampleRate === 44100) {
    return 4;
  }
  if (sampleRate === 32000) {
    return 5;
  }
  if (sampleRate === 24000) {
    return 6;
  }
  if (sampleRate === 22050) {
    return 7;
  }
  if (sampleRate === 16000) {
    return 8;
  }
  if (sampleRate === 12000) {
    return 9;
  }
  if (sampleRate === 11025) {
    return 10;
  }
  if (sampleRate === 8000) {
    return 11;
  }
  if (sampleRate === 7350) {
    return 12;
  }
  throw new Error(`Unexpected sample rate ${sampleRate}`);
};
var createAacCodecPrivate = ({
  audioObjectType,
  sampleRate,
  channelConfiguration,
  codecPrivate
}) => {
  if (codecPrivate !== null && codecPrivate.length > 2) {
    return codecPrivate;
  }
  const bits = `${audioObjectType.toString(2).padStart(5, "0")}${getConfigForSampleRate(sampleRate).toString(2).padStart(4, "0")}${channelConfiguration.toString(2).padStart(4, "0")}000`;
  if (bits.length !== 16) {
    throw new Error("Invalid AAC codec private " + bits.length);
  }
  if (channelConfiguration === 0 || channelConfiguration > 7) {
    throw new Error("Invalid channel configuration " + channelConfiguration);
  }
  const firstByte = parseInt(bits.slice(0, 8), 2);
  const secondByte = parseInt(bits.slice(8, 16), 2);
  return new Uint8Array([firstByte, secondByte]);
};
var parseAacCodecPrivate = (bytes) => {
  if (bytes.length < 2) {
    throw new Error("Invalid AAC codec private length");
  }
  const bits = [...bytes].map((b) => b.toString(2).padStart(8, "0")).join("");
  let offset = 0;
  const audioObjectType = parseInt(bits.slice(offset, offset + 5), 2);
  offset += 5;
  const samplingFrequencyIndex = parseInt(bits.slice(offset, offset + 4), 2);
  offset += 4;
  if (samplingFrequencyIndex === 15) {
    offset += 24;
  }
  const channelConfiguration = parseInt(bits.slice(offset, offset + 4), 2);
  offset += 4;
  if (audioObjectType === 5) {
    const extensionSamplingFrequencyIndex = parseInt(bits.slice(offset, offset + 4), 2);
    offset += 4;
    const newAudioObjectType = parseInt(bits.slice(offset, offset + 5), 2);
    offset += 5;
    return {
      audioObjectType: newAudioObjectType,
      sampleRate: getSampleRateFromSampleFrequencyIndex(extensionSamplingFrequencyIndex),
      channelConfiguration
    };
  }
  const sampleRate = getSampleRateFromSampleFrequencyIndex(samplingFrequencyIndex);
  return {
    audioObjectType,
    sampleRate,
    channelConfiguration
  };
};
var mapAudioObjectTypeToCodecString = (audioObjectType) => {
  switch (audioObjectType) {
    case 1:
      return "mp4a.40.2";
    case 2:
      return "mp4a.40.5";
    case 3:
      return "mp4a.40.29";
    case 4:
      return "mp4a.40.1";
    case 5:
      return "mp4a.40.3";
    case 6:
      return "mp4a.40.4";
    case 17:
      return "mp4a.40.17";
    case 23:
      return "mp4a.40.23";
    default:
      throw new Error(`Unexpected audio object type ${audioObjectType}`);
  }
};

// src/containers/webm/segments/all-segments.ts
var matroskaElements = {
  Header: "0x1a45dfa3",
  EBMLMaxIDLength: "0x42f2",
  EBMLVersion: "0x4286",
  EBMLReadVersion: "0x42f7",
  EBMLMaxSizeLength: "0x42f3",
  DocType: "0x4282",
  DocTypeVersion: "0x4287",
  DocTypeReadVersion: "0x4285",
  Segment: "0x18538067",
  SeekHead: "0x114d9b74",
  Seek: "0x4dbb",
  SeekID: "0x53ab",
  SeekPosition: "0x53ac",
  Info: "0x1549a966",
  SegmentUUID: "0x73a4",
  SegmentFilename: "0x7384",
  PrevUUID: "0x3cb923",
  PrevFilename: "0x3c83ab",
  NextUUID: "0x3eb923",
  NextFilename: "0x3e83bb",
  SegmentFamily: "0x4444",
  ChapterTranslate: "0x6924",
  ChapterTranslateID: "0x69a5",
  ChapterTranslateCodec: "0x69bf",
  ChapterTranslateEditionUID: "0x69fc",
  TimestampScale: "0x2ad7b1",
  Duration: "0x4489",
  DateUTC: "0x4461",
  Title: "0x7ba9",
  MuxingApp: "0x4d80",
  WritingApp: "0x5741",
  Cluster: "0x1f43b675",
  Timestamp: "0xe7",
  SilentTracks: "0x5854",
  SilentTrackNumber: "0x58d7",
  Position: "0xa7",
  PrevSize: "0xab",
  SimpleBlock: "0xa3",
  BlockGroup: "0xa0",
  Block: "0xa1",
  BlockVirtual: "0xa2",
  BlockAdditions: "0x75a1",
  BlockMore: "0xa6",
  BlockAdditional: "0xa5",
  BlockAddID: "0xee",
  BlockDuration: "0x9b",
  ReferencePriority: "0xfa",
  ReferenceBlock: "0xfb",
  ReferenceVirtual: "0xfd",
  CodecState: "0xa4",
  DiscardPadding: "0x75a2",
  Slices: "0x8e",
  TimeSlice: "0xe8",
  LaceNumber: "0xcc",
  FrameNumber: "0xcd",
  BlockAdditionID: "0xcb",
  Delay: "0xce",
  SliceDuration: "0xcf",
  ReferenceFrame: "0xc8",
  ReferenceOffset: "0xc9",
  ReferenceTimestamp: "0xca",
  EncryptedBlock: "0xaf",
  Tracks: "0x1654ae6b",
  TrackEntry: "0xae",
  TrackNumber: "0xd7",
  TrackUID: "0x73c5",
  TrackType: "0x83",
  FlagEnabled: "0xb9",
  FlagDefault: "0x88",
  FlagForced: "0x55aa",
  FlagHearingImpaired: "0x55ab",
  FlagVisualImpaired: "0x55ac",
  FlagTextDescriptions: "0x55ad",
  FlagOriginal: "0x55ae",
  FlagCommentary: "0x55af",
  FlagLacing: "0x9c",
  MinCache: "0x6de7",
  MaxCache: "0x6df8",
  DefaultDuration: "0x23e383",
  DefaultDecodedFieldDuration: "0x234e7a",
  TrackTimestampScale: "0x23314f",
  TrackOffset: "0x537f",
  MaxBlockAdditionID: "0x55ee",
  BlockAdditionMapping: "0x41e4",
  BlockAddIDValue: "0x41f0",
  BlockAddIDName: "0x41a4",
  BlockAddIDType: "0x41e7",
  BlockAddIDExtraData: "0x41ed",
  Name: "0x536e",
  Language: "0x22b59c",
  LanguageBCP47: "0x22b59d",
  CodecID: "0x86",
  CodecPrivate: "0x63a2",
  CodecName: "0x258688",
  AttachmentLink: "0x7446",
  CodecSettings: "0x3a9697",
  CodecInfoURL: "0x3b4040",
  CodecDownloadURL: "0x26b240",
  CodecDecodeAll: "0xaa",
  TrackOverlay: "0x6fab",
  CodecDelay: "0x56aa",
  SeekPreRoll: "0x56bb",
  TrackTranslate: "0x6624",
  TrackTranslateTrackID: "0x66a5",
  TrackTranslateCodec: "0x66bf",
  TrackTranslateEditionUID: "0x66fc",
  Video: "0xe0",
  FlagInterlaced: "0x9a",
  FieldOrder: "0x9d",
  StereoMode: "0x53b8",
  AlphaMode: "0x53c0",
  OldStereoMode: "0x53b9",
  PixelWidth: "0xb0",
  PixelHeight: "0xba",
  PixelCropBottom: "0x54aa",
  PixelCropTop: "0x54bb",
  PixelCropLeft: "0x54cc",
  PixelCropRight: "0x54dd",
  DisplayWidth: "0x54b0",
  DisplayHeight: "0x54ba",
  DisplayUnit: "0x54b2",
  AspectRatioType: "0x54b3",
  UncompressedFourCC: "0x2eb524",
  GammaValue: "0x2fb523",
  FrameRate: "0x2383e3",
  Colour: "0x55b0",
  MatrixCoefficients: "0x55b1",
  BitsPerChannel: "0x55b2",
  ChromaSubsamplingHorz: "0x55b3",
  ChromaSubsamplingVert: "0x55b4",
  CbSubsamplingHorz: "0x55b5",
  CbSubsamplingVert: "0x55b6",
  ChromaSitingHorz: "0x55b7",
  ChromaSitingVert: "0x55b8",
  Range: "0x55b9",
  TransferCharacteristics: "0x55ba",
  Primaries: "0x55bb",
  MaxCLL: "0x55bc",
  MaxFALL: "0x55bd",
  MasteringMetadata: "0x55d0",
  PrimaryRChromaticityX: "0x55d1",
  PrimaryRChromaticityY: "0x55d2",
  PrimaryGChromaticityX: "0x55d3",
  PrimaryGChromaticityY: "0x55d4",
  PrimaryBChromaticityX: "0x55d5",
  PrimaryBChromaticityY: "0x55d6",
  WhitePointChromaticityX: "0x55d7",
  WhitePointChromaticityY: "0x55d8",
  LuminanceMax: "0x55d9",
  LuminanceMin: "0x55da",
  Projection: "0x7670",
  ProjectionType: "0x7671",
  ProjectionPrivate: "0x7672",
  ProjectionPoseYaw: "0x7673",
  ProjectionPosePitch: "0x7674",
  ProjectionPoseRoll: "0x7675",
  Audio: "0xe1",
  SamplingFrequency: "0xb5",
  OutputSamplingFrequency: "0x78b5",
  Channels: "0x9f",
  ChannelPositions: "0x7d7b",
  BitDepth: "0x6264",
  Emphasis: "0x52f1",
  TrackOperation: "0xe2",
  TrackCombinePlanes: "0xe3",
  TrackPlane: "0xe4",
  TrackPlaneUID: "0xe5",
  TrackPlaneType: "0xe6",
  TrackJoinBlocks: "0xe9",
  TrackJoinUID: "0xed",
  TrickTrackUID: "0xc0",
  TrickTrackSegmentUID: "0xc1",
  TrickTrackFlag: "0xc6",
  TrickMasterTrackUID: "0xc7",
  TrickMasterTrackSegmentUID: "0xc4",
  ContentEncodings: "0x6d80",
  ContentEncoding: "0x6240",
  ContentEncodingOrder: "0x5031",
  ContentEncodingScope: "0x5032",
  ContentEncodingType: "0x5033",
  ContentCompression: "0x5034",
  ContentCompAlgo: "0x4254",
  ContentCompSettings: "0x4255",
  ContentEncryption: "0x5035",
  ContentEncAlgo: "0x47e1",
  ContentEncKeyID: "0x47e2",
  ContentEncAESSettings: "0x47e7",
  AESSettingsCipherMode: "0x47e8",
  ContentSignature: "0x47e3",
  ContentSigKeyID: "0x47e4",
  ContentSigAlgo: "0x47e5",
  ContentSigHashAlgo: "0x47e6",
  Cues: "0x1c53bb6b",
  CuePoint: "0xbb",
  CueTime: "0xb3",
  CueTrackPositions: "0xb7",
  CueTrack: "0xf7",
  CueClusterPosition: "0xf1",
  CueRelativePosition: "0xf0",
  CueDuration: "0xb2",
  CueBlockNumber: "0x5378",
  CueCodecState: "0xea",
  CueReference: "0xdb",
  CueRefTime: "0x96",
  CueRefCluster: "0x97",
  CueRefNumber: "0x535f",
  CueRefCodecState: "0xeb",
  Attachments: "0x1941a469",
  AttachedFile: "0x61a7",
  FileDescription: "0x467e",
  FileName: "0x466e",
  FileMediaType: "0x4660",
  FileData: "0x465c",
  FileUID: "0x46ae",
  FileReferral: "0x4675",
  FileUsedStartTime: "0x4661",
  FileUsedEndTime: "0x4662",
  Chapters: "0x1043a770",
  EditionEntry: "0x45b9",
  EditionUID: "0x45bc",
  EditionFlagHidden: "0x45bd",
  EditionFlagDefault: "0x45db",
  EditionFlagOrdered: "0x45dd",
  EditionDisplay: "0x4520",
  EditionString: "0x4521",
  EditionLanguageIETF: "0x45e4",
  ChapterAtom: "0xb6",
  ChapterUID: "0x73c4",
  ChapterStringUID: "0x5654",
  ChapterTimeStart: "0x91",
  ChapterTimeEnd: "0x92",
  ChapterFlagHidden: "0x98",
  ChapterFlagEnabled: "0x4598",
  ChapterSegmentUUID: "0x6e67",
  ChapterSkipType: "0x4588",
  ChapterSegmentEditionUID: "0x6ebc",
  ChapterPhysicalEquiv: "0x63c3",
  ChapterTrack: "0x8f",
  ChapterTrackUID: "0x89",
  ChapterDisplay: "0x80",
  ChapString: "0x85",
  ChapLanguage: "0x437c",
  ChapLanguageBCP47: "0x437d",
  ChapCountry: "0x437e",
  ChapProcess: "0x6944",
  ChapProcessCodecID: "0x6955",
  ChapProcessPrivate: "0x450d",
  ChapProcessCommand: "0x6911",
  ChapProcessTime: "0x6922",
  ChapProcessData: "0x6933",
  Tags: "0x1254c367",
  Tag: "0x7373",
  Targets: "0x63c0",
  TargetTypeValue: "0x68ca",
  TargetType: "0x63ca",
  TagTrackUID: "0x63c5",
  TagEditionUID: "0x63c9",
  TagChapterUID: "0x63c4",
  TagAttachmentUID: "0x63c6",
  SimpleTag: "0x67c8",
  TagName: "0x45a3",
  TagLanguage: "0x447a",
  TagLanguageBCP47: "0x447b",
  TagDefault: "0x4484",
  TagDefaultBogus: "0x44b4",
  TagString: "0x4487",
  TagBinary: "0x4485",
  Void: "0xec",
  Crc32: "0xbf"
};
var matroskaIds = Object.values(matroskaElements);
var knownIdsWithOneLength = matroskaIds.filter((id) => id.length === 4);
var knownIdsWithTwoLength = matroskaIds.filter((id) => id.length === 6);
var knownIdsWithThreeLength = matroskaIds.filter((id) => id.length === 8);
var ebmlVersion = {
  name: "EBMLVersion",
  type: "uint"
};
var ebmlReadVersion = {
  name: "EBMLReadVersion",
  type: "uint"
};
var ebmlMaxIdLength = {
  name: "EBMLMaxIDLength",
  type: "uint"
};
var ebmlMaxSizeLength = {
  name: "EBMLMaxSizeLength",
  type: "uint"
};
var docType = {
  name: "DocType",
  type: "string"
};
var docTypeVersion = {
  name: "DocTypeVersion",
  type: "uint"
};
var docTypeReadVersion = {
  name: "DocTypeReadVersion",
  type: "uint"
};
var voidEbml = {
  name: "Void",
  type: "uint8array"
};
var matroskaHeader = {
  name: "Header",
  type: "children"
};
var seekId = {
  name: "SeekID",
  type: "hex-string"
};
var _name = {
  name: "Name",
  type: "string"
};
var minCache = {
  name: "MinCache",
  type: "uint"
};
var maxCache = {
  name: "MaxCache",
  type: "uint"
};
var seekPosition = {
  name: "SeekPosition",
  type: "uint"
};
var seek = {
  name: "Seek",
  type: "children"
};
var seekHead = {
  name: "SeekHead",
  type: "children"
};
var trackType = {
  name: "TrackType",
  type: "uint"
};
var widthType = {
  name: "PixelWidth",
  type: "uint"
};
var heightType = {
  name: "PixelHeight",
  type: "uint"
};
var muxingApp = {
  name: "MuxingApp",
  type: "string"
};
var duration = {
  name: "Duration",
  type: "float"
};
var timestampScale = {
  name: "TimestampScale",
  type: "uint"
};
var infoType = {
  name: "Info",
  type: "children"
};
var titleType = {
  name: "Title",
  type: "string"
};
var tagTrackUidType = {
  name: "TagTrackUID",
  type: "hex-string"
};
var samplingFrequency = {
  name: "SamplingFrequency",
  type: "float"
};
var channels = {
  name: "Channels",
  type: "uint"
};
var alphaMode = {
  name: "AlphaMode",
  type: "uint"
};
var interlaced = {
  name: "FlagInterlaced",
  type: "uint"
};
var bitDepth = {
  name: "BitDepth",
  type: "uint"
};
var displayWidth = {
  name: "DisplayWidth",
  type: "uint"
};
var displayHeight = {
  name: "DisplayHeight",
  type: "uint"
};
var displayUnit = {
  name: "DisplayUnit",
  type: "uint"
};
var flagLacing = {
  name: "FlagLacing",
  type: "uint"
};
var tagSegment = {
  name: "Tag",
  type: "children"
};
var tags = {
  name: "Tags",
  type: "children"
};
var trackNumber = {
  name: "TrackNumber",
  type: "uint"
};
var trackUID = {
  name: "TrackUID",
  type: "hex-string"
};
var color = {
  name: "Colour",
  type: "children"
};
var transferCharacteristics = {
  name: "TransferCharacteristics",
  type: "uint"
};
var matrixCoefficients = {
  name: "MatrixCoefficients",
  type: "uint"
};
var primaries = {
  name: "Primaries",
  type: "uint"
};
var range = {
  name: "Range",
  type: "uint"
};
var ChromaSitingHorz = {
  name: "ChromaSitingHorz",
  type: "uint"
};
var ChromaSitingVert = {
  name: "ChromaSitingVert",
  type: "uint"
};
var language = {
  name: "Language",
  type: "string"
};
var defaultDuration = {
  name: "DefaultDuration",
  type: "uint"
};
var codecPrivate = {
  name: "CodecPrivate",
  type: "uint8array"
};
var blockAdditionsSegment = {
  name: "BlockAdditions",
  type: "uint8array"
};
var maxBlockAdditionIdSegment = {
  name: "MaxBlockAdditionID",
  type: "uint"
};
var audioSegment = {
  name: "Audio",
  type: "children"
};
var videoSegment = {
  name: "Video",
  type: "children"
};
var flagDefault = {
  name: "FlagDefault",
  type: "uint"
};
var referenceBlock = {
  name: "ReferenceBlock",
  type: "uint"
};
var blockDurationSegment = {
  name: "BlockDuration",
  type: "uint"
};
var codecName = {
  name: "CodecName",
  type: "string"
};
var trackTimestampScale = {
  name: "TrackTimestampScale",
  type: "float"
};
var trackEntry = {
  name: "TrackEntry",
  type: "children"
};
var tracks = {
  name: "Tracks",
  type: "children"
};
var block = {
  name: "Block",
  type: "uint8array"
};
var simpleBlock = {
  name: "SimpleBlock",
  type: "uint8array"
};
var blockGroup = {
  name: "BlockGroup",
  type: "children"
};
var targetsType = {
  name: "Targets",
  type: "children"
};
var simpleTagType = {
  name: "SimpleTag",
  type: "children"
};
var tagNameType = {
  name: "TagName",
  type: "string"
};
var tagStringType = {
  name: "TagString",
  type: "string"
};
var ebmlMap = {
  [matroskaElements.Header]: matroskaHeader,
  [matroskaElements.DocType]: docType,
  [matroskaElements.Targets]: targetsType,
  [matroskaElements.SimpleTag]: simpleTagType,
  [matroskaElements.TagName]: tagNameType,
  [matroskaElements.TagString]: tagStringType,
  [matroskaElements.DocTypeVersion]: docTypeVersion,
  [matroskaElements.DocTypeReadVersion]: docTypeReadVersion,
  [matroskaElements.EBMLVersion]: ebmlVersion,
  [matroskaElements.EBMLReadVersion]: ebmlReadVersion,
  [matroskaElements.EBMLMaxIDLength]: ebmlMaxIdLength,
  [matroskaElements.EBMLMaxSizeLength]: ebmlMaxSizeLength,
  [matroskaElements.Void]: voidEbml,
  [matroskaElements.Cues]: {
    name: "Cues",
    type: "children"
  },
  [matroskaElements.CuePoint]: {
    name: "CuePoint",
    type: "children"
  },
  [matroskaElements.CueTime]: {
    name: "CueTime",
    type: "uint"
  },
  [matroskaElements.CueTrackPositions]: {
    name: "CueTrackPositions",
    type: "children"
  },
  [matroskaElements.CueClusterPosition]: {
    name: "CueClusterPosition",
    type: "uint"
  },
  [matroskaElements.CueRelativePosition]: {
    name: "CueRelativePosition",
    type: "uint"
  },
  [matroskaElements.CueBlockNumber]: {
    name: "CueBlockNumber",
    type: "uint"
  },
  [matroskaElements.CueTrack]: {
    name: "CueTrack",
    type: "uint"
  },
  [matroskaElements.DateUTC]: {
    name: "DateUTC",
    type: "uint8array"
  },
  [matroskaElements.TrackTimestampScale]: trackTimestampScale,
  [matroskaElements.CodecDelay]: {
    name: "CodecDelay",
    type: "uint8array"
  },
  [matroskaElements.SeekPreRoll]: {
    name: "SeekPreRoll",
    type: "uint8array"
  },
  [matroskaElements.DiscardPadding]: {
    name: "DiscardPadding",
    type: "uint8array"
  },
  [matroskaElements.OutputSamplingFrequency]: {
    name: "OutputSamplingFrequency",
    type: "uint8array"
  },
  [matroskaElements.CodecName]: codecName,
  [matroskaElements.Position]: {
    name: "Position",
    type: "uint8array"
  },
  [matroskaElements.SliceDuration]: {
    name: "SliceDuration",
    type: "uint8array"
  },
  [matroskaElements.TagTrackUID]: tagTrackUidType,
  [matroskaElements.SeekHead]: seekHead,
  [matroskaElements.Seek]: seek,
  [matroskaElements.SeekID]: seekId,
  [matroskaElements.Name]: _name,
  [matroskaElements.MinCache]: minCache,
  [matroskaElements.MaxCache]: maxCache,
  [matroskaElements.SeekPosition]: seekPosition,
  [matroskaElements.Crc32]: {
    name: "Crc32",
    type: "uint8array"
  },
  [matroskaElements.MuxingApp]: muxingApp,
  [matroskaElements.WritingApp]: {
    name: "WritingApp",
    type: "string"
  },
  [matroskaElements.SegmentUUID]: {
    name: "SegmentUUID",
    type: "string"
  },
  [matroskaElements.Duration]: duration,
  [matroskaElements.CodecID]: {
    name: "CodecID",
    type: "string"
  },
  [matroskaElements.TrackType]: trackType,
  [matroskaElements.PixelWidth]: widthType,
  [matroskaElements.PixelHeight]: heightType,
  [matroskaElements.TimestampScale]: timestampScale,
  [matroskaElements.Info]: infoType,
  [matroskaElements.Title]: titleType,
  [matroskaElements.SamplingFrequency]: samplingFrequency,
  [matroskaElements.Channels]: channels,
  [matroskaElements.AlphaMode]: alphaMode,
  [matroskaElements.FlagInterlaced]: interlaced,
  [matroskaElements.BitDepth]: bitDepth,
  [matroskaElements.DisplayHeight]: displayHeight,
  [matroskaElements.DisplayWidth]: displayWidth,
  [matroskaElements.DisplayUnit]: displayUnit,
  [matroskaElements.FlagLacing]: flagLacing,
  [matroskaElements.Tags]: tags,
  [matroskaElements.Tag]: tagSegment,
  [matroskaElements.TrackNumber]: trackNumber,
  [matroskaElements.TrackUID]: trackUID,
  [matroskaElements.Colour]: color,
  [matroskaElements.Language]: language,
  [matroskaElements.DefaultDuration]: defaultDuration,
  [matroskaElements.CodecPrivate]: codecPrivate,
  [matroskaElements.BlockDuration]: blockDurationSegment,
  [matroskaElements.BlockAdditions]: blockAdditionsSegment,
  [matroskaElements.MaxBlockAdditionID]: maxBlockAdditionIdSegment,
  [matroskaElements.Audio]: audioSegment,
  [matroskaElements.Video]: videoSegment,
  [matroskaElements.FlagDefault]: flagDefault,
  [matroskaElements.ReferenceBlock]: referenceBlock,
  [matroskaElements.TrackEntry]: trackEntry,
  [matroskaElements.Timestamp]: {
    name: "Timestamp",
    type: "uint"
  },
  [matroskaElements.Tracks]: tracks,
  [matroskaElements.Block]: block,
  [matroskaElements.SimpleBlock]: simpleBlock,
  [matroskaElements.BlockGroup]: blockGroup,
  [matroskaElements.Segment]: {
    name: "Segment",
    type: "children"
  },
  [matroskaElements.Cluster]: {
    name: "Cluster",
    type: "children"
  },
  [matroskaElements.TransferCharacteristics]: transferCharacteristics,
  [matroskaElements.MatrixCoefficients]: matrixCoefficients,
  [matroskaElements.Primaries]: primaries,
  [matroskaElements.Range]: range,
  [matroskaElements.ChromaSitingHorz]: ChromaSitingHorz,
  [matroskaElements.ChromaSitingVert]: ChromaSitingVert
};

// src/file-types/detect-file-type.ts
var webmPattern = new Uint8Array([26, 69, 223, 163]);
var matchesPattern = (pattern) => {
  return (data) => {
    return pattern.every((value, index) => data[index] === value);
  };
};
var isRiffAvi = (data) => {
  const riffPattern = new Uint8Array([82, 73, 70, 70]);
  if (!matchesPattern(riffPattern)(data.subarray(0, 4))) {
    return false;
  }
  const fileType = data.subarray(8, 12);
  const aviPattern = new Uint8Array([65, 86, 73, 32]);
  return matchesPattern(aviPattern)(fileType);
};
var isRiffWave = (data) => {
  const riffPattern = new Uint8Array([82, 73, 70, 70]);
  if (!matchesPattern(riffPattern)(data.subarray(0, 4))) {
    return false;
  }
  const fileType = data.subarray(8, 12);
  const wavePattern = new Uint8Array([87, 65, 86, 69]);
  return matchesPattern(wavePattern)(fileType);
};
var isWebm = (data) => {
  return matchesPattern(webmPattern)(data.subarray(0, 4));
};
var isIsoBaseMedia = (data) => {
  const isoBaseMediaMp4Pattern = new TextEncoder().encode("ftyp");
  return matchesPattern(isoBaseMediaMp4Pattern)(data.subarray(4, 8));
};
var isTransportStream = (data) => {
  return data[0] === 71 && data[188] === 71;
};
var isMp3 = (data) => {
  const mpegPattern = new Uint8Array([255, 243, 228, 100]);
  const id3v4Pattern = new Uint8Array([73, 68, 51, 4]);
  const id3v3Pattern = new Uint8Array([73, 68, 51, 3]);
  const id3v2Pattern = new Uint8Array([73, 68, 51, 2]);
  const subarray = data.subarray(0, 4);
  return matchesPattern(mpegPattern)(subarray) || matchesPattern(id3v4Pattern)(subarray) || matchesPattern(id3v3Pattern)(subarray) || matchesPattern(id3v2Pattern)(subarray);
};
var isGif = (data) => {
  const gifPattern = new Uint8Array([71, 73, 70, 56]);
  return matchesPattern(gifPattern)(data.subarray(0, 4));
};
var isAac = (data) => {
  const aacPattern = new Uint8Array([255, 241]);
  return matchesPattern(aacPattern)(data.subarray(0, 2));
};
var isFlac = (data) => {
  const flacPattern = new Uint8Array([102, 76, 97, 67]);
  return matchesPattern(flacPattern)(data.subarray(0, 4));
};

// src/file-types/bmp.ts
function getBmpDimensions(bmpData) {
  if (bmpData.length < 26) {
    return null;
  }
  const view = new DataView(bmpData.buffer, bmpData.byteOffset);
  return {
    width: view.getUint32(18, true),
    height: Math.abs(view.getInt32(22, true))
  };
}
var isBmp = (data) => {
  const bmpPattern = new Uint8Array([66, 77]);
  if (matchesPattern(bmpPattern)(data.subarray(0, 2))) {
    const bmp = getBmpDimensions(data);
    return { dimensions: bmp, type: "bmp" };
  }
  return null;
};

// src/file-types/jpeg.ts
function getJpegDimensions(data) {
  let offset = 0;
  function readUint16BE(o) {
    return data[o] << 8 | data[o + 1];
  }
  if (readUint16BE(offset) !== 65496) {
    return null;
  }
  offset += 2;
  while (offset < data.length) {
    if (data[offset] === 255) {
      const marker = data[offset + 1];
      if (marker === 192 || marker === 194) {
        const height = readUint16BE(offset + 5);
        const width = readUint16BE(offset + 7);
        return { width, height };
      }
      const length = readUint16BE(offset + 2);
      offset += length + 2;
    } else {
      offset++;
    }
  }
  return null;
}
var isJpeg = (data) => {
  const jpegPattern = new Uint8Array([255, 216]);
  const jpeg = matchesPattern(jpegPattern)(data.subarray(0, 2));
  if (!jpeg) {
    return null;
  }
  const dim = getJpegDimensions(data);
  return { dimensions: dim, type: "jpeg" };
};

// src/file-types/pdf.ts
var isPdf = (data) => {
  if (data.length < 4) {
    return null;
  }
  const pdfPattern = new Uint8Array([37, 80, 68, 70]);
  return matchesPattern(pdfPattern)(data.subarray(0, 4)) ? { type: "pdf" } : null;
};

// src/file-types/png.ts
function getPngDimensions(pngData) {
  if (pngData.length < 24) {
    return null;
  }
  const view = new DataView(pngData.buffer, pngData.byteOffset);
  const pngSignature = [137, 80, 78, 71, 13, 10, 26, 10];
  for (let i = 0;i < 8; i++) {
    if (pngData[i] !== pngSignature[i]) {
      return null;
    }
  }
  return {
    width: view.getUint32(16, false),
    height: view.getUint32(20, false)
  };
}
var isPng = (data) => {
  const pngPattern = new Uint8Array([137, 80, 78, 71]);
  if (matchesPattern(pngPattern)(data.subarray(0, 4))) {
    const png = getPngDimensions(data);
    return { dimensions: png, type: "png" };
  }
  return null;
};

// src/file-types/webp.ts
function getWebPDimensions(bytes) {
  if (bytes.length < 30) {
    return null;
  }
  if (bytes[0] !== 82 || bytes[1] !== 73 || bytes[2] !== 70 || bytes[3] !== 70 || bytes[8] !== 87 || bytes[9] !== 69 || bytes[10] !== 66 || bytes[11] !== 80) {
    return null;
  }
  if (bytes[12] === 86 && bytes[13] === 80 && bytes[14] === 56) {
    if (bytes[15] === 32) {
      return {
        width: bytes[26] | bytes[27] << 8 & 16383,
        height: bytes[28] | bytes[29] << 8 & 16383
      };
    }
  }
  if (bytes[12] === 86 && bytes[13] === 80 && bytes[14] === 56 && bytes[15] === 76) {
    return {
      width: 1 + (bytes[21] | (bytes[22] & 63) << 8),
      height: 1 + ((bytes[22] & 192) >> 6 | bytes[23] << 2 | (bytes[24] & 15) << 10)
    };
  }
  if (bytes[12] === 86 && bytes[13] === 80 && bytes[14] === 56 && bytes[15] === 88) {
    return {
      width: 1 + (bytes[24] | bytes[25] << 8 | bytes[26] << 16),
      height: 1 + (bytes[27] | bytes[28] << 8 | bytes[29] << 16)
    };
  }
  return null;
}
var isWebp = (data) => {
  const webpPattern = new Uint8Array([82, 73, 70, 70]);
  if (matchesPattern(webpPattern)(data.subarray(0, 4))) {
    return {
      type: "webp",
      dimensions: getWebPDimensions(data)
    };
  }
  return null;
};

// src/file-types/index.ts
var detectFileType = (data) => {
  if (isRiffWave(data)) {
    return { type: "wav" };
  }
  if (isRiffAvi(data)) {
    return { type: "riff" };
  }
  if (isAac(data)) {
    return { type: "aac" };
  }
  if (isFlac(data)) {
    return { type: "flac" };
  }
  const webp = isWebp(data);
  if (webp) {
    return webp;
  }
  if (isWebm(data)) {
    return { type: "webm" };
  }
  if (isIsoBaseMedia(data)) {
    return { type: "iso-base-media" };
  }
  if (isTransportStream(data)) {
    return { type: "transport-stream" };
  }
  if (isMp3(data)) {
    return { type: "mp3" };
  }
  if (isGif(data)) {
    return { type: "gif" };
  }
  const png = isPng(data);
  if (png) {
    return png;
  }
  const pdf = isPdf(data);
  if (pdf) {
    return pdf;
  }
  const bmp = isBmp(data);
  if (bmp) {
    return bmp;
  }
  const jpeg = isJpeg(data);
  if (jpeg) {
    return jpeg;
  }
  return { type: "unknown" };
};

// src/buffer-iterator.ts
class OffsetCounter {
  #offset;
  #discardedBytes;
  constructor(initial) {
    this.#offset = initial;
    this.#discardedBytes = 0;
  }
  increment(amount) {
    if (amount < 0) {
      throw new Error("Cannot increment by a negative amount: " + amount);
    }
    this.#offset += amount;
  }
  getOffset() {
    return this.#offset;
  }
  getDiscardedOffset() {
    return this.#offset - this.#discardedBytes;
  }
  setDiscardedOffset(offset) {
    this.#discardedBytes = offset;
  }
  getDiscardedBytes() {
    return this.#discardedBytes;
  }
  discardBytes(amount) {
    this.#discardedBytes += amount;
  }
  decrement(amount) {
    if (amount < 0) {
      throw new Error("Cannot decrement by a negative amount");
    }
    this.#offset -= amount;
  }
}
var makeOffsetCounter = () => {
  return new OffsetCounter(0);
};
var getArrayBufferIterator = (initialData, maxBytes) => {
  const buf = new ArrayBuffer(initialData.byteLength, {
    maxByteLength: maxBytes === null ? initialData.byteLength : Math.min(maxBytes, 2 ** 32)
  });
  if (!buf.resize) {
    throw new Error("`ArrayBuffer.resize` is not supported in this Runtime. On the server: Use at least Node.js 20 or Bun. In the browser: Chrome 111, Edge 111, Safari 16.4, Firefox 128, Opera 111");
  }
  let uintArray = new Uint8Array(buf);
  uintArray.set(initialData);
  let view = new DataView(uintArray.buffer);
  const counter = makeOffsetCounter();
  const startCheckpoint = () => {
    const checkpoint = counter.getOffset();
    return {
      returnToCheckpoint: () => {
        counter.decrement(counter.getOffset() - checkpoint);
      }
    };
  };
  const getSlice = (amount) => {
    const value = uintArray.slice(counter.getDiscardedOffset(), counter.getDiscardedOffset() + amount);
    counter.increment(amount);
    return value;
  };
  const discard = (length) => {
    counter.increment(length);
  };
  const readUntilNullTerminator = () => {
    const bytes = [];
    let byte;
    while ((byte = getUint8()) !== 0) {
      bytes.push(byte);
    }
    counter.decrement(1);
    return new TextDecoder().decode(new Uint8Array(bytes));
  };
  const getUint8 = () => {
    const val = view.getUint8(counter.getDiscardedOffset());
    counter.increment(1);
    return val;
  };
  const getEightByteNumber = (littleEndian = false) => {
    if (littleEndian) {
      const one = getUint8();
      const two = getUint8();
      const three = getUint8();
      const four = getUint8();
      const five = getUint8();
      const six = getUint8();
      const seven = getUint8();
      const eight = getUint8();
      return eight << 56 | seven << 48 | six << 40 | five << 32 | four << 24 | three << 16 | two << 8 | one;
    }
    function byteArrayToBigInt(byteArray) {
      let result = BigInt(0);
      for (let i = 0;i < byteArray.length; i++) {
        result = (result << BigInt(8)) + BigInt(byteArray[i]);
      }
      return result;
    }
    const bigInt = byteArrayToBigInt([
      getUint8(),
      getUint8(),
      getUint8(),
      getUint8(),
      getUint8(),
      getUint8(),
      getUint8(),
      getUint8()
    ]);
    return Number(bigInt);
  };
  const getFourByteNumber = () => {
    return getUint8() << 24 | getUint8() << 16 | getUint8() << 8 | getUint8();
  };
  const getPaddedFourByteNumber = () => {
    let lastInt = 128;
    while (lastInt = getUint8(), lastInt === 128) {
    }
    return lastInt;
  };
  const getUint32 = () => {
    const val = view.getUint32(counter.getDiscardedOffset());
    counter.increment(4);
    return val;
  };
  const getSyncSafeInt32 = () => {
    const val = view.getUint32(counter.getDiscardedOffset());
    counter.increment(4);
    return (val & 2130706432) >> 3 | (val & 8323072) >> 2 | (val & 32512) >> 1 | val & 127;
  };
  const getUint64 = (littleEndian = false) => {
    const val = view.getBigUint64(counter.getDiscardedOffset(), littleEndian);
    counter.increment(8);
    return val;
  };
  const getInt64 = (littleEndian = false) => {
    const val = view.getBigInt64(counter.getDiscardedOffset(), littleEndian);
    counter.increment(8);
    return val;
  };
  const startBox = (size) => {
    const startOffset = counter.getOffset();
    return {
      discardRest: () => discard(size - (counter.getOffset() - startOffset)),
      expectNoMoreBytes: () => {
        const remaining = size - (counter.getOffset() - startOffset);
        if (remaining !== 0) {
          throw new Error("expected 0 bytes, got " + remaining);
        }
      }
    };
  };
  const getUint32Le = () => {
    const val = view.getUint32(counter.getDiscardedOffset(), true);
    counter.increment(4);
    return val;
  };
  const getInt32Le = () => {
    const val = view.getInt32(counter.getDiscardedOffset(), true);
    counter.increment(4);
    return val;
  };
  const getInt32 = () => {
    const val = view.getInt32(counter.getDiscardedOffset());
    counter.increment(4);
    return val;
  };
  const addData = (newData) => {
    const oldLength = buf.byteLength;
    const newLength = oldLength + newData.byteLength;
    if (newLength < oldLength) {
      throw new Error("Cannot decrement size");
    }
    if (newLength > (maxBytes ?? Infinity)) {
      throw new Error(`Exceeded maximum byte length ${maxBytes} with ${newLength}`);
    }
    buf.resize(newLength);
    const newArray = new Uint8Array(buf);
    newArray.set(newData, oldLength);
    uintArray = newArray;
    view = new DataView(uintArray.buffer);
  };
  const bytesRemaining = () => {
    return uintArray.byteLength - counter.getDiscardedOffset();
  };
  const removeBytesRead = (force, mode) => {
    const bytesToRemove = counter.getDiscardedOffset();
    if (bytesToRemove < 3000000 && !force) {
      return { bytesRemoved: 0, removedData: null };
    }
    if (view.byteLength < bytesToRemove && !force) {
      return { bytesRemoved: 0, removedData: null };
    }
    counter.discardBytes(bytesToRemove);
    const removedData = mode === "download" ? uintArray.slice(0, bytesToRemove) : null;
    const newData = uintArray.slice(bytesToRemove);
    uintArray.set(newData);
    buf.resize(newData.byteLength);
    view = new DataView(uintArray.buffer);
    return { bytesRemoved: bytesToRemove, removedData };
  };
  const skipTo = (offset) => {
    const becomesSmaller = offset < counter.getOffset();
    if (!becomesSmaller) {
      const currentOffset = counter.getOffset();
      counter.increment(offset - currentOffset);
      return;
    }
    buf.resize(0);
    counter.decrement(counter.getOffset() - offset);
    counter.setDiscardedOffset(offset);
  };
  const readExpGolomb = () => {
    if (!bitReadingMode) {
      throw new Error("Not in bit reading mode");
    }
    let zerosCount = 0;
    while (getBits(1) === 0) {
      zerosCount++;
    }
    let suffix = 0;
    for (let i = 0;i < zerosCount; i++) {
      suffix = suffix << 1 | getBits(1);
    }
    return (1 << zerosCount) - 1 + suffix;
  };
  const peekB = (length) => {
    console.log([...getSlice(length)].map((b) => b.toString(16).padStart(2, "0")));
    counter.decrement(length);
  };
  const peekD = (length) => {
    console.log([...getSlice(length)].map((b) => b));
    counter.decrement(length);
  };
  const leb128 = () => {
    let result = 0;
    let shift = 0;
    let byte;
    do {
      byte = getBits(8);
      result |= (byte & 127) << shift;
      shift += 7;
    } while (byte >= 128);
    return result;
  };
  let bitIndex = 0;
  const stopReadingBits = () => {
    bitIndex = 0;
    bitReadingMode = false;
  };
  let byteToShift = 0;
  let bitReadingMode = false;
  const startReadingBits = () => {
    bitReadingMode = true;
    byteToShift = getUint8();
  };
  const getFlacCodecNumber = () => {
    let ones = 0;
    let bits = 0;
    while ((++bits || true) && getBits(1) === 1) {
      ones++;
    }
    if (ones === 0) {
      return getBits(7);
    }
    const bitArray = [];
    const firstByteBits = 8 - ones - 1;
    for (let i = 0;i < firstByteBits; i++) {
      bitArray.unshift(getBits(1));
    }
    const extraBytes = ones - 1;
    for (let i = 0;i < extraBytes; i++) {
      for (let j = 0;j < 8; j++) {
        const val = getBits(1);
        if (j < 2) {
          continue;
        }
        bitArray.unshift(val);
      }
    }
    const encoded = bitArray.reduce((acc, bit, index) => {
      return acc | bit << index;
    }, 0);
    return encoded;
  };
  const getBits = (bits) => {
    let result = 0;
    let bitsCollected = 0;
    while (bitsCollected < bits) {
      if (bitIndex >= 8) {
        bitIndex = 0;
        byteToShift = getUint8();
      }
      const remainingBitsInByte = 8 - bitIndex;
      const bitsToReadNow = Math.min(bits - bitsCollected, remainingBitsInByte);
      const mask = (1 << bitsToReadNow) - 1;
      const shift = remainingBitsInByte - bitsToReadNow;
      result <<= bitsToReadNow;
      result |= byteToShift >> shift & mask;
      bitsCollected += bitsToReadNow;
      bitIndex += bitsToReadNow;
    }
    return result;
  };
  const destroy = () => {
    uintArray = new Uint8Array(0);
    buf.resize(0);
  };
  return {
    startReadingBits,
    stopReadingBits,
    skipTo,
    addData,
    counter,
    peekB,
    peekD,
    getBits,
    bytesRemaining,
    leb128,
    removeBytesRead,
    discard,
    getEightByteNumber,
    getFourByteNumber,
    getSlice,
    getAtom: () => {
      const atom = getSlice(4);
      return new TextDecoder().decode(atom);
    },
    detectFileType: () => {
      return detectFileType(uintArray);
    },
    getPaddedFourByteNumber,
    getMatroskaSegmentId: () => {
      if (bytesRemaining() === 0) {
        return null;
      }
      const first = getSlice(1);
      const firstOneString = `0x${Array.from(new Uint8Array(first)).map((b) => {
        return b.toString(16).padStart(2, "0");
      }).join("")}`;
      if (knownIdsWithOneLength.includes(firstOneString)) {
        return firstOneString;
      }
      if (bytesRemaining() === 0) {
        return null;
      }
      const firstTwo = getSlice(1);
      const firstTwoString = `${firstOneString}${Array.from(new Uint8Array(firstTwo)).map((b) => {
        return b.toString(16).padStart(2, "0");
      }).join("")}`;
      if (knownIdsWithTwoLength.includes(firstTwoString)) {
        return firstTwoString;
      }
      if (bytesRemaining() === 0) {
        return null;
      }
      const firstThree = getSlice(1);
      const firstThreeString = `${firstTwoString}${Array.from(new Uint8Array(firstThree)).map((b) => {
        return b.toString(16).padStart(2, "0");
      }).join("")}`;
      if (knownIdsWithThreeLength.includes(firstThreeString)) {
        return firstThreeString;
      }
      if (bytesRemaining() === 0) {
        return null;
      }
      const segmentId = getSlice(1);
      return `${firstThreeString}${Array.from(new Uint8Array(segmentId)).map((b) => {
        return b.toString(16).padStart(2, "0");
      }).join("")}`;
    },
    getVint: () => {
      if (bytesRemaining() === 0) {
        return null;
      }
      const firstByte = getUint8();
      const totalLength = firstByte;
      if (totalLength === 0) {
        return 0;
      }
      let actualLength = 0;
      while ((totalLength >> 7 - actualLength & 1) === 0) {
        actualLength++;
      }
      if (bytesRemaining() < actualLength) {
        return null;
      }
      const slice = getSlice(actualLength);
      const d = [firstByte, ...Array.from(new Uint8Array(slice))];
      actualLength += 1;
      let value = 0;
      value = totalLength & 255 >> actualLength;
      for (let i = 1;i < actualLength; i++) {
        value = value << 8 | d[i];
      }
      if (value === -1) {
        return Infinity;
      }
      return value;
    },
    getUint8,
    getEBML: () => {
      const val = getUint8();
      const actualValue = val & 127;
      return actualValue;
    },
    getInt8: () => {
      const val = view.getInt8(counter.getDiscardedOffset());
      counter.increment(1);
      return val;
    },
    getUint16: () => {
      const val = view.getUint16(counter.getDiscardedOffset());
      counter.increment(2);
      return val;
    },
    getUint16Le: () => {
      const val = view.getUint16(counter.getDiscardedOffset(), true);
      counter.increment(2);
      return val;
    },
    getUint24: () => {
      const val1 = view.getUint8(counter.getDiscardedOffset());
      const val2 = view.getUint8(counter.getDiscardedOffset() + 1);
      const val3 = view.getUint8(counter.getDiscardedOffset() + 2);
      counter.increment(3);
      return val1 << 16 | val2 << 8 | val3;
    },
    getInt24: () => {
      const val1 = view.getInt8(counter.getDiscardedOffset());
      const val2 = view.getUint8(counter.getDiscardedOffset() + 1);
      const val3 = view.getUint8(counter.getDiscardedOffset() + 2);
      counter.increment(3);
      return val1 << 16 | val2 << 8 | val3;
    },
    getInt16: () => {
      const val = view.getInt16(counter.getDiscardedOffset());
      counter.increment(2);
      return val;
    },
    getUint32,
    getUint64,
    getInt64,
    getFixedPointUnsigned1616Number: () => {
      const val = getUint32();
      return val / 2 ** 16;
    },
    getFixedPointSigned1616Number: () => {
      const val = getInt32();
      return val / 2 ** 16;
    },
    getFixedPointSigned230Number: () => {
      const val = getInt32();
      return val / 2 ** 30;
    },
    getPascalString: () => {
      const val = getSlice(32);
      return [...Array.from(new Uint8Array(val))];
    },
    getUint(length) {
      const bytes = getSlice(length);
      const numbers = [...Array.from(new Uint8Array(bytes))];
      return numbers.reduce((acc, byte, index) => acc + (byte << 8 * (numbers.length - index - 1)), 0);
    },
    getByteString(length, trimTrailingZeroes) {
      let bytes = getSlice(length);
      while (trimTrailingZeroes && bytes[bytes.length - 1] === 0) {
        bytes = bytes.slice(0, -1);
      }
      return new TextDecoder().decode(bytes).trim();
    },
    planBytes: (size) => {
      const currentOffset = counter.getOffset();
      return {
        discardRest: () => {
          const toDiscard = size - (counter.getOffset() - currentOffset);
          if (toDiscard < 0) {
            throw new Error("read too many bytes");
          }
          return getSlice(toDiscard);
        }
      };
    },
    getFloat64: () => {
      const val = view.getFloat64(counter.getDiscardedOffset());
      counter.increment(8);
      return val;
    },
    readUntilNullTerminator,
    getFloat32: () => {
      const val = view.getFloat32(counter.getDiscardedOffset());
      counter.increment(4);
      return val;
    },
    getUint32Le,
    getInt32Le,
    getInt32,
    destroy,
    startBox,
    readExpGolomb,
    startCheckpoint,
    getFlacCodecNumber,
    getSyncSafeInt32
  };
};

// src/containers/iso-base-media/ftyp.ts
var parseFtyp = ({
  iterator,
  size,
  offset
}) => {
  const majorBrand = iterator.getByteString(4, false);
  const minorVersion = iterator.getFourByteNumber();
  const types = (size - iterator.counter.getOffset()) / 4;
  const compatibleBrands = [];
  for (let i = 0;i < types; i++) {
    compatibleBrands.push(iterator.getByteString(4, false).trim());
  }
  const offsetAtEnd = iterator.counter.getOffset();
  return {
    type: "ftyp-box",
    majorBrand,
    minorVersion,
    compatibleBrands,
    offset,
    boxSize: offsetAtEnd - offset
  };
};

// src/containers/iso-base-media/to-date.ts
var toUnixTimestamp = (value) => {
  if (value === 0) {
    return null;
  }
  const baseDate = new Date("1904-01-01T00:00:00Z");
  return Math.floor(value + baseDate.getTime() / 1000) * 1000;
};

// src/containers/iso-base-media/mvhd.ts
var parseMvhd = ({
  iterator,
  offset,
  size
}) => {
  const version = iterator.getUint8();
  iterator.discard(3);
  const creationTime = version === 1 ? iterator.getUint64() : iterator.getUint32();
  const modificationTime = version === 1 ? iterator.getUint64() : iterator.getUint32();
  const timeScale = iterator.getUint32();
  const durationInUnits = version === 1 ? iterator.getUint64() : iterator.getUint32();
  const durationInSeconds = Number(durationInUnits) / timeScale;
  const rateArray = iterator.getSlice(4);
  const rateView = getArrayBufferIterator(rateArray, rateArray.length);
  const rate = rateView.getInt8() * 10 + rateView.getInt8() + rateView.getInt8() * 0.1 + rateView.getInt8() * 0.01;
  const volumeArray = iterator.getSlice(2);
  const volumeView = getArrayBufferIterator(volumeArray, volumeArray.length);
  const volume = volumeView.getInt8() + volumeView.getInt8() * 0.1;
  iterator.discard(2);
  iterator.discard(4);
  iterator.discard(4);
  const matrix = [
    iterator.getFixedPointSigned1616Number(),
    iterator.getFixedPointSigned1616Number(),
    iterator.getFixedPointSigned230Number(),
    iterator.getFixedPointSigned1616Number(),
    iterator.getFixedPointSigned1616Number(),
    iterator.getFixedPointSigned230Number(),
    iterator.getFixedPointSigned1616Number(),
    iterator.getFixedPointSigned1616Number(),
    iterator.getFixedPointSigned230Number()
  ];
  iterator.discard(4 * 6);
  const nextTrackId = iterator.getUint32();
  volumeView.destroy();
  const bytesRemaining = size - (iterator.counter.getOffset() - offset);
  if (bytesRemaining !== 0) {
    throw new Error("expected 0 bytes " + bytesRemaining);
  }
  return {
    creationTime: toUnixTimestamp(Number(creationTime)),
    modificationTime: toUnixTimestamp(Number(modificationTime)),
    timeScale,
    durationInUnits: Number(durationInUnits),
    durationInSeconds,
    rate,
    volume,
    matrix,
    nextTrackId,
    type: "mvhd-box",
    boxSize: size,
    offset
  };
};

// src/log.ts
var logLevels = ["trace", "verbose", "info", "warn", "error"];
var getNumberForLogLevel = (level) => {
  return logLevels.indexOf(level);
};
var isEqualOrBelowLogLevel = (currentLevel, level) => {
  return getNumberForLogLevel(currentLevel) <= getNumberForLogLevel(level);
};
var Log = {
  trace: (logLevel, ...args) => {
    if (isEqualOrBelowLogLevel(logLevel, "trace")) {
      return console.log(...args);
    }
  },
  verbose: (logLevel, ...args) => {
    if (isEqualOrBelowLogLevel(logLevel, "verbose")) {
      return console.log(...args);
    }
  },
  info: (logLevel, ...args) => {
    if (isEqualOrBelowLogLevel(logLevel, "info")) {
      return console.log(...args);
    }
  },
  warn: (logLevel, ...args) => {
    if (isEqualOrBelowLogLevel(logLevel, "warn")) {
      return console.warn(...args);
    }
  },
  error: (...args) => {
    return console.error(...args);
  }
};

// src/containers/avc/codec-string.ts
var getCodecStringFromSpsAndPps = (sps) => {
  return `avc1.${sps.spsData.profile.toString(16).padStart(2, "0")}${sps.spsData.compatibility.toString(16).padStart(2, "0")}${sps.spsData.level.toString(16).padStart(2, "0")}`;
};

// src/combine-uint8-arrays.ts
var combineUint8Arrays = (arrays) => {
  if (arrays.length === 0) {
    return new Uint8Array([]);
  }
  if (arrays.length === 1) {
    return arrays[0];
  }
  let totalLength = 0;
  for (const array of arrays) {
    totalLength += array.length;
  }
  const result = new Uint8Array(totalLength);
  let offset = 0;
  for (const array of arrays) {
    result.set(array, offset);
    offset += array.length;
  }
  return result;
};

// src/containers/avc/create-sps-pps-data.ts
function serializeUint16(value) {
  const buffer = new ArrayBuffer(2);
  const view = new DataView(buffer);
  view.setUint16(0, value);
  return new Uint8Array(buffer);
}
var createSpsPpsData = (avc1Profile) => {
  return combineUint8Arrays([
    new Uint8Array([
      1,
      avc1Profile.sps.spsData.profile,
      avc1Profile.sps.spsData.compatibility,
      avc1Profile.sps.spsData.level,
      255,
      225
    ]),
    serializeUint16(avc1Profile.sps.sps.length),
    avc1Profile.sps.sps,
    new Uint8Array([1]),
    serializeUint16(avc1Profile.pps.pps.length),
    avc1Profile.pps.pps
  ]);
};

// src/add-avc-profile-to-track.ts
var addAvcProfileToTrack = (track, avc1Profile) => {
  if (avc1Profile === null) {
    return track;
  }
  return {
    ...track,
    codec: getCodecStringFromSpsAndPps(avc1Profile.sps),
    codecPrivate: createSpsPpsData(avc1Profile)
  };
};

// src/register-track.ts
var registerTrack = async ({
  state,
  track,
  container
}) => {
  if (state.callbacks.tracks.getTracks().find((t) => t.trackId === track.trackId)) {
    Log.trace(state.logLevel, `Track ${track.trackId} already registered, skipping`);
    return;
  }
  if (track.type === "video") {
    state.callbacks.tracks.addTrack(track);
    if (state.onVideoTrack) {
      const callback = await state.onVideoTrack({ track, container });
      await state.callbacks.registerVideoSampleCallback(track.trackId, callback ?? null);
    }
  }
  if (track.type === "audio") {
    state.callbacks.tracks.addTrack(track);
    if (state.onAudioTrack) {
      const callback = await state.onAudioTrack({ track, container });
      await state.callbacks.registerAudioSampleCallback(track.trackId, callback ?? null);
    }
  }
};
var registerVideoTrackWhenProfileIsAvailable = ({
  state,
  track,
  container
}) => {
  state.riff.registerOnAvcProfileCallback(async (profile) => {
    await registerTrack({
      state,
      track: addAvcProfileToTrack(track, profile),
      container
    });
  });
};

// src/containers/iso-base-media/esds/decoder-specific-config.ts
var parseDecoderSpecificConfig = (iterator) => {
  const layerTag = iterator.getUint8();
  const layerSize = iterator.getPaddedFourByteNumber();
  const start = iterator.counter.getOffset();
  if (layerTag !== 5) {
    iterator.discard(layerSize);
    return {
      type: "unknown-decoder-specific-config"
    };
  }
  const bytes = iterator.getSlice(layerSize);
  iterator.counter.decrement(layerSize);
  iterator.startReadingBits();
  const audioObjectType = iterator.getBits(5);
  const samplingFrequencyIndex = iterator.getBits(4);
  if (samplingFrequencyIndex === 15) {
    iterator.getBits(24);
  }
  const channelConfiguration = iterator.getBits(4);
  iterator.stopReadingBits();
  const read = iterator.counter.getOffset() - start;
  if (read < layerSize) {
    iterator.discard(layerSize - read);
  }
  return {
    type: "mp4a-specific-config",
    audioObjectType,
    samplingFrequencyIndex,
    channelConfiguration,
    asBytes: bytes
  };
};

// src/containers/iso-base-media/esds/esds-descriptors.ts
var mapToObjectAudioIndicator = (num) => {
  if (num === 64) {
    return "aac";
  }
  if (num === 107) {
    return "mp3";
  }
  return "unknown";
};
var processDescriptor = ({
  iterator
}) => {
  const tag = iterator.getUint8();
  if (tag === 4) {
    const size = iterator.getPaddedFourByteNumber();
    const initialOffset = iterator.counter.getOffset();
    const objectTypeIndication = iterator.getUint8();
    iterator.startReadingBits();
    const streamType = iterator.getBits(6);
    const upStream = iterator.getBits(1);
    iterator.getBits(1);
    const bufferSizeDB = iterator.getBits(24);
    iterator.stopReadingBits();
    const maxBitrate = iterator.getUint32();
    const avgBitrate = iterator.getUint32();
    const decoderSpecificConfigs = [];
    while (size - (iterator.counter.getOffset() - initialOffset) > 0) {
      const decoderSpecificConfig = parseDecoderSpecificConfig(iterator);
      decoderSpecificConfigs.push(decoderSpecificConfig);
    }
    return {
      descriptor: {
        type: "decoder-config-descriptor",
        objectTypeIndication: mapToObjectAudioIndicator(objectTypeIndication),
        asNumber: objectTypeIndication,
        bufferSizeDB,
        streamType,
        upStream,
        avgBitrate,
        maxBitrate,
        decoderSpecificConfigs
      }
    };
  }
  if (tag === 6) {
    const size = iterator.getPaddedFourByteNumber();
    iterator.discard(size);
    return {
      descriptor: {
        type: "sl-config-descriptor"
      }
    };
  }
  return {
    descriptor: null
  };
};
var parseDescriptors = (iterator, maxBytes) => {
  const descriptors = [];
  const initialOffset = iterator.counter.getOffset();
  while (iterator.bytesRemaining() > 0 && iterator.counter.getOffset() - initialOffset < maxBytes) {
    const { descriptor } = processDescriptor({
      iterator
    });
    if (descriptor) {
      descriptors.push(descriptor);
    } else {
      break;
    }
  }
  return descriptors;
};

// src/containers/iso-base-media/esds/esds.ts
var parseEsds = ({
  data,
  size,
  fileOffset
}) => {
  const version = data.getUint8();
  data.discard(3);
  const tag = data.getUint8();
  const sizeOfInstance = data.getPaddedFourByteNumber();
  const esId = data.getUint16();
  data.discard(1);
  const remaining = size - (data.counter.getOffset() - fileOffset);
  const descriptors = parseDescriptors(data, remaining);
  const remainingNow = size - (data.counter.getOffset() - fileOffset);
  data.discard(remainingNow);
  return {
    type: "esds-box",
    version,
    tag,
    sizeOfInstance,
    esId,
    descriptors
  };
};

// src/containers/iso-base-media/traversal.ts
var getMoovBox = (state) => {
  if (state.iso.moov.getMoovBox()) {
    return state.iso.moov.getMoovBox();
  }
  const structure = state.getIsoStructure();
  const moovBox = structure.boxes.find((s) => s.type === "moov-box");
  if (!moovBox || moovBox.type !== "moov-box") {
    return null;
  }
  return moovBox;
};
var getMoofBoxes = (main) => {
  const moofBoxes = main.filter((s) => s.type === "regular-box" && s.boxType === "moof");
  return moofBoxes;
};
var getMvhdBox = (moovBox) => {
  const mvHdBox = moovBox.children.find((s) => s.type === "mvhd-box");
  if (!mvHdBox || mvHdBox.type !== "mvhd-box") {
    return null;
  }
  return mvHdBox;
};
var getTraks = (moovBox) => {
  return moovBox.children.filter((s) => s.type === "trak-box");
};
var getTkhdBox = (trakBox) => {
  const tkhdBox = trakBox.children.find((s) => s.type === "tkhd-box");
  return tkhdBox;
};
var getMdiaBox = (trakBox) => {
  const mdiaBox = trakBox.children.find((s) => s.type === "regular-box" && s.boxType === "mdia");
  if (!mdiaBox || mdiaBox.type !== "regular-box") {
    return null;
  }
  return mdiaBox;
};
var getMdhdBox = (trakBox) => {
  const mdiaBox = getMdiaBox(trakBox);
  if (!mdiaBox) {
    return null;
  }
  const mdhdBox = mdiaBox.children.find((c) => c.type === "mdhd-box");
  return mdhdBox;
};
var getStblBox = (trakBox) => {
  const mdiaBox = getMdiaBox(trakBox);
  if (!mdiaBox) {
    return null;
  }
  const minfBox = mdiaBox.children.find((s) => s.type === "regular-box" && s.boxType === "minf");
  if (!minfBox || minfBox.type !== "regular-box") {
    return null;
  }
  const stblBox = minfBox.children.find((s) => s.type === "regular-box" && s.boxType === "stbl");
  if (!stblBox || stblBox.type !== "regular-box") {
    return null;
  }
  return stblBox;
};
var getStsdBox = (trakBox) => {
  const stblBox = getStblBox(trakBox);
  if (!stblBox || stblBox.type !== "regular-box") {
    return null;
  }
  const stsdBox = stblBox.children.find((s) => s.type === "stsd-box");
  return stsdBox;
};
var getVideoDescriptors = (trakBox) => {
  const stsdBox = getStsdBox(trakBox);
  if (!stsdBox) {
    return null;
  }
  const descriptors = stsdBox.samples.map((s) => {
    return s.type === "video" ? s.descriptors.map((d) => {
      return d.type === "avcc-box" ? d.privateData : d.type === "hvcc-box" ? d.privateData : null;
    }) : [];
  });
  return descriptors.flat(1).filter(Boolean)[0] ?? null;
};
var getStcoBox = (trakBox) => {
  const stblBox = getStblBox(trakBox);
  if (!stblBox || stblBox.type !== "regular-box") {
    return null;
  }
  const stcoBox = stblBox.children.find((s) => s.type === "stco-box");
  return stcoBox;
};
var getSttsBox = (trakBox) => {
  const stblBox = getStblBox(trakBox);
  if (!stblBox || stblBox.type !== "regular-box") {
    return null;
  }
  const sttsBox = stblBox.children.find((s) => s.type === "stts-box");
  return sttsBox;
};
var getCttsBox = (trakBox) => {
  const stblBox = getStblBox(trakBox);
  if (!stblBox || stblBox.type !== "regular-box") {
    return null;
  }
  const cttsBox = stblBox.children.find((s) => s.type === "ctts-box");
  return cttsBox;
};
var getStszBox = (trakBox) => {
  const stblBox = getStblBox(trakBox);
  if (!stblBox || stblBox.type !== "regular-box") {
    return null;
  }
  const stszBox = stblBox.children.find((s) => s.type === "stsz-box");
  return stszBox;
};
var getStscBox = (trakBox) => {
  const stblBox = getStblBox(trakBox);
  if (!stblBox || stblBox.type !== "regular-box") {
    return null;
  }
  const stcoBox = stblBox.children.find((b) => b.type === "stsc-box");
  return stcoBox;
};
var getStssBox = (trakBox) => {
  const stblBox = getStblBox(trakBox);
  if (!stblBox || stblBox.type !== "regular-box") {
    return null;
  }
  const stssBox = stblBox.children.find((b) => b.type === "stss-box");
  return stssBox;
};
var getTfdtBox = (segment) => {
  if (segment.type !== "regular-box" || segment.boxType !== "traf") {
    throw new Error("Expected traf-box");
  }
  const tfhdBox = segment.children.find((c) => c.type === "tfdt-box");
  if (!tfhdBox || tfhdBox.type !== "tfdt-box") {
    throw new Error("Expected tfhd-box");
  }
  return tfhdBox;
};
var getTfhdBox = (segment) => {
  if (segment.type !== "regular-box" || segment.boxType !== "traf") {
    throw new Error("Expected traf-box");
  }
  const tfhdBox = segment.children.find((c) => c.type === "tfhd-box");
  if (!tfhdBox || tfhdBox.type !== "tfhd-box") {
    throw new Error("Expected tfhd-box");
  }
  return tfhdBox;
};
var getTrunBoxes = (segment) => {
  if (segment.type !== "regular-box" || segment.boxType !== "traf") {
    throw new Error("Expected traf-box");
  }
  const trunBoxes = segment.children.filter((c) => c.type === "trun-box");
  return trunBoxes;
};

// src/containers/riff/traversal.ts
var isRiffAvi2 = (structure) => {
  return structure.boxes.some((box) => box.type === "riff-header" && box.fileType === "AVI");
};
var getHdlrBox = (structure) => {
  return structure.boxes.find((box) => box.type === "list-box" && box.listType === "hdrl");
};
var getAvihBox = (structure) => {
  const hdlrBox = getHdlrBox(structure);
  if (!hdlrBox) {
    return null;
  }
  return hdlrBox.children.find((box) => box.type === "avih-box");
};
var getStrlBoxes = (structure) => {
  const hdlrBox = getHdlrBox(structure);
  if (!hdlrBox) {
    return [];
  }
  return hdlrBox.children.filter((box) => box.type === "list-box" && box.listType === "strl");
};
var getStrhBox = (strlBoxChildren) => {
  return strlBoxChildren.find((box) => box.type === "strh-box");
};

// src/is-audio-structure.ts
var isAudioStructure = (structure) => {
  if (structure.type === "mp3") {
    return true;
  }
  if (structure.type === "wav") {
    return true;
  }
  if (structure.type === "aac") {
    return true;
  }
  if (structure.type === "flac") {
    return true;
  }
  if (structure.type === "iso-base-media") {
    return false;
  }
  if (structure.type === "matroska") {
    return false;
  }
  if (structure.type === "transport-stream") {
    return false;
  }
  if (structure.type === "riff") {
    return false;
  }
  throw new Error(`Unhandled structure type: ${structure}`);
};

// src/get-fps.ts
var calculateFps = ({
  sttsBox,
  timeScale,
  durationInSamples
}) => {
  let totalSamples = 0;
  for (const sample of sttsBox.sampleDistribution) {
    totalSamples += sample.sampleCount;
  }
  if (totalSamples === 0) {
    return null;
  }
  const durationInSeconds = durationInSamples / timeScale;
  const fps = totalSamples / durationInSeconds;
  return fps;
};
var trakBoxContainsAudio = (trakBox) => {
  const stsd = getStsdBox(trakBox);
  if (!stsd) {
    return false;
  }
  const videoSample = stsd.samples.find((s) => s.type === "audio");
  if (!videoSample || videoSample.type !== "audio") {
    return false;
  }
  return true;
};
var trakBoxContainsVideo = (trakBox) => {
  const stsd = getStsdBox(trakBox);
  if (!stsd) {
    return false;
  }
  const videoSample = stsd.samples.find((s) => s.type === "video");
  if (!videoSample || videoSample.type !== "video") {
    return false;
  }
  return true;
};
var getTimescaleAndDuration = (trakBox) => {
  const mdhdBox = getMdhdBox(trakBox);
  if (mdhdBox) {
    return { timescale: mdhdBox.timescale, duration: mdhdBox.duration };
  }
  return null;
};
var getFpsFromMp4TrakBox = (trakBox) => {
  const timescaleAndDuration = getTimescaleAndDuration(trakBox);
  if (!timescaleAndDuration) {
    return null;
  }
  const sttsBox = getSttsBox(trakBox);
  if (!sttsBox) {
    return null;
  }
  return calculateFps({
    sttsBox,
    timeScale: timescaleAndDuration.timescale,
    durationInSamples: timescaleAndDuration.duration
  });
};
var getFpsFromIsoMaseMedia = (state) => {
  const moovBox = getMoovBox(state);
  if (!moovBox) {
    return null;
  }
  const trackBoxes = getTraks(moovBox);
  const trackBox = trackBoxes.find(trakBoxContainsVideo);
  if (!trackBox) {
    return null;
  }
  return getFpsFromMp4TrakBox(trackBox);
};
var getFpsFromAvi = (structure) => {
  const strl = getStrlBoxes(structure);
  for (const s of strl) {
    const strh = getStrhBox(s.children);
    if (!strh) {
      throw new Error("No strh box");
    }
    if (strh.fccType === "auds") {
      continue;
    }
    return strh.rate;
  }
  return null;
};
var getFps = (state) => {
  const segments = state.getStructure();
  if (segments.type === "iso-base-media") {
    return getFpsFromIsoMaseMedia(state);
  }
  if (segments.type === "riff") {
    return getFpsFromAvi(segments);
  }
  if (segments.type === "matroska") {
    return null;
  }
  if (segments.type === "transport-stream") {
    return null;
  }
  if (segments.type === "mp3" || segments.type === "wav" || segments.type === "flac" || segments.type === "aac") {
    return null;
  }
  throw new Error("Cannot get fps, not implemented: " + segments);
};
var hasFpsSuitedForSlowFps = (state) => {
  try {
    return getFps(state) !== null;
  } catch {
    return false;
  }
};
var hasFps = (state) => {
  const structure = state.getStructure();
  if (isAudioStructure(structure)) {
    return true;
  }
  if (structure.type === "matroska") {
    return true;
  }
  if (structure.type === "transport-stream") {
    return true;
  }
  return hasFpsSuitedForSlowFps(state);
};

// src/containers/mp3/get-tracks-from-mp3.ts
var getTracksFromMp3OrWavOrAac = (parserState) => {
  const tracks2 = parserState.callbacks.tracks.getTracks();
  if (tracks2.length === 0) {
    throw new Error("No tracks found");
  }
  return {
    audioTracks: tracks2.filter((t) => t.type === "audio"),
    otherTracks: [],
    videoTracks: []
  };
};

// src/containers/riff/timescale.ts
var MEDIA_PARSER_RIFF_TIMESCALE = 1e6;

// src/containers/riff/get-tracks-from-avi.ts
var TO_BE_OVERRIDDEN_LATER = "to-be-overriden-later";
var getNumberOfTracks = (structure) => {
  const avihBox = getAvihBox(structure);
  if (avihBox) {
    return avihBox.streams;
  }
  throw new Error("No avih box found");
};
var makeAviAudioTrack = ({
  strf,
  index
}) => {
  if (strf.formatTag !== 255) {
    throw new Error(`Unsupported audio format ${strf.formatTag}`);
  }
  return {
    type: "audio",
    codec: "mp4a.40.2",
    codecPrivate: new Uint8Array([18, 16]),
    codecWithoutConfig: "aac",
    description: new Uint8Array([18, 16]),
    numberOfChannels: strf.numberOfChannels,
    sampleRate: strf.sampleRate,
    timescale: MEDIA_PARSER_RIFF_TIMESCALE,
    trackId: index,
    trakBox: null
  };
};
var makeAviVideoTrack = ({
  strh,
  strf,
  index
}) => {
  if (strh.handler !== "H264") {
    throw new Error(`Unsupported video codec ${strh.handler}`);
  }
  return {
    codecPrivate: null,
    codec: TO_BE_OVERRIDDEN_LATER,
    codecWithoutConfig: "h264",
    codedHeight: strf.height,
    codedWidth: strf.width,
    width: strf.width,
    height: strf.height,
    type: "video",
    displayAspectHeight: strf.height,
    timescale: MEDIA_PARSER_RIFF_TIMESCALE,
    description: undefined,
    trackId: index,
    color: {
      fullRange: null,
      matrixCoefficients: null,
      primaries: null,
      transferCharacteristics: null
    },
    displayAspectWidth: strf.width,
    trakBox: null,
    rotation: 0,
    sampleAspectRatio: {
      numerator: 1,
      denominator: 1
    },
    fps: strh.rate / strh.scale
  };
};
var getTracksFromAvi = (structure, state) => {
  const videoTracks = [];
  const audioTracks = [];
  const otherTracks = [];
  const boxes = getStrlBoxes(structure);
  let i = 0;
  for (const box of boxes) {
    const strh = getStrhBox(box.children);
    if (!strh) {
      continue;
    }
    const { strf } = strh;
    if (strf.type === "strf-box-video") {
      videoTracks.push(addAvcProfileToTrack(makeAviVideoTrack({ strh, strf, index: i }), state.riff.getAvcProfile()));
    } else if (strh.fccType === "auds") {
      audioTracks.push(makeAviAudioTrack({ strf, index: i }));
    } else {
      throw new Error(`Unsupported track type ${strh.fccType}`);
    }
    i++;
  }
  return { audioTracks, otherTracks, videoTracks };
};
var hasAllTracksFromAvi = (state) => {
  try {
    const structure = state.getRiffStructure();
    const numberOfTracks = getNumberOfTracks(structure);
    const tracks2 = getTracksFromAvi(structure, state);
    return tracks2.videoTracks.length + tracks2.audioTracks.length + tracks2.otherTracks.length === numberOfTracks && !tracks2.videoTracks.find((t) => t.codec === TO_BE_OVERRIDDEN_LATER);
  } catch {
    return false;
  }
};

// src/truthy.ts
function truthy(value) {
  return Boolean(value);
}

// src/containers/transport-stream/traversal.ts
var findProgramAssociationTableOrThrow = (structure) => {
  const box = structure.boxes.find((b) => b.type === "transport-stream-pat-box");
  if (!box) {
    throw new Error("No PAT box found");
  }
  return box;
};
var findProgramMapTableOrThrow = (structure) => {
  const box = structure.boxes.find((b) => b.type === "transport-stream-pmt-box");
  if (!box) {
    throw new Error("No PMT box found");
  }
  return box;
};
var getProgramForId = (structure, packetIdentifier) => {
  const box = findProgramAssociationTableOrThrow(structure);
  const entry = box.pat.find((e) => e.programMapIdentifier === packetIdentifier);
  return entry ?? null;
};
var getStreamForId = (structure, packetIdentifier) => {
  const box = findProgramMapTableOrThrow(structure);
  const entry = box.streams.find((e) => e.pid === packetIdentifier);
  return entry ?? null;
};

// src/containers/transport-stream/get-tracks.ts
var getTracksFromTransportStream = (parserState) => {
  const structure = parserState.getTsStructure();
  const programMapTable = findProgramMapTableOrThrow(structure);
  const parserTracks = parserState.callbacks.tracks.getTracks();
  const mapped = programMapTable.streams.map((stream) => {
    return parserTracks.find((track) => track.trackId === stream.pid);
  }).filter(truthy);
  if (mapped.length !== programMapTable.streams.length) {
    throw new Error("Not all tracks found");
  }
  return {
    videoTracks: mapped.filter((track) => track.type === "video"),
    audioTracks: mapped.filter((track) => track.type === "audio"),
    otherTracks: []
  };
};
var hasAllTracksFromTransportStream = (parserState) => {
  try {
    getTracksFromTransportStream(parserState);
    return true;
  } catch {
    return false;
  }
};

// src/make-hvc1-codec-strings.ts
var getHvc1CodecString = (data) => {
  const configurationVersion = data.getUint8();
  if (configurationVersion !== 1) {
    throw new Error(`Unsupported HVCC version ${configurationVersion}`);
  }
  const generalProfileSpaceTierFlagAndIdc = data.getUint8();
  let generalProfileCompatibility = data.getUint32();
  const generalProfileSpace = generalProfileSpaceTierFlagAndIdc >> 6;
  const generalTierFlag = generalProfileSpaceTierFlagAndIdc >> 5;
  const generalProfileIdc = generalProfileSpaceTierFlagAndIdc >> 0;
  const generalConstraintIndicator = data.getSlice(6);
  const generalLevelIdc = data.getUint8();
  let profileId = 0;
  for (let i = 0;i < 32; i++) {
    profileId |= generalProfileCompatibility & 1;
    if (i === 31)
      break;
    profileId <<= 1;
    generalProfileCompatibility >>= 1;
  }
  const profileSpaceChar = generalProfileSpace === 0 ? "" : generalProfileSpace === 1 ? "A" : generalProfileSpace === 2 ? "B" : "C";
  const generalTierChar = generalTierFlag === 0 ? "L" : "H";
  let hasByte = false;
  let generalConstraintString = "";
  for (let i = 5;i >= 0; i--) {
    if (generalConstraintIndicator[i] || hasByte) {
      generalConstraintString = generalConstraintIndicator[i].toString(16) + generalConstraintString;
      hasByte = true;
    }
  }
  return `${profileSpaceChar}${generalProfileIdc.toString(16)}.${profileId.toString(16)}.${generalTierChar}${generalLevelIdc}.${generalConstraintString}`;
};

// src/containers/webm/av1-codec-private.ts
var parseAv1PrivateData = (data, colrAtom) => {
  const iterator = getArrayBufferIterator(data, data.byteLength);
  iterator.startReadingBits();
  if (iterator.getBits(1) !== 1) {
    iterator.destroy();
    throw new Error("Expected av1 private data to be version 1");
  }
  const version = iterator.getBits(7);
  if (version !== 1) {
    iterator.destroy();
    throw new Error(`Expected av1 private data to be version 1, got ${version}`);
  }
  let str = "av01.";
  const seqProfile = iterator.getBits(3);
  str += seqProfile;
  str += ".";
  const seq_level_idx = iterator.getBits(5);
  const seq_tier_0 = iterator.getBits(1);
  str += String(seq_level_idx).padStart(2, "0");
  str += seq_tier_0 ? "H" : "M";
  str += ".";
  const high_bitdepth = iterator.getBits(1);
  const twelve_bit = iterator.getBits(1);
  const bitDepth2 = high_bitdepth && seqProfile === 2 ? twelve_bit ? 12 : 10 : high_bitdepth ? 10 : 8;
  str += bitDepth2.toString().padStart(2, "0");
  str += ".";
  const mono_chrome = iterator.getBits(1);
  str += mono_chrome ? "1" : "0";
  str += ".";
  const subsampling_x = iterator.getBits(1);
  str += subsampling_x ? "1" : "0";
  const subsampling_y = iterator.getBits(1);
  str += subsampling_y ? "1" : "0";
  const chroma_sample_position = iterator.getBits(2);
  str += subsampling_x && subsampling_y ? chroma_sample_position === 1 ? "1" : "0" : "0";
  str += ".";
  if (colrAtom && colrAtom.colorType === "transfer-characteristics") {
    str += colrAtom.primaries.toString().padStart(2, "0");
    str += ".";
    str += colrAtom.transfer.toString().padStart(2, "0");
    str += ".";
    str += colrAtom.matrixIndex.toString().padStart(2, "0");
    str += ".";
    str += colrAtom.fullRangeFlag ? "1" : "0";
  } else {
    str += "01";
    str += ".";
    str += "01";
    str += ".";
    str += "01";
    str += ".";
    str += "0";
  }
  const suffix = ".0.110.01.01.01.0";
  if (str.endsWith(suffix)) {
    str = str.slice(0, -suffix.length);
  }
  iterator.destroy();
  return str;
};

// src/containers/webm/traversal.ts
var getMainSegment = (segments) => {
  return segments.find((s) => s.type === "Segment");
};
var getTrackCodec = (track) => {
  const child = track.value.find((b) => b.type === "CodecID");
  return child ?? null;
};
var getTrackTimestampScale = (track) => {
  const child = track.value.find((b) => b.type === "TrackTimestampScale");
  if (!child) {
    return null;
  }
  if (child.type !== "TrackTimestampScale") {
    throw new Error("Expected TrackTimestampScale");
  }
  return child.value;
};
var getTrackId = (track) => {
  const trackId = track.value.find((b) => b.type === "TrackNumber");
  if (!trackId || trackId.type !== "TrackNumber") {
    throw new Error("Expected track number segment");
  }
  return trackId.value.value;
};
var getCodecSegment = (track) => {
  const codec = track.value.find((b) => b.type === "CodecID");
  if (!codec || codec.type !== "CodecID") {
    return null;
  }
  return codec;
};
var getColourSegment = (track) => {
  const videoSegment2 = getVideoSegment(track);
  if (!videoSegment2) {
    return null;
  }
  const colour = videoSegment2.value.find((b) => b.type === "Colour");
  if (!colour || colour.type !== "Colour") {
    return null;
  }
  return colour;
};
var getTransferCharacteristicsSegment = (color2) => {
  if (!color2 || color2.type !== "Colour") {
    return null;
  }
  const box = color2.value.find((b) => b.type === "TransferCharacteristics");
  if (!box || box.type !== "TransferCharacteristics") {
    return null;
  }
  return box;
};
var getMatrixCoefficientsSegment = (color2) => {
  if (!color2 || color2.type !== "Colour") {
    return null;
  }
  const box = color2.value.find((b) => b.type === "MatrixCoefficients");
  if (!box || box.type !== "MatrixCoefficients") {
    return null;
  }
  return box;
};
var getPrimariesSegment = (color2) => {
  if (!color2 || color2.type !== "Colour") {
    return null;
  }
  const box = color2.value.find((b) => b.type === "Primaries");
  if (!box || box.type !== "Primaries") {
    return null;
  }
  return box;
};
var getRangeSegment = (color2) => {
  if (!color2 || color2.type !== "Colour") {
    return null;
  }
  const box = color2.value.find((b) => b.type === "Range");
  if (!box || box.type !== "Range") {
    return null;
  }
  return box;
};
var getDisplayHeightSegment = (track) => {
  const videoSegment2 = getVideoSegment(track);
  if (!videoSegment2) {
    return null;
  }
  const displayHeight2 = videoSegment2.value.find((b) => b.type === "DisplayHeight");
  if (!displayHeight2 || displayHeight2.type !== "DisplayHeight") {
    return null;
  }
  return displayHeight2;
};
var getTrackTypeSegment = (track) => {
  const trackType2 = track.value.find((b) => b.type === "TrackType");
  if (!trackType2 || trackType2.type !== "TrackType") {
    return null;
  }
  return trackType2;
};
var getWidthSegment = (track) => {
  const videoSegment2 = getVideoSegment(track);
  if (!videoSegment2) {
    return null;
  }
  const width = videoSegment2.value.find((b) => b.type === "PixelWidth");
  if (!width || width.type !== "PixelWidth") {
    return null;
  }
  return width;
};
var getHeightSegment = (track) => {
  const videoSegment2 = getVideoSegment(track);
  if (!videoSegment2) {
    return null;
  }
  const height = videoSegment2.value.find((b) => b.type === "PixelHeight");
  if (!height || height.type !== "PixelHeight") {
    return null;
  }
  return height;
};
var getDisplayWidthSegment = (track) => {
  const videoSegment2 = getVideoSegment(track);
  if (!videoSegment2) {
    return null;
  }
  const displayWidth2 = videoSegment2.value.find((b) => b.type === "DisplayWidth");
  if (!displayWidth2 || displayWidth2.type !== "DisplayWidth") {
    return null;
  }
  return displayWidth2;
};
var getTracksSegment = (segment) => {
  const tracksSegment = segment.value.find((b) => b.type === "Tracks");
  if (!tracksSegment) {
    return null;
  }
  return tracksSegment;
};
var getTrackWithUid = (segment, trackUid) => {
  const tracksSegment = getTracksSegment(segment);
  if (!tracksSegment) {
    return null;
  }
  const trackEntries = tracksSegment.value.filter((t) => t.type === "TrackEntry");
  const trackEntry2 = trackEntries.find((entry) => {
    return entry?.value.find((t) => t.type === "TrackUID" && t.value === trackUid);
  });
  if (!trackEntry2) {
    return null;
  }
  return trackEntry2.value.find((t) => t.type === "TrackNumber")?.value.value ?? null;
};
var getVideoSegment = (track) => {
  const videoSegment2 = track.value.find((b) => b.type === "Video");
  if (!videoSegment2 || videoSegment2.type !== "Video") {
    return null;
  }
  return videoSegment2 ?? null;
};
var getAudioSegment = (track) => {
  const audioSegment2 = track.value.find((b) => b.type === "Audio");
  if (!audioSegment2 || audioSegment2.type !== "Audio") {
    return null;
  }
  return audioSegment2 ?? null;
};
var getSampleRate = (track) => {
  const audioSegment2 = getAudioSegment(track);
  if (!audioSegment2) {
    return null;
  }
  const samplingFrequency2 = audioSegment2.value.find((b) => b.type === "SamplingFrequency");
  if (!samplingFrequency2 || samplingFrequency2.type !== "SamplingFrequency") {
    return null;
  }
  return samplingFrequency2.value.value;
};
var getNumberOfChannels = (track) => {
  const audioSegment2 = getAudioSegment(track);
  if (!audioSegment2) {
    throw new Error("Could not find audio segment");
  }
  const channels2 = audioSegment2.value.find((b) => b.type === "Channels");
  if (!channels2 || channels2.type !== "Channels") {
    return 1;
  }
  return channels2.value.value;
};
var getBitDepth = (track) => {
  const audioSegment2 = getAudioSegment(track);
  if (!audioSegment2) {
    return null;
  }
  const bitDepth2 = audioSegment2.value.find((b) => b.type === "BitDepth");
  if (!bitDepth2 || bitDepth2.type !== "BitDepth") {
    return null;
  }
  return bitDepth2.value.value;
};
var getPrivateData = (track) => {
  const privateData = track.value.find((b) => b.type === "CodecPrivate");
  if (!privateData || privateData.type !== "CodecPrivate") {
    return null;
  }
  return privateData.value;
};

// src/containers/webm/color.ts
var parseColorSegment = (colourSegment) => {
  const transferCharacteristics2 = getTransferCharacteristicsSegment(colourSegment);
  const matrixCoefficients2 = getMatrixCoefficientsSegment(colourSegment);
  const primaries2 = getPrimariesSegment(colourSegment);
  const range2 = getRangeSegment(colourSegment);
  return {
    transferCharacteristics: transferCharacteristics2 ? transferCharacteristics2.value.value === 1 ? "bt709" : transferCharacteristics2.value.value === 6 ? "smpte170m" : transferCharacteristics2.value.value === 13 ? "iec61966-2-1" : null : null,
    matrixCoefficients: matrixCoefficients2 ? matrixCoefficients2.value.value === 1 ? "bt709" : matrixCoefficients2.value.value === 6 ? "smpte170m" : matrixCoefficients2.value.value === 5 ? "bt470bg" : null : null,
    primaries: primaries2 ? primaries2.value.value === 1 ? "bt709" : primaries2.value.value === 6 ? "smpte170m" : primaries2.value.value === 5 ? "bt470bg" : null : null,
    fullRange: transferCharacteristics2?.value.value && matrixCoefficients2?.value.value ? null : range2 ? Boolean(range2?.value.value) : null
  };
};

// src/containers/webm/description.ts
var getAudioDescription = (track) => {
  const codec = getCodecSegment(track);
  if (!codec || codec.value !== "A_VORBIS") {
    return;
  }
  const privateData = getPrivateData(track);
  if (!privateData) {
    return;
  }
  if (privateData[0] !== 2) {
    throw new Error("Expected vorbis private data version 2");
  }
  let offset = 1;
  let vorbisInfoLength = 0;
  let vorbisSkipLength = 0;
  while ((privateData[offset] & 255) === 255) {
    vorbisInfoLength += 255;
    offset++;
  }
  vorbisInfoLength += privateData[offset++] & 255;
  while ((privateData[offset] & 255) === 255) {
    vorbisSkipLength += 255;
    offset++;
  }
  vorbisSkipLength += privateData[offset++] & 255;
  if (privateData[offset] !== 1) {
    throw new Error("Error parsing vorbis codec private");
  }
  const vorbisInfo = privateData.slice(offset, offset + vorbisInfoLength);
  offset += vorbisInfoLength;
  if (privateData[offset] !== 3) {
    throw new Error("Error parsing vorbis codec private");
  }
  const vorbisComments = privateData.slice(offset, offset + vorbisSkipLength);
  offset += vorbisSkipLength;
  if (privateData[offset] !== 5) {
    throw new Error("Error parsing vorbis codec private");
  }
  const vorbisBooks = privateData.slice(offset);
  const bufferIterator = getArrayBufferIterator(vorbisInfo.slice(0), vorbisInfo.length);
  bufferIterator.getUint8();
  const vorbis = bufferIterator.getByteString(6, false);
  if (vorbis !== "vorbis") {
    throw new Error("Error parsing vorbis codec private");
  }
  const vorbisVersion = bufferIterator.getUint32Le();
  if (vorbisVersion !== 0) {
    throw new Error("Error parsing vorbis codec private");
  }
  const vorbisDescription = new Uint8Array([
    2,
    vorbisInfo.length,
    vorbisComments.length,
    ...vorbisInfo,
    ...vorbisComments,
    ...vorbisBooks
  ]);
  return vorbisDescription;
};

// src/containers/webm/segments/track-entry.ts
var trackTypeToString = (trackType2) => {
  switch (trackType2) {
    case 1:
      return "video";
    case 2:
      return "audio";
    case 3:
      return "complex";
    case 4:
      return "subtitle";
    case 5:
      return "button";
    case 6:
      return "control";
    case 7:
      return "metadata";
    default:
      throw new Error(`Unknown track type: ${trackType2}`);
  }
};

// src/containers/webm/make-track.ts
var getDescription = (track) => {
  const codec = getCodecSegment(track);
  if (!codec) {
    return;
  }
  if (codec.value === "V_MPEG4/ISO/AVC" || codec.value === "V_MPEGH/ISO/HEVC") {
    const priv = getPrivateData(track);
    if (priv) {
      return priv;
    }
  }
  return;
};
var getMatroskaVideoCodecWithoutConfigString = ({
  codecSegment: codec
}) => {
  if (codec.value === "V_VP8") {
    return "vp8";
  }
  if (codec.value === "V_VP9") {
    return "vp9";
  }
  if (codec.value === "V_MPEG4/ISO/AVC") {
    return "h264";
  }
  if (codec.value === "V_AV1") {
    return "av1";
  }
  if (codec.value === "V_MPEGH/ISO/HEVC") {
    return "h265";
  }
  throw new Error(`Unknown codec: ${codec.value}`);
};
var getMatroskaVideoCodecString = ({
  track,
  codecSegment: codec
}) => {
  if (codec.value === "V_VP8") {
    return "vp8";
  }
  if (codec.value === "V_VP9") {
    const priv = getPrivateData(track);
    if (priv) {
      throw new Error("@remotion/media-parser cannot handle the private data for VP9. Do you have an example file you could send so we can implement it?");
    }
    return "vp09.00.10.08";
  }
  if (codec.value === "V_MPEG4/ISO/AVC") {
    const priv = getPrivateData(track);
    if (priv) {
      return `avc1.${priv[1].toString(16).padStart(2, "0")}${priv[2].toString(16).padStart(2, "0")}${priv[3].toString(16).padStart(2, "0")}`;
    }
    throw new Error("Could not find a CodecPrivate field in TrackEntry");
  }
  if (codec.value === "V_AV1") {
    const priv = getPrivateData(track);
    if (!priv) {
      throw new Error("Expected private data in AV1 track");
    }
    return parseAv1PrivateData(priv, null);
  }
  if (codec.value === "V_MPEGH/ISO/HEVC") {
    const priv = getPrivateData(track);
    const iterator = getArrayBufferIterator(priv, priv.length);
    return "hvc1." + getHvc1CodecString(iterator);
  }
  throw new Error(`Unknown codec: ${codec.value}`);
};
var getMatroskaAudioCodecWithoutConfigString = ({
  track
}) => {
  const codec = getCodecSegment(track);
  if (!codec) {
    throw new Error("Expected codec segment");
  }
  if (codec.value === "A_OPUS") {
    return "opus";
  }
  if (codec.value === "A_VORBIS") {
    return "vorbis";
  }
  if (codec.value === "A_PCM/INT/LIT") {
    const bitDepth2 = getBitDepth(track);
    if (bitDepth2 === null) {
      throw new Error("Expected bit depth");
    }
    if (bitDepth2 === 8) {
      return "pcm-u8";
    }
    if (bitDepth2 === 16) {
      return "pcm-s16";
    }
    if (bitDepth2 === 24) {
      return "pcm-s24";
    }
    throw new Error("Unknown audio format");
  }
  if (codec.value === "A_AAC") {
    return `aac`;
  }
  if (codec.value === "A_MPEG/L3") {
    return "mp3";
  }
  throw new Error(`Unknown codec: ${codec.value}`);
};
var getMatroskaAudioCodecString = (track) => {
  const codec = getCodecSegment(track);
  if (!codec) {
    throw new Error("Expected codec segment");
  }
  if (codec.value === "A_OPUS") {
    return "opus";
  }
  if (codec.value === "A_VORBIS") {
    return "vorbis";
  }
  if (codec.value === "A_PCM/INT/LIT") {
    const bitDepth2 = getBitDepth(track);
    if (bitDepth2 === null) {
      throw new Error("Expected bit depth");
    }
    if (bitDepth2 === 8) {
      return "pcm-u8";
    }
    return "pcm-s" + bitDepth2;
  }
  if (codec.value === "A_AAC") {
    const priv = getPrivateData(track);
    const iterator = getArrayBufferIterator(priv, priv.length);
    iterator.startReadingBits();
    const profile = iterator.getBits(5);
    iterator.stopReadingBits();
    iterator.destroy();
    return `mp4a.40.${profile.toString().padStart(2, "0")}`;
  }
  if (codec.value === "A_MPEG/L3") {
    return "mp3";
  }
  throw new Error(`Unknown codec: ${codec.value}`);
};
var getTrack = ({
  timescale,
  track
}) => {
  const trackType2 = getTrackTypeSegment(track);
  if (!trackType2) {
    throw new Error("Expected track type segment");
  }
  const trackId = getTrackId(track);
  if (trackTypeToString(trackType2.value.value) === "video") {
    const width = getWidthSegment(track);
    if (width === null) {
      throw new Error("Expected width segment");
    }
    const height = getHeightSegment(track);
    if (height === null) {
      throw new Error("Expected height segment");
    }
    const displayHeight2 = getDisplayHeightSegment(track);
    const displayWidth2 = getDisplayWidthSegment(track);
    const codec = getCodecSegment(track);
    if (!codec) {
      return null;
    }
    const codecPrivate2 = getPrivateData(track);
    const codecString = getMatroskaVideoCodecString({
      track,
      codecSegment: codec
    });
    const colour = getColourSegment(track);
    if (!codecString) {
      return null;
    }
    return {
      type: "video",
      trackId,
      codec: codecString,
      description: getDescription(track),
      height: displayHeight2 ? displayHeight2.value.value : height.value.value,
      width: displayWidth2 ? displayWidth2.value.value : width.value.value,
      sampleAspectRatio: {
        numerator: 1,
        denominator: 1
      },
      timescale,
      codedHeight: height.value.value,
      codedWidth: width.value.value,
      displayAspectHeight: displayHeight2 ? displayHeight2.value.value : height.value.value,
      displayAspectWidth: displayWidth2 ? displayWidth2.value.value : width.value.value,
      rotation: 0,
      trakBox: null,
      codecPrivate: codecPrivate2,
      color: colour ? parseColorSegment(colour) : {
        fullRange: null,
        matrixCoefficients: null,
        primaries: null,
        transferCharacteristics: null
      },
      codecWithoutConfig: getMatroskaVideoCodecWithoutConfigString({
        codecSegment: codec
      }),
      fps: null
    };
  }
  if (trackTypeToString(trackType2.value.value) === "audio") {
    const sampleRate = getSampleRate(track);
    const numberOfChannels = getNumberOfChannels(track);
    const codecPrivate2 = getPrivateData(track);
    if (sampleRate === null) {
      throw new Error("Could not find sample rate or number of channels");
    }
    return {
      type: "audio",
      trackId,
      codec: getMatroskaAudioCodecString(track),
      timescale,
      numberOfChannels,
      sampleRate,
      description: getAudioDescription(track),
      trakBox: null,
      codecPrivate: codecPrivate2,
      codecWithoutConfig: getMatroskaAudioCodecWithoutConfigString({
        track
      })
    };
  }
  return null;
};

// src/containers/webm/get-ready-tracks.ts
var getTracksFromMatroska = (segment, timescale) => {
  const tracksSegment = getTracksSegment(segment);
  if (!tracksSegment) {
    throw new Error("No tracks segment");
  }
  const tracks2 = [];
  for (const trackEntrySegment of tracksSegment.value) {
    if (trackEntrySegment.type === "Crc32") {
      continue;
    }
    if (trackEntrySegment.type !== "TrackEntry") {
      throw new Error("Expected track entry segment");
    }
    const track = getTrack({
      track: trackEntrySegment,
      timescale
    });
    if (track) {
      tracks2.push(track);
    }
  }
  return tracks2;
};

// src/get-tracks.ts
var isoBaseMediaHasTracks = (state) => {
  return Boolean(getMoovBox(state));
};
var getHasTracks = (state) => {
  const structure = state.getStructure();
  if (structure.type === "matroska") {
    const mainSegment = getMainSegment(structure.boxes);
    if (!mainSegment) {
      return false;
    }
    return getTracksSegment(mainSegment) !== null;
  }
  if (structure.type === "iso-base-media") {
    return isoBaseMediaHasTracks(state);
  }
  if (structure.type === "riff") {
    return hasAllTracksFromAvi(state);
  }
  if (structure.type === "transport-stream") {
    return hasAllTracksFromTransportStream(state);
  }
  if (structure.type === "mp3") {
    return state.callbacks.tracks.getTracks().length > 0;
  }
  if (structure.type === "wav") {
    return state.callbacks.tracks.hasAllTracks();
  }
  if (structure.type === "aac") {
    return state.callbacks.tracks.hasAllTracks();
  }
  if (structure.type === "flac") {
    return state.callbacks.tracks.hasAllTracks();
  }
  throw new Error("Unknown container " + structure);
};
var getTracksFromMa = (segments, state) => {
  const videoTracks = [];
  const audioTracks = [];
  const otherTracks = [];
  const mainSegment = segments.find((s) => s.type === "Segment");
  if (!mainSegment) {
    throw new Error("No main segment found");
  }
  const matroskaTracks = getTracksFromMatroska(mainSegment, state.webm.getTimescale());
  for (const track of matroskaTracks) {
    if (track.type === "video") {
      videoTracks.push(track);
    } else if (track.type === "audio") {
      audioTracks.push(track);
    } else if (track.type === "other") {
      otherTracks.push(track);
    }
  }
  return {
    videoTracks,
    audioTracks,
    otherTracks
  };
};
var getTracksFromIsoBaseMedia = (state) => {
  const videoTracks = [];
  const audioTracks = [];
  const otherTracks = [];
  const moovBox = getMoovBox(state);
  if (!moovBox) {
    return {
      videoTracks,
      audioTracks,
      otherTracks
    };
  }
  const tracks2 = getTraks(moovBox);
  for (const trakBox of tracks2) {
    const track = makeBaseMediaTrack(trakBox);
    if (!track) {
      continue;
    }
    if (track.type === "video") {
      videoTracks.push(track);
    } else if (track.type === "audio") {
      audioTracks.push(track);
    } else if (track.type === "other") {
      otherTracks.push(track);
    }
  }
  return {
    videoTracks,
    audioTracks,
    otherTracks
  };
};
var getTracks = (state) => {
  const structure = state.getStructure();
  if (structure.type === "matroska") {
    return getTracksFromMa(structure.boxes, state);
  }
  if (structure.type === "iso-base-media") {
    return getTracksFromIsoBaseMedia(state);
  }
  if (structure.type === "riff") {
    return getTracksFromAvi(structure, state);
  }
  if (structure.type === "transport-stream") {
    return getTracksFromTransportStream(state);
  }
  if (structure.type === "mp3" || structure.type === "wav" || structure.type === "flac" || structure.type === "aac") {
    return getTracksFromMp3OrWavOrAac(state);
  }
  throw new Error(`Unknown container${structure}`);
};

// src/get-audio-codec.ts
var getAudioCodec = (parserState) => {
  const tracks2 = getTracks(parserState);
  const allTracks = tracks2.audioTracks.length + tracks2.otherTracks.length + tracks2.videoTracks.length;
  if (allTracks === 0) {
    throw new Error("No tracks yet");
  }
  const audioTrack = tracks2.audioTracks[0];
  if (!audioTrack) {
    return null;
  }
  if (audioTrack.type === "audio") {
    return audioTrack.codecWithoutConfig;
  }
  return null;
};
var hasAudioCodec = (state) => {
  return getHasTracks(state);
};
var getCodecSpecificatorFromEsdsBox = ({
  child
}) => {
  const descriptor = child.descriptors.find((d) => d.type === "decoder-config-descriptor");
  if (!descriptor) {
    throw new Error("No decoder-config-descriptor");
  }
  if (descriptor.type !== "decoder-config-descriptor") {
    throw new Error("Expected decoder-config-descriptor");
  }
  if (descriptor.asNumber !== 64) {
    return {
      primary: descriptor.asNumber,
      secondary: null,
      description: undefined
    };
  }
  const audioSpecificConfig = descriptor.decoderSpecificConfigs.find((d) => {
    return d.type === "mp4a-specific-config" ? d : null;
  });
  if (!audioSpecificConfig || audioSpecificConfig.type !== "mp4a-specific-config") {
    throw new Error("No audio-specific-config");
  }
  return {
    primary: descriptor.asNumber,
    secondary: audioSpecificConfig.audioObjectType,
    description: audioSpecificConfig.asBytes
  };
};
var getCodecPrivateFromTrak = (trakBox) => {
  const stsdBox = getStsdBox(trakBox);
  if (!stsdBox) {
    return null;
  }
  const audioSample = stsdBox.samples.find((s) => s.type === "audio");
  if (!audioSample || audioSample.type !== "audio") {
    return null;
  }
  const esds = audioSample.children.find((b) => b.type === "esds-box");
  if (!esds || esds.type !== "esds-box") {
    return null;
  }
  const decoderConfigDescriptor = esds.descriptors.find((d) => d.type === "decoder-config-descriptor");
  if (!decoderConfigDescriptor) {
    return null;
  }
  const mp4a = decoderConfigDescriptor.decoderSpecificConfigs.find((d) => d.type === "mp4a-specific-config");
  if (!mp4a) {
    return null;
  }
  return mp4a.asBytes;
};
var onSample = (sample, children) => {
  const child = children.find((c) => c.type === "esds-box");
  if (child && child.type === "esds-box") {
    const ret = getCodecSpecificatorFromEsdsBox({ child });
    return {
      format: sample.format,
      primarySpecificator: ret.primary,
      secondarySpecificator: ret.secondary,
      description: ret.description
    };
  }
  return {
    format: sample.format,
    primarySpecificator: null,
    secondarySpecificator: null,
    description: undefined
  };
};
var getNumberOfChannelsFromTrak = (trak) => {
  const stsdBox = getStsdBox(trak);
  if (!stsdBox) {
    return null;
  }
  const sample = stsdBox.samples.find((s) => s.type === "audio");
  if (!sample || sample.type !== "audio") {
    return null;
  }
  return sample.numberOfChannels;
};
var getSampleRate2 = (trak) => {
  const stsdBox = getStsdBox(trak);
  if (!stsdBox) {
    return null;
  }
  const sample = stsdBox.samples.find((s) => s.type === "audio");
  if (!sample || sample.type !== "audio") {
    return null;
  }
  return sample.sampleRate;
};
var getAudioCodecFromTrak = (trak) => {
  const stsdBox = getStsdBox(trak);
  if (!stsdBox) {
    return null;
  }
  const sample = stsdBox.samples.find((s) => s.type === "audio");
  if (!sample || sample.type !== "audio") {
    return null;
  }
  const waveBox = sample.children.find((b) => b.type === "regular-box" && b.boxType === "wave");
  if (waveBox && waveBox.type === "regular-box" && waveBox.boxType === "wave") {
    const esdsSample = onSample(sample, waveBox.children);
    if (esdsSample) {
      return esdsSample;
    }
  }
  const ret = onSample(sample, sample.children);
  if (ret) {
    return ret;
  }
  return null;
};
var isLpcmAudioCodec = (trak) => {
  return getAudioCodecFromTrak(trak)?.format === "lpcm";
};
var getAudioCodecStringFromTrak = (trak) => {
  const codec = getAudioCodecFromTrak(trak);
  if (!codec) {
    throw new Error("Expected codec");
  }
  if (codec.format === "lpcm") {
    return {
      codecString: "pcm-s16",
      description: codec.description
    };
  }
  const codecStringWithoutMp3Exception = [
    codec.format,
    codec.primarySpecificator ? codec.primarySpecificator.toString(16) : null,
    codec.secondarySpecificator ? codec.secondarySpecificator.toString().padStart(2, "0") : null
  ].filter(Boolean).join(".");
  const codecString = codecStringWithoutMp3Exception === "mp4a.6b" ? "mp3" : codecStringWithoutMp3Exception;
  return {
    codecString,
    description: codec.description
  };
};
var getAudioCodecFromAudioCodecInfo = (codec) => {
  if (codec.format === "twos") {
    return "pcm-s16";
  }
  if (codec.format === "lpcm") {
    return "pcm-s16";
  }
  if (codec.format === "sowt") {
    return "aiff";
  }
  if (codec.format === "ac-3") {
    return "ac3";
  }
  if (codec.format === "mp4a") {
    if (codec.primarySpecificator === 64) {
      return "aac";
    }
    if (codec.primarySpecificator === 107) {
      return "mp3";
    }
    if (codec.primarySpecificator === null) {
      return "aac";
    }
    throw new Error("Unknown mp4a codec: " + codec.primarySpecificator);
  }
  throw new Error(`Unknown audio format: ${codec.format}`);
};
var getAudioCodecFromTrack = (track) => {
  const audioSample = getAudioCodecFromTrak(track);
  if (!audioSample) {
    throw new Error("Could not find audio sample");
  }
  return getAudioCodecFromAudioCodecInfo(audioSample);
};

// src/get-sample-aspect-ratio.ts
var getStsdVideoConfig = (trakBox) => {
  const stsdBox = getStsdBox(trakBox);
  if (!stsdBox) {
    return null;
  }
  const videoConfig = stsdBox.samples.find((s) => s.type === "video");
  if (!videoConfig || videoConfig.type !== "video") {
    return null;
  }
  return videoConfig;
};
var getAvccBox = (trakBox) => {
  const videoConfig = getStsdVideoConfig(trakBox);
  if (!videoConfig) {
    return null;
  }
  const avccBox = videoConfig.descriptors.find((c) => c.type === "avcc-box");
  if (!avccBox || avccBox.type !== "avcc-box") {
    return null;
  }
  return avccBox;
};
var getAv1CBox = (trakBox) => {
  const videoConfig = getStsdVideoConfig(trakBox);
  if (!videoConfig) {
    return null;
  }
  const av1cBox = videoConfig.descriptors.find((c) => c.type === "av1C-box");
  if (!av1cBox || av1cBox.type !== "av1C-box") {
    return null;
  }
  return av1cBox;
};
var getPaspBox = (trakBox) => {
  const videoConfig = getStsdVideoConfig(trakBox);
  if (!videoConfig) {
    return null;
  }
  const paspBox = videoConfig.descriptors.find((c) => c.type === "pasp-box");
  if (!paspBox || paspBox.type !== "pasp-box") {
    return null;
  }
  return paspBox;
};
var getHvccBox = (trakBox) => {
  const videoConfig = getStsdVideoConfig(trakBox);
  if (!videoConfig) {
    return null;
  }
  const hvccBox = videoConfig.descriptors.find((c) => c.type === "hvcc-box");
  if (!hvccBox || hvccBox.type !== "hvcc-box") {
    return null;
  }
  return hvccBox;
};
var getSampleAspectRatio = (trakBox) => {
  const paspBox = getPaspBox(trakBox);
  if (!paspBox) {
    return {
      numerator: 1,
      denominator: 1
    };
  }
  return {
    numerator: paspBox.hSpacing,
    denominator: paspBox.vSpacing
  };
};
var getColrBox = (videoSample) => {
  const colrBox = videoSample.descriptors.find((c) => c.type === "colr-box");
  if (!colrBox || colrBox.type !== "colr-box") {
    return null;
  }
  return colrBox;
};
var applyTkhdBox = (aspectRatioApplied, tkhdBox) => {
  if (tkhdBox === null || tkhdBox.rotation === 0) {
    return {
      displayAspectWidth: aspectRatioApplied.width,
      displayAspectHeight: aspectRatioApplied.height,
      width: aspectRatioApplied.width,
      height: aspectRatioApplied.height,
      rotation: 0
    };
  }
  return {
    width: tkhdBox.width,
    height: tkhdBox.height,
    rotation: tkhdBox.rotation,
    displayAspectWidth: aspectRatioApplied.width,
    displayAspectHeight: aspectRatioApplied.height
  };
};
var applyAspectRatios = ({
  dimensions,
  sampleAspectRatio,
  displayAspectRatio
}) => {
  if (displayAspectRatio.numerator === 0) {
    return dimensions;
  }
  if (displayAspectRatio.denominator === 0) {
    return dimensions;
  }
  const newWidth = Math.round(dimensions.width * sampleAspectRatio.numerator / sampleAspectRatio.denominator);
  const newHeight = Math.floor(newWidth / (displayAspectRatio.numerator / displayAspectRatio.denominator));
  return {
    width: Math.floor(newWidth),
    height: newHeight
  };
};
function gcd(a, b) {
  return b === 0 ? a : gcd(b, a % b);
}
function reduceFraction(numerator, denominator) {
  const greatestCommonDivisor = gcd(Math.abs(numerator), Math.abs(denominator));
  return {
    numerator: numerator / greatestCommonDivisor,
    denominator: denominator / greatestCommonDivisor
  };
}
var getDisplayAspectRatio = ({
  sampleAspectRatio,
  nativeDimensions
}) => {
  const num = Math.round(nativeDimensions.width * sampleAspectRatio.numerator);
  const den = Math.round(nativeDimensions.height * sampleAspectRatio.denominator);
  return reduceFraction(num, den);
};

// src/containers/avc/color.ts
var getMatrixCoefficientsFromIndex = (index) => {
  return index === 1 ? "bt709" : index === 5 ? "bt470bg" : index === 6 ? "smpte170m" : index === 9 ? "bt2020" : null;
};
var getTransferCharacteristicsFromIndex = (index) => {
  return index === 1 ? "bt709" : index === 6 ? "smpte170m" : index === 13 ? "iec61966-2-1" : index === 18 ? "arib-std-b67" : null;
};
var getPrimariesFromIndex = (index) => {
  return index === 1 ? "bt709" : index === 5 ? "bt470bg" : index === 6 ? "smpte170m" : index === 9 ? "bt2020" : null;
};

// src/get-video-codec.ts
var getVideoCodec = (state) => {
  const track = getTracks(state);
  return track.videoTracks[0]?.codecWithoutConfig ?? null;
};
var hasVideoCodec = (state) => {
  return getHasTracks(state);
};
var getVideoPrivateData = (trakBox) => {
  const videoSample = getStsdVideoConfig(trakBox);
  const avccBox = getAvccBox(trakBox);
  const hvccBox = getHvccBox(trakBox);
  const av1cBox = getAv1CBox(trakBox);
  if (!videoSample) {
    return null;
  }
  if (avccBox) {
    return avccBox.privateData;
  }
  if (hvccBox) {
    return hvccBox.privateData;
  }
  if (av1cBox) {
    return av1cBox.privateData;
  }
  return null;
};
var getIsoBmColrConfig = (trakBox) => {
  const videoSample = getStsdVideoConfig(trakBox);
  if (!videoSample) {
    return null;
  }
  const colrAtom = getColrBox(videoSample);
  if (!colrAtom) {
    return null;
  }
  if (colrAtom.colorType !== "transfer-characteristics") {
    return null;
  }
  return {
    fullRange: colrAtom.fullRangeFlag,
    matrixCoefficients: getMatrixCoefficientsFromIndex(colrAtom.matrixIndex),
    primaries: getPrimariesFromIndex(colrAtom.primaries),
    transferCharacteristics: getTransferCharacteristicsFromIndex(colrAtom.transfer)
  };
};
var getVideoCodecString = (trakBox) => {
  const videoSample = getStsdVideoConfig(trakBox);
  const avccBox = getAvccBox(trakBox);
  const hvccBox = getHvccBox(trakBox);
  const av1cBox = getAv1CBox(trakBox);
  if (!videoSample) {
    return null;
  }
  if (avccBox) {
    return `${videoSample.format}.${avccBox.configurationString}`;
  }
  if (hvccBox) {
    return `${videoSample.format}.${hvccBox.configurationString}`;
  }
  if (av1cBox) {
    const colrAtom = getColrBox(videoSample);
    return parseAv1PrivateData(av1cBox.privateData, colrAtom);
  }
  return videoSample.format;
};

// src/containers/iso-base-media/get-actual-number-of-channels.ts
var getActualDecoderParameters = ({
  audioCodec,
  codecPrivate: codecPrivate2,
  numberOfChannels,
  sampleRate
}) => {
  if (audioCodec !== "aac") {
    return { numberOfChannels, sampleRate, codecPrivate: codecPrivate2 };
  }
  if (codecPrivate2 === null) {
    return { numberOfChannels, sampleRate, codecPrivate: codecPrivate2 };
  }
  const parsed = parseAacCodecPrivate(codecPrivate2);
  return {
    numberOfChannels: parsed.channelConfiguration,
    sampleRate: parsed.sampleRate,
    codecPrivate: createAacCodecPrivate({ ...parsed, codecPrivate: codecPrivate2 })
  };
};

// src/containers/iso-base-media/get-video-codec-from-iso-track.ts
var getVideoCodecFromIsoTrak = (trakBox) => {
  const stsdBox = getStsdBox(trakBox);
  if (stsdBox && stsdBox.type === "stsd-box") {
    const videoSample = stsdBox.samples.find((s) => s.type === "video");
    if (videoSample && videoSample.type === "video") {
      if (videoSample.format === "hvc1" || videoSample.format === "hev1") {
        return "h265";
      }
      if (videoSample.format === "avc1") {
        return "h264";
      }
      if (videoSample.format === "av01") {
        return "av1";
      }
      if (videoSample.format === "ap4h") {
        return "prores";
      }
      if (videoSample.format === "ap4x") {
        return "prores";
      }
      if (videoSample.format === "apch") {
        return "prores";
      }
      if (videoSample.format === "apcn") {
        return "prores";
      }
      if (videoSample.format === "apcs") {
        return "prores";
      }
      if (videoSample.format === "apco") {
        return "prores";
      }
      if (videoSample.format === "aprh") {
        return "prores";
      }
      if (videoSample.format === "aprn") {
        return "prores";
      }
    }
  }
  throw new Error("Could not find video codec");
};

// src/containers/iso-base-media/make-track.ts
var makeBaseMediaTrack = (trakBox) => {
  const tkhdBox = getTkhdBox(trakBox);
  const videoDescriptors = getVideoDescriptors(trakBox);
  const timescaleAndDuration = getTimescaleAndDuration(trakBox);
  if (!tkhdBox) {
    throw new Error("Expected tkhd box in trak box");
  }
  if (!timescaleAndDuration) {
    throw new Error("Expected timescale and duration in trak box");
  }
  if (trakBoxContainsAudio(trakBox)) {
    const numberOfChannels = getNumberOfChannelsFromTrak(trakBox);
    if (numberOfChannels === null) {
      throw new Error("Could not find number of channels");
    }
    const sampleRate = getSampleRate2(trakBox);
    if (sampleRate === null) {
      throw new Error("Could not find sample rate");
    }
    const { codecString, description } = getAudioCodecStringFromTrak(trakBox);
    const codecPrivate2 = getCodecPrivateFromTrak(trakBox) ?? description ?? null;
    const codecWithoutConfig = getAudioCodecFromTrack(trakBox);
    const actual = getActualDecoderParameters({
      audioCodec: codecWithoutConfig,
      codecPrivate: codecPrivate2,
      numberOfChannels,
      sampleRate
    });
    return {
      type: "audio",
      trackId: tkhdBox.trackId,
      timescale: timescaleAndDuration.timescale,
      codec: codecString,
      numberOfChannels: actual.numberOfChannels,
      sampleRate: actual.sampleRate,
      description: actual.codecPrivate ?? undefined,
      trakBox,
      codecPrivate: actual.codecPrivate,
      codecWithoutConfig
    };
  }
  if (!trakBoxContainsVideo(trakBox)) {
    return {
      type: "other",
      trackId: tkhdBox.trackId,
      timescale: timescaleAndDuration.timescale,
      trakBox
    };
  }
  const videoSample = getStsdVideoConfig(trakBox);
  if (!videoSample) {
    throw new Error("No video sample");
  }
  const sampleAspectRatio = getSampleAspectRatio(trakBox);
  const aspectRatioApplied = applyAspectRatios({
    dimensions: videoSample,
    sampleAspectRatio,
    displayAspectRatio: getDisplayAspectRatio({
      sampleAspectRatio,
      nativeDimensions: videoSample
    })
  });
  const { displayAspectHeight, displayAspectWidth, height, rotation, width } = applyTkhdBox(aspectRatioApplied, tkhdBox);
  const codec = getVideoCodecString(trakBox);
  if (!codec) {
    throw new Error("Could not find video codec");
  }
  const privateData = getVideoPrivateData(trakBox);
  const track = {
    type: "video",
    trackId: tkhdBox.trackId,
    description: videoDescriptors ?? undefined,
    timescale: timescaleAndDuration.timescale,
    codec,
    sampleAspectRatio: getSampleAspectRatio(trakBox),
    width,
    height,
    codedWidth: videoSample.width,
    codedHeight: videoSample.height,
    displayAspectWidth,
    displayAspectHeight,
    rotation,
    trakBox,
    codecPrivate: privateData,
    color: getIsoBmColrConfig(trakBox) ?? {
      fullRange: null,
      matrixCoefficients: null,
      primaries: null,
      transferCharacteristics: null
    },
    codecWithoutConfig: getVideoCodecFromIsoTrak(trakBox),
    fps: getFpsFromMp4TrakBox(trakBox)
  };
  return track;
};

// src/containers/iso-base-media/mdhd.ts
var parseMdhd = ({
  data,
  size,
  fileOffset
}) => {
  const version = data.getUint8();
  data.discard(3);
  const creationTime = version === 1 ? Number(data.getUint64()) : data.getUint32();
  const modificationTime = version === 1 ? Number(data.getUint64()) : data.getUint32();
  const timescale = data.getUint32();
  const duration2 = version === 1 ? data.getUint64() : data.getUint32();
  const language2 = data.getUint16();
  const quality = data.getUint16();
  const remaining = size - (data.counter.getOffset() - fileOffset);
  if (remaining !== 0) {
    throw new Error(`Expected remaining bytes to be 0, got ${remaining}`);
  }
  return {
    type: "mdhd-box",
    duration: Number(duration2),
    timescale,
    version,
    language: language2,
    quality,
    creationTime,
    modificationTime
  };
};

// src/containers/iso-base-media/meta/hdlr.ts
var parseHdlr = ({
  iterator,
  size,
  offset
}) => {
  const box = iterator.startBox(size - 8);
  const version = iterator.getUint8();
  if (version !== 0) {
    throw new Error(`Unsupported hdlr version: ${version}`);
  }
  iterator.discard(3);
  iterator.discard(4);
  const hdlrType = iterator.getByteString(4, false);
  iterator.discard(4);
  iterator.discard(4);
  iterator.discard(4);
  const componentName = iterator.readUntilNullTerminator();
  box.discardRest();
  return Promise.resolve({
    type: "hdlr-box",
    boxSize: size,
    offset,
    hdlrType,
    componentName
  });
};

// src/containers/iso-base-media/meta/ilst.ts
var parseFromWellKnownType = (wellKnownType, iterator, size) => {
  if (wellKnownType === 1) {
    const value = iterator.getByteString(size, false);
    return { type: "text", value };
  }
  if (wellKnownType === 21) {
    if (size === 1) {
      return { type: "number", value: iterator.getInt8() };
    }
    if (size === 2) {
      return { type: "number", value: iterator.getInt16() };
    }
    if (size === 3) {
      return { type: "number", value: iterator.getInt24() };
    }
    if (size === 4) {
      return { type: "number", value: iterator.getInt32() };
    }
    if (size === 8) {
      return { type: "number", value: Number(iterator.getInt64()) };
    }
    throw new Error(`Weird size for number ${size}`);
  }
  if (wellKnownType === 22) {
    if (size === 1) {
      return { type: "number", value: iterator.getUint8() };
    }
    if (size === 2) {
      return { type: "number", value: iterator.getUint16() };
    }
    if (size === 3) {
      return { type: "number", value: iterator.getUint24() };
    }
    if (size === 4) {
      return { type: "number", value: iterator.getUint32() };
    }
    throw new Error(`Weird size for number ${size}`);
  }
  if (wellKnownType === 23) {
    if (size === 4) {
      return { type: "number", value: iterator.getFloat32() };
    }
    if (size === 8) {
      return { type: "number", value: iterator.getFloat64() };
    }
    throw new Error(`Weird size for number ${size}`);
  }
  iterator.discard(size);
  return { type: "unknown", value: null };
};
var parseIlstBox = ({
  iterator,
  size,
  offset
}) => {
  const box = iterator.startBox(size - 8);
  const entries = [];
  while (iterator.counter.getOffset() < size + offset) {
    const metadataSize = iterator.getUint32();
    const index = iterator.getUint32();
    if (index === 1936419184) {
      iterator.discard(metadataSize - 8);
      continue;
    }
    const innerSize = iterator.getUint32();
    const type = iterator.getAtom();
    const typeIndicator = iterator.getUint8();
    if (typeIndicator !== 0) {
      throw new Error("Expected type indicator to be 0");
    }
    const wellKnownType = iterator.getUint24();
    iterator.discard(4);
    const value = parseFromWellKnownType(wellKnownType, iterator, innerSize - 16);
    entries.push({ index, type, wellKnownType, value });
  }
  box.discardRest();
  return {
    type: "ilst-box",
    boxSize: size,
    offset,
    entries
  };
};

// src/containers/iso-base-media/moov/moov.ts
var parseMoov = async ({
  offset,
  size,
  state
}) => {
  const children = await getIsoBaseMediaChildren({
    state,
    size: size - 8
  });
  return {
    offset,
    boxSize: size,
    type: "moov-box",
    children
  };
};

// src/containers/iso-base-media/stsd/av1c.ts
var parseAv1C = ({
  data,
  size
}) => {
  return {
    type: "av1C-box",
    privateData: data.getSlice(size - 8)
  };
};

// src/containers/iso-base-media/stsd/avcc.ts
var parseAvcc = ({
  data,
  size
}) => {
  const confVersion = data.getUint8();
  if (confVersion !== 1) {
    throw new Error(`Unsupported AVCC version ${confVersion}`);
  }
  const profile = data.getUint8();
  const profileCompatibility = data.getUint8();
  const level = data.getUint8();
  const str = `${profile.toString(16).padStart(2, "0")}${profileCompatibility.toString(16).padStart(2, "0")}${level.toString(16).padStart(2, "0")}`;
  data.counter.decrement(4);
  const privateData = data.getSlice(size - 8);
  return {
    type: "avcc-box",
    privateData,
    configurationString: str
  };
};

// src/containers/iso-base-media/parse-icc-profile.ts
var parseIccProfile = (data) => {
  const iterator = getArrayBufferIterator(data, Infinity);
  const size = iterator.getUint32();
  if (size !== data.length) {
    throw new Error("Invalid ICC profile size");
  }
  const preferredCMMType = iterator.getByteString(4, false);
  const profileVersion = iterator.getByteString(4, false);
  const profileDeviceClass = iterator.getByteString(4, false);
  const colorSpace = iterator.getByteString(4, false);
  const pcs = iterator.getByteString(4, false);
  const dateTime = iterator.getSlice(12);
  const signature = iterator.getByteString(4, false);
  if (signature !== "acsp") {
    throw new Error("Invalid ICC profile signature");
  }
  const primaryPlatform = iterator.getByteString(4, false);
  const profileFlags = iterator.getUint32();
  const deviceManufacturer = iterator.getByteString(4, false);
  const deviceModel = iterator.getByteString(4, false);
  const deviceAttributes = iterator.getUint64();
  const renderingIntent = iterator.getUint32();
  const pcsIlluminant1 = iterator.getUint32();
  const pcsIlluminant2 = iterator.getUint32();
  const pcsIlluminant3 = iterator.getUint32();
  const profileCreator = iterator.getByteString(4, false);
  const profileId = iterator.getByteString(16, false);
  iterator.discard(28);
  const tagCount = iterator.getUint32();
  const entries = [];
  for (let i = 0;i < tagCount; i++) {
    const entry = {
      tag: iterator.getByteString(4, false),
      offset: iterator.getUint32(),
      size: iterator.getUint32()
    };
    entries.push(entry);
  }
  let lastOffset = -1;
  let rXYZ = null;
  let gXYZ = null;
  let bXYZ = null;
  let whitePoint = null;
  for (const entry of entries) {
    const found = data.slice(entry.offset, entry.offset + entry.size);
    if (entry.tag === "rXYZ" || entry.tag === "gXYZ" || entry.tag === "bXYZ" || entry.tag === "wtpt") {
      const it = getArrayBufferIterator(found, Infinity);
      it.discard(4);
      const x = it.getInt32() / 65536;
      const y = it.getInt32() / 65536;
      const z = it.getInt32() / 65536;
      it.destroy();
      const point = { x, y, z };
      if (entry.tag === "rXYZ") {
        rXYZ = point;
      } else if (entry.tag === "gXYZ") {
        gXYZ = point;
      } else if (entry.tag === "bXYZ") {
        bXYZ = point;
      } else if (entry.tag === "wtpt") {
        whitePoint = point;
      }
    }
    if (lastOffset !== -1) {
      const bytesToAdvance = entry.offset - lastOffset;
      const bytesToGoBackwards = entry.size - bytesToAdvance;
      if (bytesToGoBackwards > 0) {
        iterator.counter.decrement(bytesToGoBackwards);
      }
    }
    lastOffset = entry.offset;
  }
  const profile = {
    size,
    preferredCMMType,
    profileVersion,
    profileDeviceClass,
    colorSpace,
    pcs,
    dateTime,
    signature,
    primaryPlatform,
    profileFlags,
    deviceManufacturer,
    deviceModel,
    deviceAttributes,
    renderingIntent,
    pcsIlluminant: [
      pcsIlluminant1 / 65536,
      pcsIlluminant2 / 65536,
      pcsIlluminant3 / 65536
    ],
    profileCreator,
    profileId,
    entries,
    bXYZ,
    gXYZ,
    rXYZ,
    whitePoint
  };
  iterator.destroy();
  return profile;
};

// src/containers/iso-base-media/stsd/colr.ts
var parseColorParameterBox = ({
  iterator,
  size
}) => {
  const byteString = iterator.getByteString(4, false);
  if (byteString === "nclx") {
    const primaries2 = iterator.getUint16();
    const transfer = iterator.getUint16();
    const matrixIndex = iterator.getUint16();
    iterator.startReadingBits();
    const fullRangeFlag = Boolean(iterator.getBits(1));
    iterator.stopReadingBits();
    return {
      type: "colr-box",
      colorType: "transfer-characteristics",
      fullRangeFlag,
      matrixIndex,
      primaries: primaries2,
      transfer
    };
  }
  if (byteString === "nclc") {
    const primaries2 = iterator.getUint16();
    const transfer = iterator.getUint16();
    const matrixIndex = iterator.getUint16();
    return {
      type: "colr-box",
      colorType: "transfer-characteristics",
      fullRangeFlag: false,
      matrixIndex,
      primaries: primaries2,
      transfer
    };
  }
  if (byteString === "prof") {
    const profile = iterator.getSlice(size - 12);
    return {
      type: "colr-box",
      colorType: "icc-profile",
      profile,
      parsed: parseIccProfile(profile)
    };
  }
  throw new Error("Unexpected box type " + byteString);
};

// src/containers/iso-base-media/stsd/ctts.ts
var parseCtts = ({
  iterator,
  offset,
  size
}) => {
  const version = iterator.getUint8();
  if (version !== 0 && version !== 1) {
    throw new Error(`Unsupported CTTS version ${version}`);
  }
  const flags = iterator.getSlice(3);
  const entryCount = iterator.getUint32();
  const entries = [];
  for (let i = 0;i < entryCount; i++) {
    const sampleCount = iterator.getUint32();
    const sampleOffset = iterator.getInt32();
    entries.push({
      sampleCount,
      sampleOffset
    });
  }
  return {
    type: "ctts-box",
    boxSize: size,
    offset,
    version,
    flags: [...flags],
    entryCount,
    entries
  };
};

// src/containers/iso-base-media/stsd/hvcc.ts
var parseHvcc = ({
  data,
  size,
  offset
}) => {
  const privateData = data.getSlice(size - 8);
  data.counter.decrement(size - 8);
  const constraintString = getHvc1CodecString(data);
  const remaining = size - (data.counter.getOffset() - offset);
  data.discard(remaining);
  return {
    type: "hvcc-box",
    privateData,
    configurationString: constraintString
  };
};

// src/containers/iso-base-media/stsd/keys.ts
var parseKeys = ({
  iterator,
  offset,
  size
}) => {
  const box = iterator.startBox(size - 8);
  const version = iterator.getUint8();
  iterator.discard(3);
  const entryCount = iterator.getUint32();
  const entries = [];
  for (let i = 0;i < entryCount; i++) {
    const keySize = iterator.getUint32();
    const namespace = iterator.getAtom();
    const value = iterator.getByteString(keySize - 8, false);
    const entry = {
      keySize,
      namespace,
      value
    };
    entries.push(entry);
  }
  box.discardRest();
  return {
    type: "keys-box",
    boxSize: size,
    offset,
    version,
    entryCount,
    entries
  };
};

// src/containers/iso-base-media/stsd/mebx.ts
var parseMebx = async ({
  offset,
  size,
  state
}) => {
  state.iterator.discard(6);
  const dataReferenceIndex = state.iterator.getUint16();
  const children = await getIsoBaseMediaChildren({
    state,
    size: size - 8
  });
  return {
    type: "mebx-box",
    boxSize: size,
    offset,
    dataReferenceIndex,
    format: "mebx",
    children
  };
};

// src/containers/iso-base-media/stsd/pasp.ts
var parsePasp = ({
  iterator,
  offset,
  size
}) => {
  const hSpacing = iterator.getUint32();
  const vSpacing = iterator.getUint32();
  const bytesRemainingInBox = size - (iterator.counter.getOffset() - offset);
  iterator.discard(bytesRemainingInBox);
  return {
    type: "pasp-box",
    boxSize: size,
    offset,
    hSpacing,
    vSpacing
  };
};

// src/containers/iso-base-media/stsd/stco.ts
var parseStco = ({
  iterator,
  offset,
  size,
  mode64Bit
}) => {
  const version = iterator.getUint8();
  if (version !== 0) {
    throw new Error(`Unsupported STSD version ${version}`);
  }
  const flags = iterator.getSlice(3);
  const entryCount = iterator.getUint32();
  const entries = [];
  for (let i = 0;i < entryCount; i++) {
    const bytesRemaining = size - (iterator.counter.getOffset() - offset);
    if (bytesRemaining < 4) {
      break;
    }
    entries.push(mode64Bit ? iterator.getUint64() : iterator.getUint32());
  }
  iterator.discard(size - (iterator.counter.getOffset() - offset));
  return {
    type: "stco-box",
    boxSize: size,
    offset,
    version,
    flags: [...flags],
    entries,
    entryCount
  };
};

// src/containers/iso-base-media/stsd/stsc.ts
var parseStsc = ({
  iterator,
  offset,
  size
}) => {
  const version = iterator.getUint8();
  if (version !== 0) {
    throw new Error(`Unsupported STSD version ${version}`);
  }
  const flags = iterator.getSlice(3);
  const entryCount = iterator.getUint32();
  const entries = [];
  for (let i = 0;i < entryCount; i++) {
    const firstChunk = iterator.getUint32();
    const samplesPerChunk = iterator.getUint32();
    const sampleDescriptionIndex = iterator.getUint32();
    if (sampleDescriptionIndex !== 1) {
      throw new Error(`Expected sampleDescriptionIndex to be 1, but got ${sampleDescriptionIndex}`);
    }
    entries.push({
      firstChunk,
      samplesPerChunk
    });
  }
  return {
    type: "stsc-box",
    boxSize: size,
    offset,
    version,
    flags: [...flags],
    entryCount,
    entries
  };
};

// src/containers/iso-base-media/stsd/stsd.ts
var parseStsd = async ({
  offset,
  size,
  state
}) => {
  const { iterator } = state;
  const version = iterator.getUint8();
  if (version !== 0) {
    throw new Error(`Unsupported STSD version ${version}`);
  }
  iterator.discard(3);
  const numberOfEntries = iterator.getUint32();
  const bytesRemainingInBox = size - (iterator.counter.getOffset() - offset);
  const boxes = await parseIsoFormatBoxes({
    maxBytes: bytesRemainingInBox,
    state
  });
  if (boxes.length !== numberOfEntries) {
    throw new Error(`Expected ${numberOfEntries} sample descriptions, got ${boxes.length}`);
  }
  return {
    type: "stsd-box",
    boxSize: size,
    offset,
    numberOfEntries,
    samples: boxes
  };
};

// src/containers/iso-base-media/stsd/stss.ts
var parseStss = ({
  iterator,
  offset,
  boxSize
}) => {
  const version = iterator.getUint8();
  if (version !== 0) {
    throw new Error(`Unsupported STSS version ${version}`);
  }
  const flags = iterator.getSlice(3);
  const sampleCount = iterator.getUint32();
  const sampleNumber = [];
  for (let i = 0;i < sampleCount; i++) {
    sampleNumber.push(iterator.getUint32());
  }
  const bytesRemainingInBox = boxSize - (iterator.counter.getOffset() - offset);
  if (bytesRemainingInBox > 0) {
    throw new Error(`Unexpected bytes remaining in box stss`);
  }
  return {
    type: "stss-box",
    version,
    flags: [...flags],
    sampleNumber,
    boxSize,
    offset
  };
};

// src/containers/iso-base-media/stsd/stsz.ts
var parseStsz = ({
  iterator,
  offset,
  size
}) => {
  const version = iterator.getUint8();
  if (version !== 0) {
    throw new Error(`Unsupported STSD version ${version}`);
  }
  const flags = iterator.getSlice(3);
  const sampleSize = iterator.getUint32();
  const sampleCount = iterator.getUint32();
  if (sampleSize !== 0) {
    return {
      type: "stsz-box",
      boxSize: size,
      offset,
      version,
      flags: [...flags],
      sampleCount,
      countType: "fixed",
      sampleSize
    };
  }
  const samples = [];
  for (let i = 0;i < sampleCount; i++) {
    const bytesRemaining = size - (iterator.counter.getOffset() - offset);
    if (bytesRemaining < 4) {
      break;
    }
    samples.push(iterator.getUint32());
  }
  iterator.discard(size - (iterator.counter.getOffset() - offset));
  return {
    type: "stsz-box",
    boxSize: size,
    offset,
    version,
    flags: [...flags],
    sampleCount,
    countType: "variable",
    entries: samples
  };
};

// src/containers/iso-base-media/stsd/stts.ts
var parseStts = ({
  data,
  size,
  fileOffset
}) => {
  const initialOffset = data.counter.getOffset();
  const initialCounter = initialOffset - fileOffset;
  const version = data.getUint8();
  if (version !== 0) {
    throw new Error(`Unsupported STTS version ${version}`);
  }
  data.discard(3);
  const entryCount = data.getUint32();
  const sampleDistributions = [];
  for (let i = 0;i < entryCount; i++) {
    const sampleCount = data.getUint32();
    const sampleDelta = data.getUint32();
    const sampleDistribution = {
      sampleCount,
      sampleDelta
    };
    sampleDistributions.push(sampleDistribution);
  }
  const bytesUsed = data.counter.getOffset() - initialOffset + initialCounter;
  if (bytesUsed !== size) {
    throw new Error(`Expected stts box to be ${size} bytes, but was ${bytesUsed} bytes`);
  }
  return {
    type: "stts-box",
    sampleDistribution: sampleDistributions
  };
};

// src/containers/iso-base-media/tfdt.ts
var parseTfdt = ({
  iterator,
  size,
  offset
}) => {
  const version = iterator.getUint8();
  iterator.discard(3);
  const num = version === 0 ? iterator.getUint32() : Number(iterator.getUint64());
  const bytesRemaining = size - (iterator.counter.getOffset() - offset);
  if (bytesRemaining !== 0) {
    throw new Error("expected 0 bytes " + bytesRemaining);
  }
  return {
    type: "tfdt-box",
    version,
    baseMediaDecodeTime: num,
    offset
  };
};

// src/containers/iso-base-media/tfhd.ts
var getTfhd = ({
  iterator,
  offset,
  size
}) => {
  const version = iterator.getUint8();
  const flags = iterator.getUint24();
  const trackId = iterator.getUint32();
  const baseDataOffsetPresent = flags & 1;
  const baseDataOffset = baseDataOffsetPresent ? Number(iterator.getUint64()) : 0;
  const baseSampleDescriptionIndexPresent = flags & 2;
  const baseSampleDescriptionIndex = baseSampleDescriptionIndexPresent ? iterator.getUint32() : 0;
  const defaultSampleDurationPresent = flags & 8;
  const defaultSampleDuration = defaultSampleDurationPresent ? iterator.getUint32() : 0;
  const defaultSampleSizePresent = flags & 16;
  const defaultSampleSize = defaultSampleSizePresent ? iterator.getUint32() : 0;
  const defaultSampleFlagsPresent = flags & 32;
  const defaultSampleFlags = defaultSampleFlagsPresent ? iterator.getUint32() : 0;
  const bytesRemaining = size - (iterator.counter.getOffset() - offset);
  if (bytesRemaining !== 0) {
    throw new Error("expected 0 bytes " + bytesRemaining);
  }
  return {
    type: "tfhd-box",
    version,
    trackId,
    baseDataOffset,
    baseSampleDescriptionIndex,
    defaultSampleDuration,
    defaultSampleSize,
    defaultSampleFlags
  };
};

// src/containers/iso-base-media/tkhd.ts
function getRotationAngleFromMatrix(matrix) {
  const [a, b, c, d] = matrix;
  if (a === 0 && b === 0 && c === 0 && d === 0) {
    return 0;
  }
  if (Math.round(a * a + b * b) !== 1 || Math.round(c * c + d * d) !== 1) {
    throw new Error("The provided matrix is not a valid rotation matrix.");
  }
  const angleRadians = Math.atan2(c, a);
  const angleDegrees = angleRadians * (180 / Math.PI);
  return angleDegrees;
}
var applyRotation = ({
  matrix,
  width,
  height
}) => {
  const newWidth = matrix[0] * width + matrix[1] * height;
  const newHeight = matrix[2] * width + matrix[3] * height;
  return {
    width: Math.abs(newWidth),
    height: Math.abs(newHeight)
  };
};
var parseTkhd = ({
  iterator,
  offset,
  size
}) => {
  const version = iterator.getUint8();
  iterator.discard(3);
  const creationTime = version === 1 ? iterator.getUint64() : iterator.getUint32();
  const modificationTime = version === 1 ? iterator.getUint64() : iterator.getUint32();
  const trackId = iterator.getUint32();
  iterator.discard(4);
  const duration2 = version === 1 ? iterator.getUint64() : iterator.getUint32();
  iterator.discard(4);
  iterator.discard(4);
  const layer = iterator.getUint16();
  const alternateGroup = iterator.getUint16();
  const volume = iterator.getUint16();
  iterator.discard(2);
  const matrix = [
    iterator.getFixedPointSigned1616Number(),
    iterator.getFixedPointSigned1616Number(),
    iterator.getFixedPointSigned230Number(),
    iterator.getFixedPointSigned1616Number(),
    iterator.getFixedPointSigned1616Number(),
    iterator.getFixedPointSigned230Number(),
    iterator.getFixedPointSigned1616Number(),
    iterator.getFixedPointSigned1616Number(),
    iterator.getFixedPointSigned230Number()
  ];
  const rotationMatrix = [matrix[0], matrix[1], matrix[3], matrix[4]];
  const widthWithoutRotationApplied = iterator.getFixedPointUnsigned1616Number();
  const heightWithoutRotationApplied = iterator.getFixedPointSigned1616Number();
  const { width, height } = applyRotation({
    matrix: rotationMatrix,
    width: widthWithoutRotationApplied,
    height: heightWithoutRotationApplied
  });
  const rotation = getRotationAngleFromMatrix(rotationMatrix);
  return {
    offset,
    boxSize: size,
    type: "tkhd-box",
    creationTime: toUnixTimestamp(Number(creationTime)),
    modificationTime: toUnixTimestamp(Number(modificationTime)),
    trackId,
    duration: Number(duration2),
    layer,
    alternateGroup,
    volume,
    matrix,
    width,
    height,
    version,
    rotation,
    unrotatedWidth: widthWithoutRotationApplied,
    unrotatedHeight: heightWithoutRotationApplied
  };
};

// src/containers/iso-base-media/trak/trak.ts
var parseTrak = async ({
  size,
  offsetAtStart,
  state: options
}) => {
  const children = await getIsoBaseMediaChildren({
    state: options,
    size: size - 8
  });
  return {
    offset: offsetAtStart,
    boxSize: size,
    type: "trak-box",
    children
  };
};

// src/containers/iso-base-media/trun.ts
var parseTrun = ({
  iterator,
  offset,
  size
}) => {
  const version = iterator.getUint8();
  if (version !== 0) {
    throw new Error(`Unsupported TRUN version ${version}`);
  }
  const flags = iterator.getUint24();
  const sampleCount = iterator.getUint32();
  const dataOffset = flags & 1 ? iterator.getInt32() : null;
  const firstSampleFlags = flags & 4 ? iterator.getUint32() : null;
  const samples = [];
  for (let i = 0;i < sampleCount; i++) {
    const sampleDuration = flags & 256 ? iterator.getUint32() : null;
    const sampleSize = flags & 512 ? iterator.getUint32() : null;
    const sampleFlags = flags & 1024 ? iterator.getUint32() : null;
    const sampleCompositionTimeOffset = flags & 2048 ? version === 0 ? iterator.getUint32() : iterator.getInt32Le() : null;
    samples.push({
      sampleDuration,
      sampleSize,
      sampleFlags,
      sampleCompositionTimeOffset
    });
  }
  const currentOffset = iterator.counter.getOffset();
  const left = size - (currentOffset - offset);
  if (left !== 0) {
    throw new Error(`Unexpected data left in TRUN box: ${left}`);
  }
  return {
    type: "trun-box",
    version,
    sampleCount,
    dataOffset,
    firstSampleFlags,
    samples
  };
};

// src/containers/iso-base-media/process-box.ts
var processBox = async (state) => {
  const { iterator } = state;
  const fileOffset = iterator.counter.getOffset();
  const { returnToCheckpoint } = iterator.startCheckpoint();
  const bytesRemaining = iterator.bytesRemaining();
  const startOff = iterator.counter.getOffset();
  const boxSizeRaw = iterator.getFourByteNumber();
  if (boxSizeRaw === 0) {
    return {
      type: "void-box",
      boxSize: 0
    };
  }
  if (boxSizeRaw === 1 && iterator.bytesRemaining() < 12 || iterator.bytesRemaining() < 4) {
    iterator.counter.decrement(iterator.counter.getOffset() - fileOffset);
    throw new Error(`Expected box size of ${bytesRemaining}, got ${boxSizeRaw}. Incomplete boxes are not allowed.`);
  }
  const boxType = iterator.getByteString(4, false);
  const boxSize = boxSizeRaw === 1 ? iterator.getEightByteNumber() : boxSizeRaw;
  Log.trace(state.logLevel, "Found box", boxType, boxSize);
  const headerLength = iterator.counter.getOffset() - startOff;
  if (boxType === "mdat") {
    state.videoSection.setVideoSection({
      size: boxSize - headerLength,
      start: iterator.counter.getOffset()
    });
    return null;
  }
  if (bytesRemaining < boxSize) {
    returnToCheckpoint();
    return null;
  }
  if (boxType === "ftyp") {
    return parseFtyp({ iterator, size: boxSize, offset: fileOffset });
  }
  if (boxType === "colr") {
    return parseColorParameterBox({
      iterator,
      size: boxSize
    });
  }
  if (boxType === "mvhd") {
    return parseMvhd({ iterator, offset: fileOffset, size: boxSize });
  }
  if (boxType === "tkhd") {
    return parseTkhd({ iterator, offset: fileOffset, size: boxSize });
  }
  if (boxType === "trun") {
    return parseTrun({ iterator, offset: fileOffset, size: boxSize });
  }
  if (boxType === "tfdt") {
    return parseTfdt({ iterator, size: boxSize, offset: fileOffset });
  }
  if (boxType === "stsd") {
    return parseStsd({
      offset: fileOffset,
      size: boxSize,
      state
    });
  }
  if (boxType === "stsz") {
    return parseStsz({
      iterator,
      offset: fileOffset,
      size: boxSize
    });
  }
  if (boxType === "stco" || boxType === "co64") {
    return parseStco({
      iterator,
      offset: fileOffset,
      size: boxSize,
      mode64Bit: boxType === "co64"
    });
  }
  if (boxType === "pasp") {
    return parsePasp({
      iterator,
      offset: fileOffset,
      size: boxSize
    });
  }
  if (boxType === "stss") {
    return parseStss({
      iterator,
      offset: fileOffset,
      boxSize
    });
  }
  if (boxType === "ctts") {
    return parseCtts({
      iterator,
      offset: fileOffset,
      size: boxSize
    });
  }
  if (boxType === "stsc") {
    return parseStsc({
      iterator,
      offset: fileOffset,
      size: boxSize
    });
  }
  if (boxType === "mebx") {
    return parseMebx({
      offset: fileOffset,
      size: boxSize,
      state
    });
  }
  if (boxType === "hdlr") {
    return parseHdlr({ iterator, size: boxSize, offset: fileOffset });
  }
  if (boxType === "keys") {
    return parseKeys({ iterator, size: boxSize, offset: fileOffset });
  }
  if (boxType === "ilst") {
    return parseIlstBox({
      iterator,
      offset: fileOffset,
      size: boxSize
    });
  }
  if (boxType === "moov") {
    if (state.callbacks.tracks.hasAllTracks()) {
      iterator.discard(boxSize - 8);
      return null;
    }
    if (state.iso.moov.getMoovBox()) {
      Log.verbose(state.logLevel, "Moov box already parsed, skipping");
      iterator.discard(boxSize - 8);
      return null;
    }
    const box = await parseMoov({
      offset: fileOffset,
      size: boxSize,
      state
    });
    state.callbacks.tracks.setIsDone(state.logLevel);
    return box;
  }
  if (boxType === "trak") {
    const box = await parseTrak({
      size: boxSize,
      offsetAtStart: fileOffset,
      state
    });
    const transformedTrack = makeBaseMediaTrack(box);
    if (transformedTrack) {
      await registerTrack({
        state,
        track: transformedTrack,
        container: "mp4"
      });
    }
    return box;
  }
  if (boxType === "stts") {
    return parseStts({
      data: iterator,
      size: boxSize,
      fileOffset
    });
  }
  if (boxType === "avcC") {
    return parseAvcc({
      data: iterator,
      size: boxSize
    });
  }
  if (boxType === "av1C") {
    return parseAv1C({
      data: iterator,
      size: boxSize
    });
  }
  if (boxType === "hvcC") {
    return parseHvcc({
      data: iterator,
      size: boxSize,
      offset: fileOffset
    });
  }
  if (boxType === "tfhd") {
    return getTfhd({
      iterator,
      offset: fileOffset,
      size: boxSize
    });
  }
  if (boxType === "mdhd") {
    return parseMdhd({
      data: iterator,
      size: boxSize,
      fileOffset
    });
  }
  if (boxType === "esds") {
    return parseEsds({
      data: iterator,
      size: boxSize,
      fileOffset
    });
  }
  if (boxType === "mdia" || boxType === "minf" || boxType === "stbl" || boxType === "udta" || boxType === "moof" || boxType === "dims" || boxType === "meta" || boxType === "wave" || boxType === "traf" || boxType === "stsb") {
    const children = await getIsoBaseMediaChildren({
      state,
      size: boxSize - 8
    });
    return {
      type: "regular-box",
      boxType,
      boxSize,
      children,
      offset: fileOffset
    };
  }
  iterator.discard(boxSize - 8);
  return {
    type: "regular-box",
    boxType,
    boxSize,
    children: [],
    offset: fileOffset
  };
};

// src/containers/iso-base-media/get-children.ts
var getIsoBaseMediaChildren = async ({
  state,
  size
}) => {
  const boxes = [];
  const { iterator } = state;
  const initial = iterator.counter.getOffset();
  while (iterator.counter.getOffset() < size + initial) {
    const parsed = await processBox(state);
    if (!parsed) {
      throw new Error("Expected box");
    }
    boxes.push(parsed);
  }
  if (iterator.counter.getOffset() > size + initial) {
    throw new Error(`read too many bytes - size: ${size}, read: ${iterator.counter.getOffset() - initial}. initial offset: ${initial}`);
  }
  return boxes;
};

// src/containers/iso-base-media/stsd/samples.ts
var videoTags = [
  "cvid",
  "jpeg",
  "smc ",
  "rle ",
  "rpza",
  "kpcd",
  "png ",
  "mjpa",
  "mjpb",
  "SVQ1",
  "SVQ3",
  "mp4v",
  "avc1",
  "dvc ",
  "dvcp",
  "gif ",
  "h263",
  "tiff",
  "raw ",
  "2vuY",
  "yuv2",
  "v308",
  "v408",
  "v216",
  "v410",
  "v210",
  "hvc1",
  "hev1",
  "ap4h",
  "av01"
];
var audioTags = [
  0,
  "NONE",
  "raw ",
  "twos",
  "sowt",
  "MAC3 ",
  "MAC6 ",
  "ima4",
  "fl32",
  "lpcm",
  "fl64",
  "in24",
  "in32",
  "ulaw",
  "alaw",
  1836253186,
  1836253201,
  "dvca",
  "QDMC",
  "QDM2",
  "Qclp",
  1836253269,
  ".mp3",
  "mp4a",
  "ac-3"
];
var processIsoFormatBox = async ({
  state
}) => {
  const { iterator } = state;
  const fileOffset = iterator.counter.getOffset();
  const bytesRemaining = iterator.bytesRemaining();
  const boxSize = iterator.getUint32();
  if (bytesRemaining < boxSize) {
    throw new Error(`Expected box size of ${bytesRemaining}, got ${boxSize}`);
  }
  const boxFormat = iterator.getAtom();
  const isVideo = videoTags.includes(boxFormat);
  const isAudio = audioTags.includes(boxFormat) || audioTags.includes(Number(boxFormat));
  iterator.discard(6);
  const dataReferenceIndex = iterator.getUint16();
  if (!isVideo && !isAudio) {
    const bytesRemainingInBox = boxSize - (iterator.counter.getOffset() - fileOffset);
    iterator.discard(bytesRemainingInBox);
    return {
      sample: {
        type: "unknown",
        offset: fileOffset,
        dataReferenceIndex,
        size: boxSize,
        format: boxFormat
      }
    };
  }
  if (isAudio) {
    const version = iterator.getUint16();
    const revisionLevel = iterator.getUint16();
    const vendor = iterator.getSlice(4);
    if (version === 0) {
      const numberOfChannels = iterator.getUint16();
      const sampleSize = iterator.getUint16();
      const compressionId = iterator.getUint16();
      const packetSize = iterator.getUint16();
      const sampleRate = iterator.getFixedPointUnsigned1616Number();
      const children = await getIsoBaseMediaChildren({
        state,
        size: boxSize - (iterator.counter.getOffset() - fileOffset)
      });
      return {
        sample: {
          format: boxFormat,
          offset: fileOffset,
          dataReferenceIndex,
          version,
          revisionLevel,
          vendor: [...Array.from(new Uint8Array(vendor))],
          size: boxSize,
          type: "audio",
          numberOfChannels,
          sampleSize,
          compressionId,
          packetSize,
          sampleRate,
          samplesPerPacket: null,
          bytesPerPacket: null,
          bytesPerFrame: null,
          bitsPerSample: null,
          children
        }
      };
    }
    if (version === 1) {
      const numberOfChannels = iterator.getUint16();
      const sampleSize = iterator.getUint16();
      const compressionId = iterator.getInt16();
      const packetSize = iterator.getUint16();
      const sampleRate = iterator.getFixedPointUnsigned1616Number();
      const samplesPerPacket = iterator.getUint32();
      const bytesPerPacket = iterator.getUint32();
      const bytesPerFrame = iterator.getUint32();
      const bytesPerSample = iterator.getUint32();
      const children = await getIsoBaseMediaChildren({
        state,
        size: boxSize - (iterator.counter.getOffset() - fileOffset)
      });
      return {
        sample: {
          format: boxFormat,
          offset: fileOffset,
          dataReferenceIndex,
          version,
          revisionLevel,
          vendor: [...Array.from(new Uint8Array(vendor))],
          size: boxSize,
          type: "audio",
          numberOfChannels,
          sampleSize,
          compressionId,
          packetSize,
          sampleRate,
          samplesPerPacket,
          bytesPerPacket,
          bytesPerFrame,
          bitsPerSample: bytesPerSample,
          children
        }
      };
    }
    if (version === 2) {
      iterator.getUint16();
      const sampleSize = iterator.getUint16();
      const compressionId = iterator.getUint16();
      const packetSize = iterator.getUint16();
      iterator.getFixedPointUnsigned1616Number();
      iterator.getUint32();
      const higherSampleRate = iterator.getFloat64();
      const numAudioChannel = iterator.getUint32();
      iterator.getUint32();
      const bitsPerChannel = iterator.getUint32();
      iterator.getUint32();
      const bytesPerFrame = iterator.getUint32();
      const samplesPerPacket = iterator.getUint32();
      const children = await getIsoBaseMediaChildren({
        state,
        size: boxSize - (iterator.counter.getOffset() - fileOffset)
      });
      return {
        sample: {
          format: boxFormat,
          offset: fileOffset,
          dataReferenceIndex,
          version,
          revisionLevel,
          vendor: [...Array.from(new Uint8Array(vendor))],
          size: boxSize,
          type: "audio",
          numberOfChannels: numAudioChannel,
          sampleSize,
          compressionId,
          packetSize,
          sampleRate: higherSampleRate,
          samplesPerPacket,
          bytesPerPacket: null,
          bytesPerFrame,
          bitsPerSample: bitsPerChannel,
          children
        }
      };
    }
    throw new Error(`Unsupported version ${version}`);
  }
  if (isVideo) {
    const version = iterator.getUint16();
    const revisionLevel = iterator.getUint16();
    const vendor = iterator.getSlice(4);
    const temporalQuality = iterator.getUint32();
    const spacialQuality = iterator.getUint32();
    const width = iterator.getUint16();
    const height = iterator.getUint16();
    const horizontalResolution = iterator.getFixedPointUnsigned1616Number();
    const verticalResolution = iterator.getFixedPointUnsigned1616Number();
    const dataSize = iterator.getUint32();
    const frameCountPerSample = iterator.getUint16();
    const compressorName = iterator.getPascalString();
    const depth = iterator.getUint16();
    const colorTableId = iterator.getInt16();
    const bytesRemainingInBox = boxSize - (iterator.counter.getOffset() - fileOffset);
    const children = bytesRemainingInBox > 8 ? await getIsoBaseMediaChildren({
      state,
      size: bytesRemainingInBox
    }) : (iterator.discard(bytesRemainingInBox), []);
    return {
      sample: {
        format: boxFormat,
        offset: fileOffset,
        dataReferenceIndex,
        version,
        revisionLevel,
        vendor: [...Array.from(new Uint8Array(vendor))],
        size: boxSize,
        type: "video",
        width,
        height,
        horizontalResolutionPpi: horizontalResolution,
        verticalResolutionPpi: verticalResolution,
        spacialQuality,
        temporalQuality,
        dataSize,
        frameCountPerSample,
        compressorName,
        depth,
        colorTableId,
        descriptors: children
      }
    };
  }
  throw new Error(`Unknown sample format ${boxFormat}`);
};
var parseIsoFormatBoxes = async ({
  maxBytes,
  state
}) => {
  const { iterator } = state;
  const samples = [];
  const initialOffset = iterator.counter.getOffset();
  while (iterator.bytesRemaining() > 0 && iterator.counter.getOffset() - initialOffset < maxBytes) {
    const { sample } = await processIsoFormatBox({
      state
    });
    if (sample) {
      samples.push(sample);
    }
  }
  return samples;
};

// src/containers/webm/segments/block-simple-block-flags.ts
var parseBlockFlags = (iterator, type) => {
  if (type === matroskaElements.Block) {
    iterator.startReadingBits();
    iterator.getBits(4);
    const invisible = Boolean(iterator.getBits(1));
    const lacing = iterator.getBits(2);
    iterator.getBits(1);
    iterator.stopReadingBits();
    return {
      invisible,
      lacing,
      keyframe: null
    };
  }
  if (type === matroskaElements.SimpleBlock) {
    iterator.startReadingBits();
    const keyframe = Boolean(iterator.getBits(1));
    iterator.getBits(3);
    const invisible = Boolean(iterator.getBits(1));
    const lacing = iterator.getBits(2);
    iterator.getBits(1);
    iterator.stopReadingBits();
    return {
      invisible,
      lacing,
      keyframe
    };
  }
  throw new Error("Unexpected type");
};

// src/containers/webm/get-sample-from-block.ts
var getSampleFromBlock = (ebml, state, offset) => {
  const iterator = getArrayBufferIterator(ebml.value, ebml.value.length);
  const trackNumber2 = iterator.getVint();
  if (trackNumber2 === null) {
    throw new Error("Not enough data to get track number, should not happen");
  }
  const timecodeRelativeToCluster = iterator.getInt16();
  const { keyframe } = parseBlockFlags(iterator, ebml.type === "SimpleBlock" ? matroskaElements.SimpleBlock : matroskaElements.Block);
  const { codec, trackTimescale } = state.webm.getTrackInfoByNumber(trackNumber2);
  const clusterOffset = state.webm.getTimestampOffsetForByteOffset(offset);
  const timescale = state.webm.getTimescale();
  if (clusterOffset === undefined) {
    throw new Error("Could not find offset for byte offset " + offset);
  }
  const timecodeInNanoSeconds = (timecodeRelativeToCluster + clusterOffset) * timescale * (trackTimescale ?? 1);
  const timecodeInMicroseconds = timecodeInNanoSeconds / 1000;
  if (!codec) {
    throw new Error(`Could not find codec for track ${trackNumber2}`);
  }
  const remainingNow = ebml.value.length - iterator.counter.getOffset();
  if (codec.startsWith("V_")) {
    const partialVideoSample = {
      data: iterator.getSlice(remainingNow),
      cts: timecodeInMicroseconds,
      dts: timecodeInMicroseconds,
      duration: undefined,
      trackId: trackNumber2,
      timestamp: timecodeInMicroseconds,
      offset,
      timescale
    };
    if (keyframe === null) {
      iterator.destroy();
      return {
        type: "partial-video-sample",
        partialVideoSample
      };
    }
    const sample = {
      ...partialVideoSample,
      type: keyframe ? "key" : "delta"
    };
    iterator.destroy();
    return {
      type: "video-sample",
      videoSample: sample
    };
  }
  if (codec.startsWith("A_")) {
    const audioSample = {
      data: iterator.getSlice(remainingNow),
      trackId: trackNumber2,
      timestamp: timecodeInMicroseconds,
      type: "key",
      duration: undefined,
      cts: timecodeInMicroseconds,
      dts: timecodeInMicroseconds,
      offset,
      timescale
    };
    iterator.destroy();
    return {
      type: "audio-sample",
      audioSample
    };
  }
  iterator.destroy();
  return {
    type: "no-sample"
  };
};

// src/containers/webm/parse-ebml.ts
var parseEbml = async (state) => {
  const { iterator } = state;
  const hex = iterator.getMatroskaSegmentId();
  if (hex === null) {
    throw new Error("Not enough bytes left to parse EBML - this should not happen");
  }
  const hasInMap = ebmlMap[hex];
  if (!hasInMap) {
    throw new Error(`Don't know how to parse EBML hex ID ${JSON.stringify(hex)}`);
  }
  const off = iterator.counter.getOffset();
  const size = iterator.getVint();
  const minVintWidth = iterator.counter.getOffset() - off;
  if (size === null) {
    throw new Error("Not enough bytes left to parse EBML - this should not happen");
  }
  if (hasInMap.type === "uint") {
    const beforeUintOffset = iterator.counter.getOffset();
    const value = size === 0 ? 0 : iterator.getUint(size);
    const { name } = hasInMap;
    return {
      type: name,
      value: {
        value,
        byteLength: iterator.counter.getOffset() - beforeUintOffset
      },
      minVintWidth
    };
  }
  if (hasInMap.type === "string") {
    const value = iterator.getByteString(size, true);
    return {
      type: hasInMap.name,
      value,
      minVintWidth
    };
  }
  if (hasInMap.type === "float") {
    const value = size === 0 ? 0 : size === 4 ? iterator.getFloat32() : iterator.getFloat64();
    return {
      type: hasInMap.name,
      value: {
        value,
        size: size === 4 ? "32" : "64"
      },
      minVintWidth
    };
  }
  if (hasInMap.type === "hex-string") {
    return {
      type: hasInMap.name,
      value: "0x" + [...iterator.getSlice(size)].map((b) => b.toString(16).padStart(2, "0")).join("").replace(new RegExp("^" + hex), ""),
      minVintWidth
    };
  }
  if (hasInMap.type === "uint8array") {
    return {
      type: hasInMap.name,
      value: iterator.getSlice(size),
      minVintWidth
    };
  }
  if (hasInMap.type === "children") {
    const children = [];
    const startOffset = iterator.counter.getOffset();
    while (true) {
      if (size === 0) {
        break;
      }
      const offset = iterator.counter.getOffset();
      const value = await parseEbml(state);
      const remapped = await postprocessEbml({
        offset,
        ebml: value,
        state
      });
      children.push(remapped);
      const offsetNow = iterator.counter.getOffset();
      if (offsetNow - startOffset > size) {
        throw new Error(`Offset ${offsetNow - startOffset} is larger than the length of the hex ${size}`);
      }
      if (offsetNow - startOffset === size) {
        break;
      }
    }
    return { type: hasInMap.name, value: children, minVintWidth };
  }
  throw new Error(`Unknown segment type ${hasInMap.type}`);
};
var postprocessEbml = async ({
  offset,
  ebml,
  state
}) => {
  if (ebml.type === "TimestampScale") {
    state.webm.setTimescale(ebml.value.value);
  }
  if (ebml.type === "Tracks") {
    state.callbacks.tracks.setIsDone(state.logLevel);
  }
  if (ebml.type === "TrackEntry") {
    state.webm.onTrackEntrySegment(ebml);
    const track = getTrack({
      track: ebml,
      timescale: state.webm.getTimescale()
    });
    if (track) {
      await registerTrack({
        state,
        track,
        container: "webm"
      });
    }
  }
  if (ebml.type === "Timestamp") {
    state.webm.setTimestampOffset(offset, ebml.value.value);
  }
  if (ebml.type === "Block" || ebml.type === "SimpleBlock") {
    const sample = getSampleFromBlock(ebml, state, offset);
    if (sample.type === "video-sample") {
      await state.callbacks.onVideoSample(sample.videoSample.trackId, sample.videoSample);
      return {
        type: "Block",
        value: new Uint8Array([]),
        minVintWidth: ebml.minVintWidth
      };
    }
    if (sample.type === "audio-sample") {
      await state.callbacks.onAudioSample(sample.audioSample.trackId, sample.audioSample);
      return {
        type: "Block",
        value: new Uint8Array([]),
        minVintWidth: ebml.minVintWidth
      };
    }
    if (sample.type === "no-sample") {
      return {
        type: "Block",
        value: new Uint8Array([]),
        minVintWidth: ebml.minVintWidth
      };
    }
  }
  if (ebml.type === "BlockGroup") {
    const block2 = ebml.value.find((c) => c.type === "SimpleBlock" || c.type === "Block");
    if (!block2 || block2.type !== "SimpleBlock" && block2.type !== "Block") {
      throw new Error("Expected block segment");
    }
    const hasReferenceBlock = ebml.value.find((c) => c.type === "ReferenceBlock");
    const sample = block2.value.length === 0 ? null : getSampleFromBlock(block2, state, offset);
    if (sample && sample.type === "partial-video-sample") {
      const completeFrame = {
        ...sample.partialVideoSample,
        type: hasReferenceBlock ? "delta" : "key"
      };
      await state.callbacks.onVideoSample(sample.partialVideoSample.trackId, completeFrame);
    }
    return {
      type: "BlockGroup",
      value: [],
      minVintWidth: ebml.minVintWidth
    };
  }
  return ebml;
};

// src/get-container.ts
var getContainer = (segments) => {
  if (segments.type === "iso-base-media") {
    return "mp4";
  }
  if (segments.type === "matroska") {
    return "webm";
  }
  if (segments.type === "transport-stream") {
    return "transport-stream";
  }
  if (segments.type === "mp3") {
    return "mp3";
  }
  if (segments.type === "wav") {
    return "wav";
  }
  if (segments.type === "flac") {
    return "flac";
  }
  if (segments.type === "riff") {
    if (isRiffAvi2(segments)) {
      return "avi";
    }
    throw new Error("Unknown RIFF container " + segments.type);
  }
  if (segments.type === "aac") {
    return "aac";
  }
  throw new Error("Unknown container " + segments);
};
var hasContainer = (boxes) => {
  try {
    return getContainer(boxes) !== null;
  } catch {
    return false;
  }
};

// src/get-dimensions.ts
var getDimensions = (state) => {
  const structure = state.getStructureOrNull();
  if (structure && isAudioStructure(structure)) {
    return null;
  }
  const { videoTracks } = getTracks(state);
  if (!videoTracks.length) {
    return null;
  }
  const firstVideoTrack = videoTracks[0];
  return {
    width: firstVideoTrack.width,
    height: firstVideoTrack.height,
    rotation: firstVideoTrack.rotation,
    unrotatedHeight: firstVideoTrack.displayAspectHeight,
    unrotatedWidth: firstVideoTrack.displayAspectWidth
  };
};
var hasDimensions = (state) => {
  const structure = state.getStructureOrNull();
  if (structure && isAudioStructure(structure)) {
    return true;
  }
  try {
    return getDimensions(state) !== null;
  } catch {
    return false;
  }
};

// src/containers/flac/get-duration-from-flac.ts
var getDurationFromFlac = (parserState) => {
  const structure = parserState.getFlacStructure();
  const streaminfo = structure.boxes.find((b) => b.type === "flac-streaminfo");
  if (!streaminfo) {
    throw new Error("Streaminfo not found");
  }
  return streaminfo.totalSamples / streaminfo.sampleRate;
};

// src/get-sample-positions.ts
var getSamplePositions = ({
  stcoBox,
  stszBox,
  stscBox,
  stssBox,
  sttsBox,
  cttsBox
}) => {
  const sttsDeltas = [];
  for (const distribution of sttsBox.sampleDistribution) {
    for (let i = 0;i < distribution.sampleCount; i++) {
      sttsDeltas.push(distribution.sampleDelta);
    }
  }
  const cttsEntries = [];
  for (const entry of cttsBox?.entries ?? [
    { sampleCount: sttsDeltas.length, sampleOffset: 0 }
  ]) {
    for (let i = 0;i < entry.sampleCount; i++) {
      cttsEntries.push(entry.sampleOffset);
    }
  }
  let dts = 0;
  const chunks = stcoBox.entries;
  const samples = [];
  let samplesPerChunk = 1;
  for (let i = 0;i < chunks.length; i++) {
    const hasEntry = stscBox.entries.find((entry) => entry.firstChunk === i + 1);
    if (hasEntry) {
      samplesPerChunk = hasEntry.samplesPerChunk;
    }
    let offsetInThisChunk = 0;
    for (let j = 0;j < samplesPerChunk; j++) {
      const size = stszBox.countType === "fixed" ? stszBox.sampleSize : stszBox.entries[samples.length];
      const isKeyframe = stssBox ? stssBox.sampleNumber.includes(samples.length + 1) : true;
      const delta = sttsDeltas[samples.length];
      const ctsOffset = cttsEntries[samples.length];
      const cts = dts + ctsOffset;
      samples.push({
        offset: Number(chunks[i]) + offsetInThisChunk,
        size,
        isKeyframe,
        dts,
        cts,
        duration: delta,
        chunk: i
      });
      dts += delta;
      offsetInThisChunk += size;
    }
  }
  return samples;
};

// src/get-sample-positions-from-lpcm.ts
var getSamplePositionsFromLpcm = (trakBox) => {
  const stscBox = getStscBox(trakBox);
  const stszBox = getStszBox(trakBox);
  const stcoBox = getStcoBox(trakBox);
  if (!stscBox) {
    throw new Error("Expected stsc box in trak box");
  }
  if (!stcoBox) {
    throw new Error("Expected stco box in trak box");
  }
  if (!stszBox) {
    throw new Error("Expected stsz box in trak box");
  }
  if (stszBox.countType !== "fixed") {
    throw new Error("Only supporting fixed count type in stsz box");
  }
  const samples = [];
  let timestamp = 0;
  for (let i = 0;i < stcoBox.entries.length; i++) {
    const entry = stcoBox.entries[i];
    const chunk = i + 1;
    const stscEntry = stscBox.entries.findLast((e) => e.firstChunk <= chunk);
    if (!stscEntry) {
      throw new Error("should not be");
    }
    samples.push({
      chunk,
      cts: timestamp,
      dts: timestamp,
      offset: Number(entry),
      size: stszBox.sampleSize * stscEntry.samplesPerChunk,
      duration: stscEntry.samplesPerChunk,
      isKeyframe: true
    });
    timestamp += stscEntry.samplesPerChunk;
  }
  return samples;
};

// src/samples-from-moof.ts
var getSamplesFromTraf = (trafSegment, moofOffset) => {
  if (trafSegment.type !== "regular-box" || trafSegment.boxType !== "traf") {
    throw new Error("Expected traf-box");
  }
  const tfhdBox = getTfhdBox(trafSegment);
  const defaultSampleDuration = tfhdBox?.defaultSampleDuration ?? null;
  const defaultSampleSize = tfhdBox?.defaultSampleSize ?? null;
  const defaultSampleFlags = tfhdBox?.defaultSampleFlags ?? null;
  const tfdtBox = getTfdtBox(trafSegment);
  const trunBoxes = getTrunBoxes(trafSegment);
  let time = 0;
  let offset = 0;
  let dataOffset = 0;
  const samples = [];
  for (const trunBox of trunBoxes) {
    let i = -1;
    if (trunBox.dataOffset) {
      dataOffset = trunBox.dataOffset;
      offset = 0;
    }
    for (const sample of trunBox.samples) {
      i++;
      const duration2 = sample.sampleDuration ?? defaultSampleDuration;
      if (duration2 === null) {
        throw new Error("Expected duration");
      }
      const size = sample.sampleSize ?? defaultSampleSize;
      if (size === null) {
        throw new Error("Expected size");
      }
      const isFirstSample = i === 0;
      const sampleFlags = sample.sampleFlags ? sample.sampleFlags : isFirstSample && trunBox.firstSampleFlags !== null ? trunBox.firstSampleFlags : defaultSampleFlags;
      if (sampleFlags === null) {
        throw new Error("Expected sample flags");
      }
      const keyframe = !(sampleFlags >> 16 & 1);
      const dts = time + (tfdtBox?.baseMediaDecodeTime ?? 0);
      const samplePosition = {
        offset: offset + (moofOffset ?? 0) + (dataOffset ?? 0),
        dts,
        cts: dts,
        duration: duration2,
        isKeyframe: keyframe,
        size,
        chunk: 0
      };
      samples.push(samplePosition);
      offset += size;
      time += duration2;
    }
  }
  return samples;
};
var getSamplesFromMoof = ({
  moofBox,
  trackId
}) => {
  if (moofBox.type !== "regular-box") {
    throw new Error("Expected moof-box");
  }
  const trafs = moofBox.children.filter((c) => c.type === "regular-box" && c.boxType === "traf");
  const mapped = trafs.map((traf) => {
    const tfhdBox = getTfhdBox(traf);
    return tfhdBox?.trackId === trackId ? getSamplesFromTraf(traf, moofBox.offset) : [];
  });
  return mapped.flat(1);
};

// src/containers/iso-base-media/get-sample-positions-from-track.ts
var getSamplePositionsFromTrack = ({
  trakBox,
  moofBoxes
}) => {
  const isLpcm = isLpcmAudioCodec(trakBox);
  const timescaleAndDuration = getTimescaleAndDuration(trakBox);
  if (isLpcm) {
    return getSamplePositionsFromLpcm(trakBox);
  }
  const stszBox = getStszBox(trakBox);
  const stcoBox = getStcoBox(trakBox);
  const stscBox = getStscBox(trakBox);
  const stssBox = getStssBox(trakBox);
  const sttsBox = getSttsBox(trakBox);
  const tkhdBox = getTkhdBox(trakBox);
  const cttsBox = getCttsBox(trakBox);
  if (!tkhdBox) {
    throw new Error("Expected tkhd box in trak box");
  }
  if (!stszBox) {
    throw new Error("Expected stsz box in trak box");
  }
  if (!stcoBox) {
    throw new Error("Expected stco box in trak box");
  }
  if (!stscBox) {
    throw new Error("Expected stsc box in trak box");
  }
  if (!sttsBox) {
    throw new Error("Expected stts box in trak box");
  }
  if (!timescaleAndDuration) {
    throw new Error("Expected timescale and duration in trak box");
  }
  let samplePositions = getSamplePositions({
    stcoBox,
    stscBox,
    stszBox,
    stssBox,
    sttsBox,
    cttsBox
  });
  if (samplePositions.length === 0 && moofBoxes.length > 0) {
    samplePositions = moofBoxes.map((m) => {
      return getSamplesFromMoof({ moofBox: m, trackId: tkhdBox.trackId });
    }).flat(1);
  }
  return samplePositions;
};

// src/containers/mp3/get-frame-length.ts
var getUnroundedMpegFrameLength = ({
  samplesPerFrame,
  bitrateKbit,
  samplingFrequency: samplingFrequency2,
  padding,
  layer
}) => {
  if (layer === 1) {
    throw new Error("MPEG Layer I is not supported");
  }
  return samplesPerFrame / 8 * bitrateKbit / samplingFrequency2 * 1000 + (padding ? layer === 1 ? 4 : 1 : 0);
};
var getAverageMpegFrameLength = ({
  samplesPerFrame,
  bitrateKbit,
  samplingFrequency: samplingFrequency2,
  layer
}) => {
  const withoutPadding = getUnroundedMpegFrameLength({
    bitrateKbit,
    layer,
    padding: false,
    samplesPerFrame,
    samplingFrequency: samplingFrequency2
  });
  const rounded = Math.floor(withoutPadding);
  const rest = withoutPadding % 1;
  return rest * (rounded + 1) + (1 - rest) * rounded;
};
var getMpegFrameLength = ({
  samplesPerFrame,
  bitrateKbit,
  samplingFrequency: samplingFrequency2,
  padding,
  layer
}) => {
  return Math.floor(getUnroundedMpegFrameLength({
    bitrateKbit,
    layer,
    padding,
    samplesPerFrame,
    samplingFrequency: samplingFrequency2
  }));
};

// src/containers/mp3/samples-per-mpeg-file.ts
var getSamplesPerMpegFrame = ({
  mpegVersion,
  layer
}) => {
  if (mpegVersion === 1) {
    if (layer === 1) {
      return 384;
    }
    if (layer === 2 || layer === 3) {
      return 1152;
    }
  }
  if (mpegVersion === 2) {
    if (layer === 1) {
      return 384;
    }
    if (layer === 2) {
      return 1152;
    }
    if (layer === 3) {
      return 576;
    }
  }
  throw new Error("Invalid MPEG layer");
};

// src/containers/mp3/get-duration.ts
var getDurationFromMp3 = (state) => {
  const mp3Info = state.mp3Info.getMp3Info();
  if (!mp3Info) {
    throw new Error("No mp3 info");
  }
  const samplesPerFrame = getSamplesPerMpegFrame({
    layer: mp3Info.layer,
    mpegVersion: mp3Info.mpegVersion
  });
  const frameLengthInBytes = getMpegFrameLength({
    bitrateKbit: mp3Info.bitrateKbit,
    padding: false,
    samplesPerFrame,
    samplingFrequency: mp3Info.sampleRate,
    layer: mp3Info.layer
  });
  const frames = Math.floor((state.contentLength - mp3Info.startOfMpegStream) / frameLengthInBytes);
  const samples = frames * samplesPerFrame;
  const durationInSeconds = samples / mp3Info.sampleRate;
  return durationInSeconds;
};

// src/containers/riff/get-duration.ts
var getDurationFromAvi = (structure) => {
  const strl = getStrlBoxes(structure);
  const lengths = [];
  for (const s of strl) {
    const strh = getStrhBox(s.children);
    if (!strh) {
      throw new Error("No strh box");
    }
    const samplesPerSecond = strh.rate / strh.scale;
    const streamLength = strh.length / samplesPerSecond;
    lengths.push(streamLength);
  }
  return Math.max(...lengths);
};

// src/containers/wav/get-duration-from-wav.ts
var getDurationFromWav = (state) => {
  const structure = state.getWavStructure();
  const fmt = structure.boxes.find((b) => b.type === "wav-fmt");
  if (!fmt) {
    throw new Error("Expected fmt box");
  }
  const dataBox = structure.boxes.find((b) => b.type === "wav-data");
  if (!dataBox) {
    throw new Error("Expected data box");
  }
  const durationInSeconds = dataBox.dataSize / (fmt.sampleRate * fmt.blockAlign);
  return durationInSeconds;
};

// src/get-duration.ts
var getDurationFromMatroska = (segments) => {
  const mainSegment = segments.find((s) => s.type === "Segment");
  if (!mainSegment || mainSegment.type !== "Segment") {
    return null;
  }
  const { value: children } = mainSegment;
  if (!children) {
    return null;
  }
  const infoSegment = children.find((s) => s.type === "Info");
  const relevantBoxes = [
    ...mainSegment.value,
    ...infoSegment && infoSegment.type === "Info" ? infoSegment.value : []
  ];
  const timestampScale2 = relevantBoxes.find((s) => s.type === "TimestampScale");
  if (!timestampScale2 || timestampScale2.type !== "TimestampScale") {
    return null;
  }
  const duration2 = relevantBoxes.find((s) => s.type === "Duration");
  if (!duration2 || duration2.type !== "Duration") {
    return null;
  }
  return duration2.value.value / timestampScale2.value.value * 1000;
};
var getDurationFromIsoBaseMedia = (parserState) => {
  const structure = parserState.getIsoStructure();
  const moovBox = getMoovBox(parserState);
  if (!moovBox) {
    return null;
  }
  const moofBoxes = getMoofBoxes(structure.boxes);
  const mvhdBox = getMvhdBox(moovBox);
  if (!mvhdBox) {
    return null;
  }
  if (mvhdBox.type !== "mvhd-box") {
    throw new Error("Expected mvhd-box");
  }
  if (mvhdBox.durationInSeconds > 0) {
    return mvhdBox.durationInSeconds;
  }
  const tracks2 = getTracks(parserState);
  const allTracks = [
    ...tracks2.videoTracks,
    ...tracks2.audioTracks,
    ...tracks2.otherTracks
  ];
  const allSamples = allTracks.map((t) => {
    const { timescale: ts } = t;
    const samplePositions = getSamplePositionsFromTrack({
      trakBox: t.trakBox,
      moofBoxes
    });
    const highest = samplePositions?.map((sp) => (sp.cts + sp.duration) / ts).reduce((a, b) => Math.max(a, b), 0);
    return highest ?? 0;
  });
  const highestTimestamp = Math.max(...allSamples);
  return highestTimestamp;
};
var getDuration = (parserState) => {
  const structure = parserState.getStructure();
  if (structure.type === "matroska") {
    return getDurationFromMatroska(structure.boxes);
  }
  if (structure.type === "iso-base-media") {
    return getDurationFromIsoBaseMedia(parserState);
  }
  if (structure.type === "riff") {
    return getDurationFromAvi(structure);
  }
  if (structure.type === "transport-stream") {
    return null;
  }
  if (structure.type === "mp3") {
    return getDurationFromMp3(parserState);
  }
  if (structure.type === "wav") {
    return getDurationFromWav(parserState);
  }
  if (structure.type === "aac") {
    return null;
  }
  if (structure.type === "flac") {
    return getDurationFromFlac(parserState);
  }
  throw new Error("Has no duration " + structure);
};
var hasDuration = (parserState) => {
  return getHasTracks(parserState);
};
var hasSlowDuration = (parserState) => {
  try {
    return getDuration(parserState) !== null;
  } catch {
    return false;
  }
};

// src/get-is-hdr.ts
var isVideoTrackHdr = (track) => {
  return track.color.matrixCoefficients === "bt2020" && track.color.transferCharacteristics === "arib-std-b67" && track.color.primaries === "bt2020";
};
var getIsHdr = (state) => {
  const { videoTracks } = getTracks(state);
  return videoTracks.some((track) => isVideoTrackHdr(track));
};
var hasHdr = (state) => {
  return getHasTracks(state);
};

// src/containers/iso-base-media/get-keyframes.ts
var getKeyframesFromIsoBaseMedia = (state) => {
  const { videoTracks } = getTracksFromIsoBaseMedia(state);
  const structure = state.getIsoStructure();
  const moofBox = getMoofBoxes(structure.boxes);
  const allSamples = videoTracks.map((t) => {
    const { timescale: ts } = t;
    const samplePositions = getSamplePositionsFromTrack({
      trakBox: t.trakBox,
      moofBoxes: moofBox
    });
    const keyframes = samplePositions.filter((k) => {
      return k.isKeyframe;
    }).map((k) => {
      return {
        trackId: t.trackId,
        presentationTimeInSeconds: k.cts / ts,
        decodingTimeInSeconds: k.dts / ts,
        positionInBytes: k.offset,
        sizeInBytes: k.size
      };
    });
    return keyframes;
  });
  return allSamples.flat();
};

// src/get-keyframes.ts
var getKeyframes = (state) => {
  const structure = state.getStructure();
  if (structure.type === "iso-base-media") {
    return getKeyframesFromIsoBaseMedia(state);
  }
  return null;
};
var hasKeyframes = (parserState) => {
  const structure = parserState.getStructure();
  if (structure.type === "iso-base-media") {
    return getHasTracks(parserState);
  }
  return true;
};

// src/containers/flac/get-metadata-from-flac.ts
var getMetadataFromFlac = (structure) => {
  const box = structure.boxes.find((b) => b.type === "flac-vorbis-comment");
  if (!box) {
    return null;
  }
  return box.fields;
};

// src/containers/mp3/get-metadata-from-mp3.ts
var getMetadataFromMp3 = (mp3Structure) => {
  const findHeader = mp3Structure.boxes.find((b) => b.type === "id3-header");
  return findHeader ? findHeader.metatags : null;
};

// src/containers/wav/get-metadata-from-wav.ts
var getMetadataFromWav = (structure) => {
  const list = structure.boxes.find((b) => b.type === "wav-list");
  if (!list) {
    return null;
  }
  return list.metadata;
};

// src/metadata/metadata-from-iso.ts
var mapToKey = (index) => {
  if (index === 2839630420) {
    return "artist";
  }
  if (index === 2841734242) {
    return "album";
  }
  if (index === 2841865588) {
    return "comment";
  }
  if (index === 2841928057) {
    return "releaseDate";
  }
  if (index === 2842125678) {
    return "genre";
  }
  if (index === 2842583405) {
    return "title";
  }
  if (index === 2842980207) {
    return "encoder";
  }
  if (index === 2843177588) {
    return "writer";
  }
  if (index === 2841866361) {
    return "copyright";
  }
  if (index === 2841930098) {
    return "director";
  }
  if (index === 2842718820) {
    return "producer";
  }
  if (index === 2841929075) {
    return "description";
  }
  return null;
};
var parseIlstBoxWithoutKeys = (ilstBox) => {
  return ilstBox.entries.map((entry) => {
    const key = mapToKey(entry.index);
    if (!key) {
      return null;
    }
    if (entry.value.type === "unknown") {
      return null;
    }
    return {
      trackId: null,
      key,
      value: entry.value.value
    };
  }).filter(truthy);
};
var parseIsoMetaBox = (meta, trackId) => {
  const ilstBox = meta.children.find((b) => b.type === "ilst-box");
  const keysBox = meta.children.find((b) => b.type === "keys-box");
  if (!ilstBox || !keysBox) {
    if (ilstBox) {
      return parseIlstBoxWithoutKeys(ilstBox);
    }
    return [];
  }
  const entries = [];
  for (let i = 0;i < ilstBox.entries.length; i++) {
    const ilstEntry = ilstBox.entries[i];
    const keysEntry = keysBox.entries[i];
    if (ilstEntry.value.type !== "unknown") {
      const value = typeof ilstEntry.value.value === "string" && ilstEntry.value.value.endsWith("\x00") ? ilstEntry.value.value.slice(0, -1) : ilstEntry.value.value;
      entries.push({
        key: keysEntry.value,
        value,
        trackId
      });
    }
  }
  return entries;
};
var getMetadataFromIsoBase = (state) => {
  const moov = getMoovBox(state);
  if (!moov) {
    return [];
  }
  const traks = getTraks(moov);
  const meta = moov.children.find((b) => b.type === "regular-box" && b.boxType === "meta");
  const udta = moov.children.find((b) => b.type === "regular-box" && b.boxType === "udta");
  const metaInUdta = udta?.children.find((b) => {
    return b.type === "regular-box" && b.boxType === "meta";
  });
  const metaInTracks = traks.map((t) => {
    const metaBox = t.children.find((child) => child.type === "regular-box" && child.boxType === "meta");
    if (metaBox) {
      const tkhd = getTkhdBox(t);
      if (!tkhd) {
        throw new Error("No tkhd box found");
      }
      return parseIsoMetaBox(metaBox, tkhd.trackId);
    }
    return null;
  }).filter(truthy);
  return [
    ...meta ? parseIsoMetaBox(meta, null) : [],
    ...metaInUdta ? parseIsoMetaBox(metaInUdta, null) : [],
    ...metaInTracks.flat(1)
  ];
};

// src/metadata/metadata-from-matroska.ts
var removeEndZeroes = (value) => {
  return value.endsWith("\x00") ? removeEndZeroes(value.slice(0, -1)) : value;
};
var parseSimpleTagIntoEbml = (children, trackId) => {
  const tagName = children.find((c) => c.type === "TagName");
  const tagString = children.find((c) => c.type === "TagString");
  if (!tagName || !tagString) {
    return null;
  }
  return {
    trackId,
    key: tagName.value.toLowerCase(),
    value: removeEndZeroes(tagString.value)
  };
};
var getMetadataFromMatroska = (structure) => {
  const entries = [];
  for (const segment of structure.boxes) {
    if (segment.type !== "Segment") {
      continue;
    }
    const tags2 = segment.value.filter((s) => s.type === "Tags");
    for (const tag of tags2) {
      for (const child of tag.value) {
        if (child.type !== "Tag") {
          continue;
        }
        let trackId = null;
        const target = child.value.find((c) => c.type === "Targets");
        if (target) {
          const tagTrackId = target.value.find((c) => c.type === "TagTrackUID")?.value;
          if (tagTrackId) {
            trackId = getTrackWithUid(segment, tagTrackId);
          }
        }
        const simpleTags = child.value.filter((s) => s.type === "SimpleTag");
        for (const simpleTag of simpleTags) {
          const parsed = parseSimpleTagIntoEbml(simpleTag.value, trackId);
          if (parsed) {
            entries.push(parsed);
          }
        }
      }
    }
  }
  return entries;
};

// src/metadata/metadata-from-riff.ts
var getMetadataFromRiff = (structure) => {
  const boxes = structure.boxes.find((b) => b.type === "list-box" && b.listType === "INFO");
  if (!boxes) {
    return [];
  }
  const { children } = boxes;
  return children.map((child) => {
    if (child.type !== "isft-box") {
      return null;
    }
    return {
      trackId: null,
      key: "encoder",
      value: child.software
    };
  }).filter(truthy);
};

// src/metadata/get-metadata.ts
var getMetadata = (state) => {
  const structure = state.getStructure();
  if (structure.type === "matroska") {
    return getMetadataFromMatroska(structure);
  }
  if (structure.type === "riff") {
    return getMetadataFromRiff(structure);
  }
  if (structure.type === "transport-stream") {
    return [];
  }
  if (structure.type === "mp3") {
    const tags2 = getMetadataFromMp3(structure);
    if (tags2 === null) {
      throw new Error("Failed to get metadata from mp3");
    }
    return tags2;
  }
  if (structure.type === "wav") {
    return getMetadataFromWav(structure) ?? [];
  }
  if (structure.type === "aac") {
    return [];
  }
  if (structure.type === "flac") {
    return getMetadataFromFlac(structure) ?? [];
  }
  return getMetadataFromIsoBase(state);
};
var hasMetadata = (structure) => {
  if (structure.type === "mp3") {
    return getMetadataFromMp3(structure) !== null;
  }
  if (structure.type === "wav") {
    return getMetadataFromWav(structure) !== null;
  }
  return false;
};

// src/get-location.ts
function parseLocation(locationString) {
  const locationPattern = /^([+-]\d{2}\.?\d{0,10})([+-]\d{3}\.?\d{0,10})([+-]\d+(\.\d+)?)?\/$/;
  const match = locationString.match(locationPattern);
  if (!match) {
    return null;
  }
  const latitude = parseFloat(match[1]);
  const longitude = parseFloat(match[2]);
  const altitude = match[3] ? parseFloat(match[3]) : null;
  return {
    latitude,
    longitude,
    altitude
  };
}
var getLocation = (state) => {
  const metadata = getMetadata(state);
  const locationEntry = metadata.find((entry) => entry.key === "com.apple.quicktime.location.ISO6709");
  const horizontalAccuracy = metadata.find((entry) => entry.key === "com.apple.quicktime.location.accuracy.horizontal");
  if (locationEntry) {
    const parsed = parseLocation(locationEntry.value);
    if (parsed === null) {
      return null;
    }
    return {
      ...parsed,
      horizontalAccuracy: horizontalAccuracy?.value ? parseFloat(String(horizontalAccuracy.value)) : null
    };
  }
  return null;
};

// src/get-number-of-audio-channels.ts
var getNumberOfAudioChannels = (state) => {
  return state.callbacks.tracks.getTracks().find((track) => {
    return track.type === "audio";
  })?.numberOfChannels ?? null;
};
var hasNumberOfAudioChannels = (state) => {
  return state.callbacks.tracks.hasAllTracks();
};

// src/get-sample-rate.ts
var getSampleRate3 = (state) => {
  return state.callbacks.tracks.getTracks().find((track) => {
    return track.type === "audio";
  })?.sampleRate ?? null;
};
var hasSampleRate = (state) => {
  return state.callbacks.tracks.hasAllTracks();
};

// src/emit-available-info.ts
var emitAvailableInfo = async ({
  hasInfo,
  callbacks,
  state,
  returnValue,
  name,
  mimeType,
  fieldsInReturnValue
}) => {
  const keys = Object.keys(hasInfo);
  const { emittedFields } = state;
  for (const key of keys) {
    if (key === "structure") {
      if (hasInfo.structure && !emittedFields.structure) {
        await callbacks.onStructure?.(state.getStructure());
        if (fieldsInReturnValue.structure) {
          returnValue.structure = state.getStructure();
        }
        emittedFields.structure = true;
      }
      continue;
    }
    if (key === "durationInSeconds") {
      if (hasInfo.durationInSeconds) {
        if (!emittedFields.durationInSeconds) {
          const durationInSeconds = getDuration(state);
          await callbacks.onDurationInSeconds?.(durationInSeconds);
          if (fieldsInReturnValue.durationInSeconds) {
            returnValue.durationInSeconds = durationInSeconds;
          }
          emittedFields.durationInSeconds = true;
        }
      }
      continue;
    }
    if (key === "slowDurationInSeconds") {
      if (hasInfo.slowDurationInSeconds && !emittedFields.slowDurationInSeconds) {
        const slowDurationInSeconds = getDuration(state) ?? state.slowDurationAndFps.getSlowDurationInSeconds();
        await callbacks.onSlowDurationInSeconds?.(slowDurationInSeconds);
        if (fieldsInReturnValue.slowDurationInSeconds) {
          returnValue.slowDurationInSeconds = slowDurationInSeconds;
        }
        emittedFields.slowDurationInSeconds = true;
      }
      continue;
    }
    if (key === "fps") {
      if (hasInfo.fps) {
        if (!emittedFields.fps) {
          const fps = getFps(state);
          await callbacks.onFps?.(fps);
          if (fieldsInReturnValue.fps) {
            returnValue.fps = fps;
          }
          emittedFields.fps = true;
        }
        if (!emittedFields.slowFps) {
          const fps = getFps(state);
          if (fps) {
            await callbacks.onSlowFps?.(fps);
            if (fieldsInReturnValue.slowFps) {
              returnValue.slowFps = fps;
            }
            emittedFields.slowFps = true;
          }
        }
      }
      continue;
    }
    if (key === "slowFps") {
      if (hasInfo.slowFps && !emittedFields.slowFps) {
        const slowFps = state.slowDurationAndFps.getFps();
        await callbacks.onSlowFps?.(slowFps);
        if (fieldsInReturnValue.slowFps) {
          returnValue.slowFps = slowFps;
        }
        emittedFields.slowFps = true;
      }
      continue;
    }
    if (key === "dimensions") {
      if (hasInfo.dimensions && !emittedFields.dimensions) {
        const dimensionsQueried = getDimensions(state);
        const dimensions = dimensionsQueried === null ? null : {
          height: dimensionsQueried.height,
          width: dimensionsQueried.width
        };
        await callbacks.onDimensions?.(dimensions);
        if (fieldsInReturnValue.dimensions) {
          returnValue.dimensions = dimensions;
        }
        emittedFields.dimensions = true;
      }
      continue;
    }
    if (key === "unrotatedDimensions") {
      if (hasInfo.unrotatedDimensions && !emittedFields.unrotatedDimensions) {
        const dimensionsQueried = getDimensions(state);
        const unrotatedDimensions = dimensionsQueried === null ? null : {
          height: dimensionsQueried.unrotatedHeight,
          width: dimensionsQueried.unrotatedWidth
        };
        await callbacks.onUnrotatedDimensions?.(unrotatedDimensions);
        if (fieldsInReturnValue.unrotatedDimensions) {
          returnValue.unrotatedDimensions = unrotatedDimensions;
        }
        emittedFields.unrotatedDimensions = true;
      }
      continue;
    }
    if (key === "rotation") {
      if (hasInfo.rotation && !emittedFields.rotation) {
        const dimensionsQueried = getDimensions(state);
        const rotation = dimensionsQueried?.rotation ?? 0;
        await callbacks.onRotation?.(rotation);
        if (fieldsInReturnValue.rotation) {
          returnValue.rotation = rotation;
        }
        emittedFields.rotation = true;
      }
      continue;
    }
    if (key === "videoCodec") {
      if (!emittedFields.videoCodec && hasInfo.videoCodec) {
        const videoCodec = getVideoCodec(state);
        await callbacks.onVideoCodec?.(videoCodec);
        if (fieldsInReturnValue.videoCodec) {
          returnValue.videoCodec = videoCodec;
        }
        emittedFields.videoCodec = true;
      }
      continue;
    }
    if (key === "audioCodec") {
      if (!emittedFields.audioCodec && hasInfo.audioCodec) {
        const audioCodec = getAudioCodec(state);
        await callbacks.onAudioCodec?.(audioCodec);
        if (fieldsInReturnValue.audioCodec) {
          returnValue.audioCodec = audioCodec;
        }
        emittedFields.audioCodec = true;
      }
      continue;
    }
    if (key === "tracks") {
      if (!emittedFields.tracks && hasInfo.tracks) {
        const { videoTracks, audioTracks } = getTracks(state);
        await callbacks.onTracks?.({ videoTracks, audioTracks });
        if (fieldsInReturnValue.tracks) {
          returnValue.tracks = { videoTracks, audioTracks };
        }
        emittedFields.tracks = true;
      }
      continue;
    }
    if (key === "internalStats") {
      if (hasInfo.internalStats) {
        const internalStats = state.getInternalStats();
        if (fieldsInReturnValue.internalStats) {
          returnValue.internalStats = internalStats;
        }
        emittedFields.internalStats = true;
      }
      continue;
    }
    if (key === "size") {
      if (!emittedFields.size && hasInfo.size) {
        await callbacks.onSize?.(state.contentLength);
        if (fieldsInReturnValue.size) {
          returnValue.size = state.contentLength;
        }
        emittedFields.size = true;
      }
      continue;
    }
    if (key === "mimeType") {
      if (!emittedFields.mimeType && hasInfo.mimeType) {
        await callbacks.onMimeType?.(mimeType);
        if (fieldsInReturnValue.mimeType) {
          returnValue.mimeType = mimeType;
        }
        emittedFields.mimeType = true;
      }
      continue;
    }
    if (key === "name") {
      if (!emittedFields.name && hasInfo.name) {
        await callbacks.onName?.(name);
        if (fieldsInReturnValue.name) {
          returnValue.name = name;
        }
        emittedFields.name = true;
      }
      continue;
    }
    if (key === "isHdr") {
      if (!returnValue.isHdr && hasInfo.isHdr) {
        const isHdr = getIsHdr(state);
        await callbacks.onIsHdr?.(isHdr);
        if (fieldsInReturnValue.isHdr) {
          returnValue.isHdr = isHdr;
        }
        emittedFields.isHdr = true;
      }
      continue;
    }
    if (key === "container") {
      if (!returnValue.container && hasInfo.container) {
        const container = getContainer(state.getStructure());
        await callbacks.onContainer?.(container);
        if (fieldsInReturnValue.container) {
          returnValue.container = container;
        }
        emittedFields.container = true;
      }
      continue;
    }
    if (key === "metadata") {
      if (!emittedFields.metadata && hasInfo.metadata) {
        const metadata = getMetadata(state);
        await callbacks.onMetadata?.(metadata);
        if (fieldsInReturnValue.metadata) {
          returnValue.metadata = metadata;
        }
        emittedFields.metadata = true;
      }
      continue;
    }
    if (key === "location") {
      if (!emittedFields.location && hasInfo.location) {
        const location = getLocation(state);
        await callbacks.onLocation?.(location);
        if (fieldsInReturnValue.location) {
          returnValue.location = location;
        }
        emittedFields.location = true;
      }
      continue;
    }
    if (key === "slowKeyframes") {
      if (!emittedFields.slowKeyframes && hasInfo.slowKeyframes) {
        await callbacks.onSlowKeyframes?.(state.keyframes.getKeyframes());
        if (fieldsInReturnValue.slowKeyframes) {
          returnValue.slowKeyframes = state.keyframes.getKeyframes();
        }
        emittedFields.slowKeyframes = true;
      }
      continue;
    }
    if (key === "slowNumberOfFrames") {
      if (!emittedFields.slowNumberOfFrames && hasInfo.slowNumberOfFrames) {
        await callbacks.onSlowNumberOfFrames?.(state.slowDurationAndFps.getSlowNumberOfFrames());
        if (fieldsInReturnValue.slowNumberOfFrames) {
          returnValue.slowNumberOfFrames = state.slowDurationAndFps.getSlowNumberOfFrames();
        }
        emittedFields.slowNumberOfFrames = true;
      }
      continue;
    }
    if (key === "slowAudioBitrate") {
      if (!emittedFields.slowAudioBitrate && hasInfo.slowAudioBitrate) {
        await callbacks.onSlowAudioBitrate?.(state.slowDurationAndFps.getAudioBitrate());
        if (fieldsInReturnValue.slowAudioBitrate) {
          returnValue.slowAudioBitrate = state.slowDurationAndFps.getAudioBitrate();
        }
        emittedFields.slowAudioBitrate = true;
      }
      continue;
    }
    if (key === "slowVideoBitrate") {
      if (!emittedFields.slowVideoBitrate && hasInfo.slowVideoBitrate) {
        await callbacks.onSlowVideoBitrate?.(state.slowDurationAndFps.getVideoBitrate());
        if (fieldsInReturnValue.slowVideoBitrate) {
          returnValue.slowVideoBitrate = state.slowDurationAndFps.getVideoBitrate();
        }
        emittedFields.slowVideoBitrate = true;
      }
      continue;
    }
    if (key === "keyframes") {
      if (!emittedFields.keyframes && hasInfo.keyframes) {
        await callbacks.onKeyframes?.(getKeyframes(state));
        if (fieldsInReturnValue.keyframes) {
          returnValue.keyframes = getKeyframes(state);
        }
        emittedFields.keyframes = true;
      }
      continue;
    }
    if (key === "images") {
      if (!emittedFields.images && hasInfo.images) {
        await callbacks.onImages?.(state.images.images);
        if (fieldsInReturnValue.images) {
          returnValue.images = state.images.images;
        }
        emittedFields.images = true;
      }
      continue;
    }
    if (key === "sampleRate") {
      if (!emittedFields.sampleRate && hasInfo.sampleRate) {
        const sampleRate = getSampleRate3(state);
        await callbacks.onSampleRate?.(sampleRate);
        if (fieldsInReturnValue.sampleRate) {
          returnValue.sampleRate = sampleRate;
        }
        emittedFields.sampleRate = true;
      }
      continue;
    }
    if (key === "numberOfAudioChannels") {
      if (!emittedFields.numberOfAudioChannels && hasInfo.numberOfAudioChannels) {
        const numberOfAudioChannels = getNumberOfAudioChannels(state);
        await callbacks.onNumberOfAudioChannels?.(numberOfAudioChannels);
        if (fieldsInReturnValue.numberOfAudioChannels) {
          returnValue.numberOfAudioChannels = numberOfAudioChannels;
        }
        emittedFields.numberOfAudioChannels = true;
      }
      continue;
    }
    throw new Error(`Unhandled key: ${key}`);
  }
};

// src/get-fields-from-callbacks.ts
var getFieldsFromCallback = ({
  fields,
  callbacks
}) => {
  const newFields = {
    audioCodec: Boolean(callbacks.onAudioCodec),
    container: Boolean(callbacks.onContainer),
    dimensions: Boolean(callbacks.onDimensions),
    durationInSeconds: Boolean(callbacks.onDurationInSeconds),
    fps: Boolean(callbacks.onFps),
    internalStats: Boolean(callbacks.onInternalStats),
    isHdr: Boolean(callbacks.onIsHdr),
    location: Boolean(callbacks.onLocation),
    metadata: Boolean(callbacks.onMetadata),
    mimeType: Boolean(callbacks.onMimeType),
    name: Boolean(callbacks.onName),
    rotation: Boolean(callbacks.onRotation),
    size: Boolean(callbacks.onSize),
    structure: Boolean(callbacks.onStructure),
    tracks: Boolean(callbacks.onTracks),
    unrotatedDimensions: Boolean(callbacks.onUnrotatedDimensions),
    videoCodec: Boolean(callbacks.onVideoCodec),
    slowKeyframes: Boolean(callbacks.onSlowKeyframes),
    slowDurationInSeconds: Boolean(callbacks.onSlowDurationInSeconds),
    slowFps: Boolean(callbacks.onSlowFps),
    slowNumberOfFrames: Boolean(callbacks.onSlowNumberOfFrames),
    keyframes: Boolean(callbacks.onKeyframes),
    images: Boolean(callbacks.onImages),
    numberOfAudioChannels: Boolean(callbacks.onNumberOfAudioChannels),
    sampleRate: Boolean(callbacks.onSampleRate),
    slowAudioBitrate: Boolean(callbacks.onSlowAudioBitrate),
    slowVideoBitrate: Boolean(callbacks.onSlowVideoBitrate),
    ...fields
  };
  return newFields;
};

// src/state/need-samples-for-fields.ts
var needsSamples = {
  slowDurationInSeconds: true,
  slowFps: true,
  slowKeyframes: true,
  slowNumberOfFrames: true,
  audioCodec: false,
  container: false,
  dimensions: false,
  durationInSeconds: false,
  fps: false,
  internalStats: false,
  isHdr: false,
  name: false,
  rotation: false,
  size: false,
  structure: false,
  tracks: false,
  unrotatedDimensions: false,
  videoCodec: false,
  metadata: false,
  location: false,
  mimeType: false,
  keyframes: false,
  images: false,
  numberOfAudioChannels: false,
  sampleRate: false,
  slowAudioBitrate: true,
  slowVideoBitrate: true
};
var needsToIterateOverSamples = ({
  fields,
  emittedFields
}) => {
  const keys = Object.keys(fields ?? {});
  const selectedKeys = keys.filter((k) => fields[k]);
  return selectedKeys.some((k) => needsSamples[k] && !emittedFields[k]);
};

// src/state/may-skip-video-data.ts
var maySkipVideoData = ({ state }) => {
  const hasAllTracksAndNoCallbacks = state.callbacks.tracks.hasAllTracks() && Object.values(state.callbacks.videoSampleCallbacks).length === 0 && Object.values(state.callbacks.audioSampleCallbacks).length === 0;
  const hasNoTrackHandlers = !state.callbacks.hasAudioTrackHandlers && !state.callbacks.hasVideoTrackHandlers;
  const noCallbacksNeeded = hasNoTrackHandlers || hasAllTracksAndNoCallbacks;
  return noCallbacksNeeded && !needsToIterateOverSamples({
    emittedFields: state.emittedFields,
    fields: state.fields
  });
};

// src/has-all-info.ts
var getAvailableInfo = ({
  fieldsToFetch,
  state
}) => {
  const keys = Object.entries(fieldsToFetch).filter(([, value]) => value);
  const structure = state.getStructureOrNull();
  const infos = keys.map(([_key]) => {
    const key = _key;
    if (key === "structure") {
      return false;
    }
    if (key === "durationInSeconds") {
      return Boolean(structure && hasDuration(state));
    }
    if (key === "slowDurationInSeconds") {
      return Boolean(structure && hasSlowDuration(state));
    }
    if (key === "dimensions" || key === "rotation" || key === "unrotatedDimensions") {
      return Boolean(structure && hasDimensions(state));
    }
    if (key === "fps") {
      return Boolean(structure && hasFps(state));
    }
    if (key === "slowFps") {
      return Boolean(structure && hasFpsSuitedForSlowFps(state));
    }
    if (key === "isHdr") {
      return Boolean(structure && hasHdr(state));
    }
    if (key === "videoCodec") {
      return Boolean(structure && hasVideoCodec(state));
    }
    if (key === "audioCodec") {
      return Boolean(structure && hasAudioCodec(state));
    }
    if (key === "tracks") {
      return Boolean(structure && getHasTracks(state));
    }
    if (key === "keyframes") {
      return Boolean(structure && hasKeyframes(state));
    }
    if (key === "internalStats") {
      return true;
    }
    if (key === "size") {
      return true;
    }
    if (key === "mimeType") {
      return true;
    }
    if (key === "name") {
      return true;
    }
    if (key === "container") {
      return Boolean(structure && hasContainer(structure));
    }
    if (key === "metadata" || key === "location" || key === "images") {
      return Boolean(structure && hasMetadata(structure));
    }
    if (key === "slowKeyframes" || key === "slowVideoBitrate" || key === "slowAudioBitrate" || key === "slowNumberOfFrames") {
      return false;
    }
    if (key === "numberOfAudioChannels") {
      return hasNumberOfAudioChannels(state);
    }
    if (key === "sampleRate") {
      return hasSampleRate(state);
    }
    throw new Error(`Unknown key: ${key}`);
  });
  const entries = [];
  let i = 0;
  for (const [key] of keys) {
    entries.push([key, infos[i++]]);
  }
  return Object.fromEntries(entries);
};
var hasAllInfo = ({
  fields,
  state
}) => {
  const availableInfo = getAvailableInfo({
    fieldsToFetch: fields ?? {},
    state
  });
  if (!Object.values(availableInfo).every(Boolean)) {
    return false;
  }
  const canSkipSamples = maySkipVideoData({ state }) || state.callbacks.canSkipTracksState.canSkipTracks();
  return canSkipSamples;
};

// src/emitter.ts
class MediaParserEmitter {
  listeners = {
    pause: [],
    resume: []
  };
  addEventListener = (name, callback) => {
    this.listeners[name].push(callback);
  };
  removeEventListener = (name, callback) => {
    this.listeners[name] = this.listeners[name].filter((l) => l !== callback);
  };
  dispatchEvent(dispatchName, context) {
    this.listeners[dispatchName].forEach((callback) => {
      callback({ detail: context });
    });
  }
  dispatchPause = () => {
    this.dispatchEvent("pause", undefined);
  };
  dispatchResume = () => {
    this.dispatchEvent("resume", undefined);
  };
}

// src/pause-signal.ts
var makePauseSignal = (emitter) => {
  const waiterFns = [];
  let paused = false;
  return {
    pause: () => {
      if (paused) {
        return;
      }
      emitter.dispatchPause();
      paused = true;
    },
    resume: () => {
      if (!paused) {
        return;
      }
      paused = false;
      for (const waiterFn of waiterFns) {
        waiterFn();
      }
      waiterFns.length = 0;
      emitter.dispatchResume();
    },
    waitUntilResume: () => {
      return new Promise((resolve) => {
        if (!paused) {
          resolve();
        } else {
          waiterFns.push(resolve);
        }
      });
    }
  };
};

// src/media-parser-controller.ts
var mediaParserController = () => {
  const abortController = new AbortController;
  const emitter = new MediaParserEmitter;
  const pauseSignal = makePauseSignal(emitter);
  const checkForAbortAndPause = async () => {
    if (abortController.signal.aborted) {
      throw new Error("Aborted");
    }
    await pauseSignal.waitUntilResume();
  };
  return {
    abort: (reason) => {
      abortController.abort(reason);
    },
    pause: pauseSignal.pause,
    resume: pauseSignal.resume,
    addEventListener: emitter.addEventListener,
    removeEventListener: emitter.removeEventListener,
    _internals: {
      signal: abortController.signal,
      checkForAbortAndPause
    }
  };
};

// src/perform-seek.ts
var performSeek = async ({
  seekTo,
  state,
  currentReader,
  readerInterface,
  src
}) => {
  const { iterator, logLevel, controller, mode, contentLength } = state;
  if (seekTo <= iterator.counter.getOffset()) {
    throw new Error(`Seeking backwards is not supported. Current position: ${iterator.counter.getOffset()}, seekTo: ${seekTo}`);
  }
  if (seekTo > state.contentLength) {
    throw new Error(`Unexpected seek: ${seekTo} > ${contentLength}`);
  }
  if (iterator.counter.getOffset() + iterator.bytesRemaining() >= seekTo) {
    Log.verbose(logLevel, `Skipping over video data from position ${iterator.counter.getOffset()} -> ${seekTo}. Data already fetched`);
    iterator.discard(seekTo - iterator.counter.getOffset());
    return currentReader;
  }
  if (mode === "download") {
    Log.verbose(logLevel, `Skipping over video data from position ${iterator.counter.getOffset()} -> ${seekTo}. Fetching but not reading all the data inbetween because in download mode`);
    iterator.discard(seekTo - iterator.counter.getOffset());
    return currentReader;
  }
  const time = Date.now();
  Log.verbose(logLevel, `Skipping over video data from position ${iterator.counter.getOffset()} -> ${seekTo}. Re-reading because this portion is not available`);
  currentReader.abort();
  await controller?._internals.checkForAbortAndPause();
  const { reader: newReader } = await readerInterface.read({
    src,
    range: seekTo,
    controller
  });
  iterator.skipTo(seekTo);
  await state.discardReadBytes(true);
  Log.verbose(logLevel, `Re-reading took ${Date.now() - time}ms. New position: ${iterator.counter.getOffset()}`);
  return newReader;
};

// src/remotion-license-acknowledge.ts
var warningShown = false;
var warnIfRemotionLicenseNotAcknowledged = ({
  acknowledgeRemotionLicense,
  logLevel,
  apiName
}) => {
  if (acknowledgeRemotionLicense) {
    return;
  }
  if (warningShown) {
    return;
  }
  warningShown = true;
  Log.warn(logLevel, "Note: Some companies are required to obtain a license to use @remotion/media-parser. See: https://remotion.dev/license");
  Log.warn(logLevel, `Pass \`acknowledgeRemotionLicense: true\` to \`${apiName}\` function to make this message disappear.`);
};

// src/convert-audio-or-video-sample.ts
var convertAudioOrVideoSampleToWebCodecsTimestamps = (sample, timescale) => {
  const { cts, dts, timestamp } = sample;
  return {
    cts: cts * 1e6 / timescale,
    dts: dts * 1e6 / timescale,
    timestamp: timestamp * 1e6 / timescale,
    duration: sample.duration === undefined ? undefined : sample.duration * 1e6 / timescale,
    data: sample.data,
    trackId: sample.trackId,
    type: sample.type,
    offset: sample.offset,
    timescale: 1e6
  };
};

// src/containers/aac/parse-aac.ts
var parseAac = async (state) => {
  const { iterator } = state;
  const startOffset = iterator.counter.getOffset();
  iterator.startReadingBits();
  const syncWord = iterator.getBits(12);
  if (syncWord !== 4095) {
    throw new Error("Invalid syncword: " + syncWord);
  }
  const id = iterator.getBits(1);
  if (id !== 0) {
    throw new Error("Only supporting MPEG-4 for .aac");
  }
  const layer = iterator.getBits(2);
  if (layer !== 0) {
    throw new Error("Only supporting layer 0 for .aac");
  }
  const protectionAbsent = iterator.getBits(1);
  const audioObjectType = iterator.getBits(2);
  const samplingFrequencyIndex = iterator.getBits(4);
  const sampleRate = getSampleRateFromSampleFrequencyIndex(samplingFrequencyIndex);
  iterator.getBits(1);
  const channelConfiguration = iterator.getBits(3);
  const codecPrivate2 = createAacCodecPrivate({
    audioObjectType,
    sampleRate,
    channelConfiguration,
    codecPrivate: null
  });
  iterator.getBits(1);
  iterator.getBits(1);
  iterator.getBits(1);
  iterator.getBits(1);
  const frameLength = iterator.getBits(13);
  iterator.getBits(11);
  iterator.getBits(2);
  if (!protectionAbsent) {
    iterator.getBits(16);
  }
  iterator.stopReadingBits();
  iterator.counter.decrement(iterator.counter.getOffset() - startOffset);
  const data = iterator.getSlice(frameLength);
  if (state.callbacks.tracks.getTracks().length === 0) {
    await registerTrack({
      state,
      container: "aac",
      track: {
        codec: mapAudioObjectTypeToCodecString(audioObjectType),
        codecWithoutConfig: "aac",
        codecPrivate: codecPrivate2,
        description: codecPrivate2,
        numberOfChannels: channelConfiguration,
        sampleRate,
        timescale: 1e6,
        trackId: 0,
        trakBox: null,
        type: "audio"
      }
    });
    state.callbacks.tracks.setIsDone(state.logLevel);
  }
  const duration2 = 1024 / sampleRate;
  const { index } = state.aac.addSample({ offset: startOffset, size: frameLength });
  const timestamp = 1024 / sampleRate * index;
  await state.callbacks.onAudioSample(0, convertAudioOrVideoSampleToWebCodecsTimestamps({
    duration: duration2,
    type: "key",
    data,
    offset: startOffset,
    timescale: 1e6,
    trackId: 0,
    cts: timestamp,
    dts: timestamp,
    timestamp
  }, 1));
  return Promise.resolve(null);
};

// src/skip.ts
var makeSkip = (skipTo) => ({
  action: "skip",
  skipTo
});

// src/containers/flac/get-block-size.ts
var getBlockSize = (iterator) => {
  const bits = iterator.getBits(4);
  if (bits === 0) {
    throw new Error("Reserved block size");
  }
  if (bits === 1) {
    return 192;
  }
  if (bits >= 2 && bits <= 5) {
    return 144 * 2 ** bits;
  }
  if (bits === 6) {
    return "uncommon-u8";
  }
  if (bits === 7) {
    return "uncommon-u16";
  }
  if (bits >= 8 && bits <= 15) {
    return 2 ** bits;
  }
  throw new Error("Invalid block size");
};

// src/containers/flac/get-channel-count.ts
var getChannelCount = (iterator) => {
  const bits = iterator.getBits(4);
  if (bits === 0) {
    return 1;
  }
  if (bits === 1) {
    return 2;
  }
  if (bits === 2) {
    return 3;
  }
  if (bits === 3) {
    return 4;
  }
  if (bits === 4) {
    return 5;
  }
  if (bits === 5) {
    return 6;
  }
  if (bits === 6) {
    return 7;
  }
  if (bits === 7) {
    return 8;
  }
  if (bits === 8 || bits === 9 || bits === 10) {
    return 2;
  }
  throw new Error(`Invalid channel count: ${bits.toString(2)}`);
};

// src/containers/flac/get-sample-rate.ts
var getSampleRate4 = (iterator, state) => {
  const mode = iterator.getBits(4);
  if (mode === 0) {
    const structure = state.getFlacStructure();
    const sampleRate = structure.boxes.find((box) => box.type === "flac-streaminfo")?.sampleRate ?? null;
    if (sampleRate === null) {
      throw new Error("Sample rate not found");
    }
    return sampleRate;
  }
  if (mode === 1) {
    return 88200;
  }
  if (mode === 2) {
    return 176400;
  }
  if (mode === 3) {
    return 192000;
  }
  if (mode === 4) {
    return 8000;
  }
  if (mode === 5) {
    return 16000;
  }
  if (mode === 6) {
    return 22050;
  }
  if (mode === 7) {
    return 24000;
  }
  if (mode === 8) {
    return 32000;
  }
  if (mode === 9) {
    return 44100;
  }
  if (mode === 10) {
    return 48000;
  }
  if (mode === 11) {
    return 96000;
  }
  if (mode === 12) {
    return "uncommon-u8";
  }
  if (mode === 13) {
    return "uncommon-u16";
  }
  if (mode === 14) {
    return "uncommon-u16-10";
  }
  throw new Error(`Invalid sample rate mode: ${mode.toString(2)}`);
};

// src/containers/flac/parse-flac-frame.ts
function calculateCRC8(data) {
  const polynomial = 7;
  let crc = 0;
  for (const byte of data) {
    crc ^= byte;
    for (let i = 0;i < 8; i++) {
      if ((crc & 128) !== 0) {
        crc = crc << 1 ^ polynomial;
      } else {
        crc <<= 1;
      }
      crc &= 255;
    }
  }
  return crc;
}
var parseFrameHeader = ({
  iterator,
  state
}) => {
  if (iterator.bytesRemaining() < 10) {
    return null;
  }
  const startOffset = iterator.counter.getOffset();
  iterator.discard(2);
  iterator.startReadingBits();
  const blockSizeBits = getBlockSize(iterator);
  const sampleRateBits = getSampleRate4(iterator, state);
  getChannelCount(iterator);
  iterator.getBits(3);
  iterator.getBits(1);
  const num = iterator.getFlacCodecNumber();
  const blockSize = blockSizeBits === "uncommon-u16" ? iterator.getBits(16) + 1 : blockSizeBits === "uncommon-u8" ? iterator.getBits(8) + 1 : blockSizeBits;
  const sampleRate = sampleRateBits === "uncommon-u16" ? iterator.getBits(16) : sampleRateBits === "uncommon-u16-10" ? iterator.getBits(16) * 10 : sampleRateBits === "uncommon-u8" ? iterator.getBits(8) : sampleRateBits;
  iterator.stopReadingBits();
  const size = iterator.counter.getOffset() - startOffset;
  const crc = iterator.getUint8();
  iterator.counter.decrement(size + 1);
  const crcCalculated = calculateCRC8(iterator.getSlice(size));
  iterator.counter.decrement(size);
  if (crcCalculated !== crc) {
    return null;
  }
  return { num, blockSize, sampleRate };
};
var emitSample = async ({
  state,
  data,
  offset
}) => {
  const iterator = getArrayBufferIterator(data, null);
  const parsed = parseFrameHeader({ iterator, state });
  if (!parsed) {
    throw new Error("Invalid CRC");
  }
  const { blockSize, num, sampleRate } = parsed;
  const duration2 = blockSize / sampleRate;
  const structure = state.getFlacStructure();
  const streamInfo = structure.boxes.find((box) => box.type === "flac-streaminfo");
  if (!streamInfo) {
    throw new Error("Stream info not found");
  }
  if (streamInfo.minimumBlockSize !== streamInfo.maximumBlockSize) {
    throw new Error("Cannot determine timestamp");
  }
  const timestamp = num * streamInfo.maximumBlockSize / streamInfo.sampleRate;
  await state.callbacks.onAudioSample(0, convertAudioOrVideoSampleToWebCodecsTimestamps({
    data,
    duration: duration2,
    cts: timestamp,
    dts: timestamp,
    timestamp,
    type: "key",
    offset,
    timescale: 1e6,
    trackId: 0
  }, 1));
  iterator.destroy();
};
var parseFlacFrame = async ({
  state,
  iterator
}) => {
  const blockingBit = state.flac.getBlockingBitStrategy();
  const offset = iterator.counter.getOffset();
  const { returnToCheckpoint } = iterator.startCheckpoint();
  iterator.startReadingBits();
  if (blockingBit === undefined) {
    const bits = iterator.getBits(15);
    if (bits !== 32764) {
      throw new Error("Invalid sync code");
    }
    state.flac.setBlockingBitStrategy(iterator.getBits(1));
  } else if (blockingBit === 1) {
    const bits = iterator.getBits(16);
    if (bits !== 65529) {
      throw new Error("Blocking bit changed, it should not");
    }
  } else if (blockingBit === 0) {
    const bits = iterator.getBits(16);
    if (bits !== 65528) {
      throw new Error("Blocking bit changed, it should not");
    }
  }
  const setBlockingBit = state.flac.getBlockingBitStrategy();
  if (setBlockingBit === undefined) {
    throw new Error("Blocking bit should be set");
  }
  iterator.stopReadingBits();
  const structure = state.getFlacStructure();
  const minimumFrameSize = structure.boxes.find((b) => b.type === "flac-streaminfo")?.minimumFrameSize ?? null;
  if (minimumFrameSize === null) {
    throw new Error("Expected flac-streaminfo");
  }
  if (minimumFrameSize !== 0) {
    iterator.getSlice(minimumFrameSize - 2);
  }
  while (true) {
    if (iterator.counter.getOffset() === state.contentLength) {
      const size = iterator.counter.getOffset() - offset;
      returnToCheckpoint();
      const slice = iterator.getSlice(size);
      await emitSample({ state, data: slice, offset });
      break;
    }
    if (iterator.bytesRemaining() === 0) {
      returnToCheckpoint();
      break;
    }
    const nextByte = iterator.getUint8();
    if (nextByte === 255) {
      const nextBits = iterator.getUint8();
      const expected = setBlockingBit === 1 ? 249 : 248;
      if (nextBits !== expected) {
        iterator.counter.decrement(1);
        continue;
      }
      iterator.counter.decrement(2);
      const nextIsLegit = parseFrameHeader({ iterator, state });
      if (!nextIsLegit) {
        iterator.discard(1);
        continue;
      }
      const size = iterator.counter.getOffset() - offset;
      returnToCheckpoint();
      const data = iterator.getSlice(size);
      await emitSample({ state, data, offset });
      break;
    }
  }
  return null;
};

// src/containers/flac/parse-header.ts
var parseFlacHeader = ({
  state
}) => {
  state.getFlacStructure().boxes.push({
    type: "flac-header"
  });
  return Promise.resolve(null);
};

// src/containers/flac/parse-metadata.ts
var parseVorbisComment = ({
  state,
  iterator,
  size
}) => {
  const { expectNoMoreBytes } = iterator.startBox(size);
  const box = {
    type: "flac-vorbis-comment",
    fields: []
  };
  const vendorLength = iterator.getUint32Le();
  const vendorString = iterator.getByteString(vendorLength, true);
  const numberOfFields = iterator.getUint32Le();
  box.fields.push({ key: "vendor", value: vendorString, trackId: null });
  for (let i = 0;i < numberOfFields; i++) {
    const fieldLength = iterator.getUint32Le();
    const field = iterator.getByteString(fieldLength, true);
    const [key, value] = field.split("=");
    box.fields.push({ key: key.toLowerCase(), value, trackId: null });
  }
  state.getFlacStructure().boxes.push(box);
  expectNoMoreBytes();
  return Promise.resolve(null);
};

// src/containers/flac/parse-streaminfo.ts
var parseStreamInfo = async ({
  iterator,
  state
}) => {
  const counter = iterator.counter.getOffset();
  const minimumBlockSize = iterator.getUint16();
  const maximumBlockSize = iterator.getUint16();
  const minimumFrameSize = iterator.getUint24();
  const maximumFrameSize = iterator.getUint24();
  iterator.startReadingBits();
  const sampleRate = iterator.getBits(20);
  const channels2 = iterator.getBits(3) + 1;
  const bitsPerSample = iterator.getBits(5);
  const totalSamples = iterator.getBits(36);
  iterator.getBits(128);
  iterator.stopReadingBits();
  const counterNow = iterator.counter.getOffset();
  const size = counterNow - counter;
  iterator.counter.decrement(size);
  const asUint8Array = iterator.getSlice(size);
  const flacStreamInfo = {
    type: "flac-streaminfo",
    bitsPerSample,
    channels: channels2,
    maximumBlockSize,
    maximumFrameSize,
    minimumBlockSize,
    minimumFrameSize,
    sampleRate,
    totalSamples
  };
  state.getFlacStructure().boxes.push(flacStreamInfo);
  await registerTrack({
    container: "flac",
    state,
    track: {
      codec: "flac",
      type: "audio",
      description: asUint8Array,
      codecPrivate: asUint8Array,
      codecWithoutConfig: "flac",
      numberOfChannels: channels2,
      sampleRate,
      timescale: 1e6,
      trackId: 0,
      trakBox: null
    }
  });
  state.callbacks.tracks.setIsDone(state.logLevel);
  return Promise.resolve(null);
};

// src/containers/flac/parse-unknown-block.ts
var parseFlacUnkownBlock = ({
  iterator,
  state,
  size
}) => {
  iterator.discard(size);
  state.getFlacStructure().boxes.push({
    type: "flac-header"
  });
  return Promise.resolve(null);
};

// src/containers/flac/parse-flac.ts
var flacTypes = {
  streaminfo: 0,
  vorbisComment: 4
};
var parseFlac = ({
  iterator,
  state
}) => {
  const videoSectionState = state.videoSection.isInVideoSectionState(iterator);
  if (videoSectionState === "in-section") {
    if (maySkipVideoData({ state })) {
      return Promise.resolve(makeSkip(state.contentLength));
    }
    return parseFlacFrame({ state, iterator });
  }
  const bytes = iterator.getByteString(4, true);
  if (bytes === "fLaC") {
    return parseFlacHeader({ state, iterator });
  }
  iterator.counter.decrement(4);
  iterator.startReadingBits();
  const isLastMetadata = iterator.getBits(1);
  const metaBlockType = iterator.getBits(7);
  iterator.stopReadingBits();
  const size = iterator.getUint24();
  if (isLastMetadata) {
    state.videoSection.setVideoSection({
      start: iterator.counter.getOffset() + size,
      size: state.contentLength - iterator.counter.getOffset() - size
    });
  }
  if (metaBlockType === flacTypes.streaminfo) {
    return parseStreamInfo({ iterator, state });
  }
  if (metaBlockType === flacTypes.vorbisComment) {
    return parseVorbisComment({ iterator, state, size });
  }
  return parseFlacUnkownBlock({ iterator, state, size });
};

// src/state/iso-base-media/cached-sample-positions.ts
var calculateFlatSamples = (state) => {
  const tracks2 = getTracks(state);
  const allTracks = [
    ...tracks2.videoTracks,
    ...tracks2.audioTracks,
    ...tracks2.otherTracks
  ];
  const flatSamples = allTracks.map((track) => {
    const samplePositions = getSamplePositionsFromTrack({
      trakBox: track.trakBox,
      moofBoxes: getMoofBoxes(state.getIsoStructure().boxes)
    });
    if (!samplePositions) {
      throw new Error("No sample positions");
    }
    return samplePositions.map((samplePosition) => {
      return {
        track,
        samplePosition
      };
    });
  }).flat(1);
  return flatSamples;
};
var cachedSamplePositionsState = () => {
  const cachedForMdatStar = {};
  return {
    getSamples: (mdatStart) => {
      if (cachedForMdatStar[mdatStart]) {
        return cachedForMdatStar[mdatStart];
      }
      return null;
    },
    setSamples: (mdatStart, samples) => {
      cachedForMdatStar[mdatStart] = samples;
    }
  };
};

// src/state/aac-state.ts
var aacState = () => {
  const samples = [];
  return {
    addSample: ({ offset, size }) => {
      if (samples.find((s) => s.offset === offset)) {
        throw new Error("Duplicate sample");
      }
      samples.push({ offset, index: samples.length, size });
      return samples[samples.length - 1];
    },
    getSamples: () => samples
  };
};

// src/state/emitted-fields.ts
var emittedState = () => {
  const emittedFields = {
    audioCodec: false,
    container: false,
    dimensions: false,
    durationInSeconds: false,
    fps: false,
    internalStats: false,
    isHdr: false,
    location: false,
    metadata: false,
    mimeType: false,
    name: false,
    rotation: false,
    size: false,
    structure: false,
    tracks: false,
    videoCodec: false,
    unrotatedDimensions: false,
    slowDurationInSeconds: false,
    slowFps: false,
    slowKeyframes: false,
    slowNumberOfFrames: false,
    keyframes: false,
    images: false,
    numberOfAudioChannels: false,
    sampleRate: false,
    slowAudioBitrate: false,
    slowVideoBitrate: false
  };
  return emittedFields;
};

// src/state/flac-state.ts
var flacState = () => {
  let blockingBitStrategy;
  return {
    setBlockingBitStrategy: (strategy) => {
      blockingBitStrategy = strategy;
    },
    getBlockingBitStrategy: () => blockingBitStrategy
  };
};

// src/state/images.ts
var imagesState = () => {
  const images = [];
  const addImage = (image) => {
    images.push(image);
  };
  return {
    images,
    addImage
  };
};

// src/state/iso-base-media/moov-box.ts
var moovState = () => {
  let moovBox = null;
  return {
    setMoovBox: (moov) => {
      moovBox = moov;
    },
    getMoovBox: () => moovBox
  };
};

// src/state/iso-base-media/iso-state.ts
var isoBaseMediaState = () => {
  return {
    flatSamples: cachedSamplePositionsState(),
    moov: moovState()
  };
};

// src/state/keyframes.ts
var keyframesState = () => {
  const keyframes = [];
  return {
    addKeyframe: (keyframe) => {
      keyframes.push(keyframe);
    },
    getKeyframes: () => {
      return keyframes;
    }
  };
};

// src/state/last-eventloop-break.ts
var eventLoopState = (logLevel) => {
  let lastEventLoopBreak = Date.now();
  const eventLoopBreakIfNeeded = async () => {
    if (Date.now() - lastEventLoopBreak > 2000) {
      await new Promise((resolve) => {
        setTimeout(() => resolve(), 50);
      });
      Log.verbose(logLevel, "10ms event loop break");
      lastEventLoopBreak = Date.now();
    }
  };
  return { eventLoopBreakIfNeeded };
};

// src/state/mp3.ts
var makeMp3State = () => {
  let mp3Info = null;
  return {
    getMp3Info: () => mp3Info,
    setMp3Info: (info) => {
      mp3Info = info;
    }
  };
};

// src/state/riff.ts
var riffSpecificState = () => {
  let avcProfile = null;
  let nextTrackIndex = 0;
  const profileCallbacks = [];
  const registerOnAvcProfileCallback = (callback) => {
    profileCallbacks.push(callback);
  };
  const onProfile = async (profile) => {
    avcProfile = profile;
    for (const callback of profileCallbacks) {
      await callback(profile);
    }
    profileCallbacks.length = 0;
  };
  return {
    getAvcProfile: () => {
      return avcProfile;
    },
    onProfile,
    registerOnAvcProfileCallback,
    getNextTrackIndex: () => {
      return nextTrackIndex;
    },
    incrementNextTrackIndex: () => {
      nextTrackIndex++;
    }
  };
};

// src/state/can-skip-tracks.ts
var needsTracksForField = ({
  field,
  structure
}) => {
  if (field === "dimensions") {
    if (structure.type === "riff") {
      return false;
    }
    return true;
  }
  if (field === "audioCodec" || field === "durationInSeconds" || field === "slowDurationInSeconds" || field === "slowFps" || field === "fps" || field === "isHdr" || field === "rotation" || field === "structure" || field === "tracks" || field === "unrotatedDimensions" || field === "videoCodec" || field === "metadata" || field === "location" || field === "slowKeyframes" || field === "slowNumberOfFrames" || field === "keyframes" || field === "images" || field === "sampleRate" || field === "numberOfAudioChannels" || field === "slowAudioBitrate" || field === "slowVideoBitrate") {
    return true;
  }
  if (field === "container" || field === "internalStats" || field === "mimeType" || field === "name" || field === "size") {
    return false;
  }
  throw new Error(`field not implemeted ${field}`);
};
var makeCanSkipTracksState = ({
  hasAudioTrackHandlers,
  fields,
  hasVideoTrackHandlers,
  structure
}) => {
  return {
    canSkipTracks: () => {
      if (hasAudioTrackHandlers || hasVideoTrackHandlers) {
        return false;
      }
      const keys = Object.keys(fields ?? {});
      const selectedKeys = keys.filter((k) => fields[k]);
      return !selectedKeys.some((k) => needsTracksForField({ field: k, structure: structure.getStructure() }));
    }
  };
};

// src/state/has-tracks-section.ts
var makeTracksSectionState = (canSkipTracksState) => {
  const tracks2 = [];
  let doneWithTracks = false;
  return {
    hasAllTracks: () => doneWithTracks,
    getIsDone: () => doneWithTracks,
    setIsDone: (logLevel) => {
      if (doneWithTracks) {
        throw new Error("Error in Media Parser: Tracks have already been parsed");
      }
      Log.verbose(logLevel, "All tracks have been parsed");
      doneWithTracks = true;
    },
    addTrack: (track) => {
      tracks2.push(track);
    },
    getTracks: () => tracks2,
    ensureHasTracksAtEnd: (fields) => {
      if (canSkipTracksState.canSkipTracks()) {
        return;
      }
      if (!fields.tracks) {
        return;
      }
      if (!doneWithTracks) {
        throw new Error("Error in Media Parser: End of parsing has been reached, but no tracks have been found");
      }
    }
  };
};

// src/state/sample-callbacks.ts
var sampleCallback = ({
  controller,
  hasAudioTrackHandlers,
  hasVideoTrackHandlers,
  fields,
  keyframes,
  emittedFields,
  slowDurationAndFpsState,
  structure
}) => {
  const videoSampleCallbacks = {};
  const audioSampleCallbacks = {};
  const queuedAudioSamples = {};
  const queuedVideoSamples = {};
  const canSkipTracksState = makeCanSkipTracksState({
    hasAudioTrackHandlers,
    fields,
    hasVideoTrackHandlers,
    structure
  });
  const tracksState = makeTracksSectionState(canSkipTracksState);
  const samplesForTrack = {};
  return {
    registerVideoSampleCallback: async (id, callback) => {
      if (callback === null) {
        delete videoSampleCallbacks[id];
        return;
      }
      videoSampleCallbacks[id] = callback;
      for (const queued of queuedVideoSamples[id] ?? []) {
        await callback(queued);
      }
      queuedVideoSamples[id] = [];
    },
    onAudioSample: async (trackId, audioSample) => {
      if (controller._internals.signal.aborted) {
        throw new Error("Aborted");
      }
      if (typeof samplesForTrack[trackId] === "undefined") {
        samplesForTrack[trackId] = 0;
      }
      const callback = audioSampleCallbacks[trackId];
      if (audioSample.data.length > 0) {
        samplesForTrack[trackId]++;
        if (callback) {
          await callback(audioSample);
        }
      }
      if (needsToIterateOverSamples({ emittedFields, fields })) {
        slowDurationAndFpsState.addAudioSample(audioSample);
      }
    },
    getSamplesForTrack: (trackId) => {
      return samplesForTrack[trackId] ?? 0;
    },
    onVideoSample: async (trackId, videoSample) => {
      if (controller._internals.signal.aborted) {
        throw new Error("Aborted");
      }
      if (typeof samplesForTrack[trackId] === "undefined") {
        samplesForTrack[trackId] = 0;
      }
      if (videoSample.data.length > 0) {
        samplesForTrack[trackId]++;
        const callback = videoSampleCallbacks[trackId];
        if (callback) {
          await callback(videoSample);
        }
      }
      if (needsToIterateOverSamples({
        fields,
        emittedFields
      })) {
        if (fields.slowKeyframes && videoSample.type === "key") {
          keyframes.addKeyframe({
            trackId,
            decodingTimeInSeconds: videoSample.dts / videoSample.timescale,
            positionInBytes: videoSample.offset,
            presentationTimeInSeconds: videoSample.cts / videoSample.timescale,
            sizeInBytes: videoSample.data.length
          });
        }
        slowDurationAndFpsState.addVideoSample(videoSample);
      }
    },
    canSkipTracksState,
    registerAudioSampleCallback: async (id, callback) => {
      if (callback === null) {
        delete audioSampleCallbacks[id];
        return;
      }
      audioSampleCallbacks[id] = callback;
      for (const queued of queuedAudioSamples[id] ?? []) {
        await callback(queued);
      }
      queuedAudioSamples[id] = [];
    },
    tracks: tracksState,
    audioSampleCallbacks,
    videoSampleCallbacks,
    hasAudioTrackHandlers,
    hasVideoTrackHandlers
  };
};

// src/state/slow-duration-fps.ts
var slowDurationAndFpsState = () => {
  let smallestVideoSample;
  let largestVideoSample;
  let smallestAudioSample;
  let largestAudioSample;
  let audioSizesInBytes = 0;
  let videoSizeInBytes = 0;
  let videoSamples = 0;
  let audioSamples = 0;
  const getSlowVideoDurationInSeconds = () => {
    let videoDuration = null;
    if (smallestVideoSample !== undefined && largestVideoSample !== undefined) {
      const startingTimestampDifference = largestVideoSample - smallestVideoSample;
      const timeBetweenSamples = startingTimestampDifference / (videoSamples - 1);
      videoDuration = timeBetweenSamples * videoSamples;
    }
    return videoDuration;
  };
  const getSlowDurationInSeconds = () => {
    const videoDuration = getSlowVideoDurationInSeconds();
    let audioDuration = null;
    if (smallestAudioSample !== undefined && largestAudioSample !== undefined) {
      const startingTimestampDifferenceAudio = largestAudioSample - smallestAudioSample;
      const timeBetweenSamplesAudio = startingTimestampDifferenceAudio / (audioSamples - 1);
      audioDuration = timeBetweenSamplesAudio * audioSamples;
    }
    if (videoDuration === null && audioDuration === null) {
      throw new Error("No samples");
    }
    return Math.max(videoDuration ?? 0, audioDuration ?? 0);
  };
  return {
    addVideoSample: (videoSample) => {
      videoSamples++;
      const presentationTimeInSeconds = videoSample.cts / videoSample.timescale;
      if (largestVideoSample === undefined || presentationTimeInSeconds > largestVideoSample) {
        largestVideoSample = presentationTimeInSeconds;
      }
      if (smallestVideoSample === undefined || presentationTimeInSeconds < smallestVideoSample) {
        smallestVideoSample = presentationTimeInSeconds;
      }
      videoSizeInBytes += videoSample.data.byteLength;
    },
    addAudioSample: (audioSample) => {
      audioSamples++;
      const presentationTimeInSeconds = audioSample.cts / audioSample.timescale;
      if (largestAudioSample === undefined || presentationTimeInSeconds > largestAudioSample) {
        largestAudioSample = presentationTimeInSeconds;
      }
      if (smallestAudioSample === undefined || presentationTimeInSeconds < smallestAudioSample) {
        smallestAudioSample = presentationTimeInSeconds;
      }
      audioSizesInBytes += audioSample.data.byteLength;
    },
    getSlowDurationInSeconds,
    getFps: () => {
      const videoDuration = getSlowVideoDurationInSeconds() ?? 0;
      if (videoDuration === 0) {
        return 0;
      }
      return videoSamples / videoDuration;
    },
    getSlowNumberOfFrames: () => videoSamples,
    getAudioBitrate: () => {
      const audioDuration = getSlowDurationInSeconds();
      if (audioDuration === 0 || audioSizesInBytes === 0) {
        return null;
      }
      return audioSizesInBytes * 8 / audioDuration;
    },
    getVideoBitrate: () => {
      const videoDuration = getSlowDurationInSeconds();
      if (videoDuration === 0 || videoSizeInBytes === 0) {
        return null;
      }
      return videoSizeInBytes * 8 / videoDuration;
    }
  };
};

// src/state/structure.ts
var structureState = () => {
  let structure = null;
  const getStructure = () => {
    if (structure === null) {
      throw new Error("Expected structure");
    }
    return structure;
  };
  return {
    getStructureOrNull: () => {
      return structure;
    },
    getStructure,
    setStructure: (value) => {
      structure = value;
    },
    getFlacStructure: () => {
      const struc = getStructure();
      if (struc.type !== "flac") {
        throw new Error("Invalid structure type");
      }
      return struc;
    },
    getIsoStructure: () => {
      const struc = getStructure();
      if (struc.type !== "iso-base-media") {
        throw new Error("Invalid structure type");
      }
      return struc;
    },
    getMp3Structure: () => {
      const struc = getStructure();
      if (struc.type !== "mp3") {
        throw new Error("Invalid structure type");
      }
      return struc;
    },
    getRiffStructure: () => {
      const struc = getStructure();
      if (struc.type !== "riff") {
        throw new Error("Invalid structure type");
      }
      return struc;
    },
    getTsStructure: () => {
      const struc = getStructure();
      if (struc.type !== "transport-stream") {
        throw new Error("Invalid structure type");
      }
      return struc;
    },
    getWavStructure: () => {
      const struc = getStructure();
      if (struc.type !== "wav") {
        throw new Error("Invalid structure type");
      }
      return struc;
    },
    getMatroskaStructure: () => {
      const struc = getStructure();
      if (struc.type !== "matroska") {
        throw new Error("Invalid structure type");
      }
      return struc;
    }
  };
};

// src/containers/transport-stream/next-pes-header-store.ts
var makeNextPesHeaderStore = () => {
  let nextPesHeader = null;
  return {
    setNextPesHeader: (pesHeader) => {
      nextPesHeader = pesHeader;
    },
    getNextPesHeader: () => {
      if (!nextPesHeader) {
        throw new Error("No next PES header found");
      }
      return nextPesHeader;
    }
  };
};

// src/state/transport-stream.ts
var transportStreamState = () => {
  return {
    nextPesHeaderStore: makeNextPesHeaderStore(),
    streamBuffers: new Map
  };
};

// src/state/video-section.ts
var videoSectionState = () => {
  let videoSection = null;
  const setVideoSection = (section) => {
    videoSection = section;
  };
  const getVideoSection = () => {
    if (!videoSection) {
      throw new Error("No video section defined");
    }
    return videoSection;
  };
  const isInVideoSectionState = (iterator) => {
    if (!videoSection) {
      return "no-section-defined";
    }
    const offset = iterator.counter.getOffset();
    if (offset >= videoSection.start && offset < videoSection.start + videoSection.size) {
      return "in-section";
    }
    return "outside-section";
  };
  return {
    setVideoSection,
    getVideoSection,
    isInVideoSectionState
  };
};

// src/state/webm.ts
var webmState = () => {
  const trackEntries = {};
  const onTrackEntrySegment = (trackEntry2) => {
    const trackId = getTrackId(trackEntry2);
    if (!trackId) {
      throw new Error("Expected track id");
    }
    if (trackEntries[trackId]) {
      return;
    }
    const codec = getTrackCodec(trackEntry2);
    if (!codec) {
      throw new Error("Expected codec");
    }
    const trackTimescale = getTrackTimestampScale(trackEntry2);
    trackEntries[trackId] = {
      codec: codec.value,
      trackTimescale: trackTimescale?.value ?? null
    };
  };
  const timestampMap = new Map;
  const getTimestampOffsetForByteOffset = (byteOffset) => {
    const entries = Array.from(timestampMap.entries());
    const sortedByByteOffset = entries.sort((a, b) => {
      return a[0] - b[0];
    }).reverse();
    for (const [offset, timestamp] of sortedByByteOffset) {
      if (offset >= byteOffset) {
        continue;
      }
      return timestamp;
    }
    return timestampMap.get(byteOffset);
  };
  const setTimestampOffset = (byteOffset, timestamp) => {
    timestampMap.set(byteOffset, timestamp);
  };
  let timescale = null;
  const setTimescale = (newTimescale) => {
    timescale = newTimescale;
  };
  const getTimescale = () => {
    if (timescale === null) {
      return 1e6;
    }
    return timescale;
  };
  const segments = [];
  const clusters = [];
  return {
    onTrackEntrySegment,
    getTrackInfoByNumber: (id) => trackEntries[id],
    setTimestampOffset,
    getTimestampOffsetForByteOffset,
    timescale,
    getTimescale,
    setTimescale,
    addSegment: (seg) => {
      const segment = {
        ...seg,
        index: segments.length
      };
      segments.push(segment);
    },
    addCluster: (cluster) => {
      clusters.push(cluster);
    },
    isInsideSegment: (iterator) => {
      const offset = iterator.counter.getOffset();
      const insideClusters = segments.filter((cluster) => {
        return offset >= cluster.start && offset <= cluster.start + cluster.size;
      });
      if (insideClusters.length > 1) {
        throw new Error("Expected to only be inside 1 cluster");
      }
      return insideClusters[0] ?? null;
    },
    isInsideCluster: (iterator) => {
      for (const cluster of clusters) {
        const offset = iterator.counter.getOffset();
        if (offset >= cluster.start && offset <= cluster.start + cluster.size) {
          return cluster;
        }
      }
      return null;
    }
  };
};

// src/state/parser-state.ts
var makeParserState = ({
  hasAudioTrackHandlers,
  hasVideoTrackHandlers,
  controller,
  fields,
  onAudioTrack,
  onVideoTrack,
  contentLength,
  logLevel,
  mode,
  src,
  readerInterface,
  onDiscardedData
}) => {
  let skippedBytes = 0;
  const iterator = getArrayBufferIterator(new Uint8Array([]), contentLength);
  const increaseSkippedBytes = (bytes) => {
    skippedBytes += bytes;
  };
  const structure = structureState();
  const keyframes = keyframesState();
  const emittedFields = emittedState();
  const slowDurationAndFps = slowDurationAndFpsState();
  const mp3Info = makeMp3State();
  const images = imagesState();
  const discardReadBytes = async (force) => {
    const { bytesRemoved, removedData } = iterator.removeBytesRead(force, mode);
    if (bytesRemoved) {
      Log.verbose(logLevel, `Freed ${bytesRemoved} bytes`);
    }
    if (removedData && onDiscardedData) {
      await onDiscardedData(removedData);
    }
  };
  return {
    riff: riffSpecificState(),
    transportStream: transportStreamState(),
    webm: webmState(),
    iso: isoBaseMediaState(),
    mp3Info,
    aac: aacState(),
    flac: flacState(),
    callbacks: sampleCallback({
      controller,
      hasAudioTrackHandlers,
      hasVideoTrackHandlers,
      fields,
      keyframes,
      emittedFields,
      slowDurationAndFpsState: slowDurationAndFps,
      structure
    }),
    getInternalStats: () => ({
      skippedBytes,
      finalCursorOffset: iterator.counter.getOffset() ?? 0
    }),
    getSkipBytes: () => skippedBytes,
    increaseSkippedBytes,
    keyframes,
    ...structure,
    onAudioTrack,
    onVideoTrack,
    emittedFields,
    fields,
    slowDurationAndFps,
    contentLength,
    images,
    videoSection: videoSectionState(),
    logLevel,
    iterator,
    controller,
    mode,
    eventLoop: eventLoopState(logLevel),
    src,
    readerInterface,
    discardReadBytes
  };
};

// src/containers/iso-base-media/get-moov-atom.ts
var getMoovAtom = async ({
  endOfMdat,
  state
}) => {
  const start = Date.now();
  Log.verbose(state.logLevel, "Starting second fetch to get moov atom");
  const { reader } = await state.readerInterface.read({
    src: state.src,
    range: endOfMdat,
    controller: state.controller
  });
  const childState = makeParserState({
    hasAudioTrackHandlers: false,
    hasVideoTrackHandlers: false,
    controller: state.controller,
    fields: {
      structure: true
    },
    onAudioTrack: state.onAudioTrack ? async ({ track, container }) => {
      await registerTrack({ state, track, container });
      return null;
    } : null,
    onVideoTrack: state.onVideoTrack ? async ({ track, container }) => {
      await registerTrack({ state, track, container });
      return null;
    } : null,
    contentLength: state.contentLength,
    logLevel: state.logLevel,
    mode: "query",
    readerInterface: state.readerInterface,
    src: state.src,
    onDiscardedData: null
  });
  while (true) {
    const result = await reader.reader.read();
    if (result.value) {
      childState.iterator.addData(result.value);
    }
    if (result.done) {
      break;
    }
  }
  const boxes = [];
  while (true) {
    const box = await processBox(childState);
    if (box) {
      boxes.push(box);
    }
    if (childState.iterator.counter.getOffset() + endOfMdat > state.contentLength) {
      throw new Error("Read past end of file");
    }
    if (childState.iterator.counter.getOffset() + endOfMdat === state.contentLength) {
      break;
    }
  }
  const moov = boxes.find((b) => b.type === "moov-box");
  if (!moov) {
    throw new Error("No moov box found");
  }
  Log.verbose(state.logLevel, `Finished fetching moov atom in ${Date.now() - start}ms`);
  return moov;
};

// src/containers/iso-base-media/mdat/mdat.ts
var parseMdatSection = async (state) => {
  const videoSection = state.videoSection.getVideoSection();
  const endOfMdat = videoSection.size + videoSection.start;
  if (maySkipVideoData({ state })) {
    return makeSkip(endOfMdat);
  }
  const alreadyHas = getHasTracks(state);
  if (!alreadyHas) {
    const moov = await getMoovAtom({
      endOfMdat,
      state
    });
    state.iso.moov.setMoovBox(moov);
    state.callbacks.tracks.setIsDone(state.logLevel);
    state.getIsoStructure().boxes.push(moov);
    return parseMdatSection(state);
  }
  if (!state.iso.flatSamples.getSamples(videoSection.start)) {
    state.iso.flatSamples.setSamples(videoSection.start, calculateFlatSamples(state));
  }
  const flatSamples = state.iso.flatSamples.getSamples(videoSection.start);
  const { iterator } = state;
  const samplesWithIndex = flatSamples.find((sample) => {
    return sample.samplePosition.offset === iterator.counter.getOffset();
  });
  if (!samplesWithIndex) {
    const nextSample_ = flatSamples.filter((s) => s.samplePosition.offset > iterator.counter.getOffset()).sort((a, b) => a.samplePosition.offset - b.samplePosition.offset)[0];
    if (nextSample_) {
      iterator.discard(nextSample_.samplePosition.offset - iterator.counter.getOffset());
      return null;
    }
    return makeSkip(endOfMdat);
  }
  if (iterator.bytesRemaining() < samplesWithIndex.samplePosition.size) {
    return null;
  }
  const bytes = iterator.getSlice(samplesWithIndex.samplePosition.size);
  const { cts, dts, duration: duration2, isKeyframe, offset } = samplesWithIndex.samplePosition;
  if (samplesWithIndex.track.type === "audio") {
    await state.callbacks.onAudioSample(samplesWithIndex.track.trackId, convertAudioOrVideoSampleToWebCodecsTimestamps({
      data: bytes,
      timestamp: cts,
      duration: duration2,
      cts,
      dts,
      trackId: samplesWithIndex.track.trackId,
      type: isKeyframe ? "key" : "delta",
      offset,
      timescale: samplesWithIndex.track.timescale
    }, samplesWithIndex.track.timescale));
  }
  if (samplesWithIndex.track.type === "video") {
    const nalUnitType = bytes[4] & 31;
    let isRecoveryPoint = false;
    if (nalUnitType === 6) {
      const seiType = bytes[5];
      isRecoveryPoint = seiType === 6;
    }
    await state.callbacks.onVideoSample(samplesWithIndex.track.trackId, convertAudioOrVideoSampleToWebCodecsTimestamps({
      data: bytes,
      timestamp: cts,
      duration: duration2,
      cts,
      dts,
      trackId: samplesWithIndex.track.trackId,
      type: isKeyframe && !isRecoveryPoint ? "key" : "delta",
      offset,
      timescale: samplesWithIndex.track.timescale
    }, samplesWithIndex.track.timescale));
  }
  return null;
};

// src/containers/iso-base-media/parse-boxes.ts
var parseIsoBaseMedia = async (state) => {
  const videoSectionState2 = state.videoSection.isInVideoSectionState(state.iterator);
  if (videoSectionState2 === "in-section") {
    const skipTo = await parseMdatSection(state);
    return skipTo;
  }
  const result = await processBox(state);
  if (result) {
    state.getIsoStructure().boxes.push(result);
  }
  return null;
};

// src/containers/mp3/id3.ts
function combine28Bits(a, b, c, d) {
  const val1 = a & 127;
  const val2 = b & 127;
  const val3 = c & 127;
  const val4 = d & 127;
  return val1 << 21 | val2 << 14 | val3 << 7 | val4;
}
var parseId3 = ({ state }) => {
  const { iterator } = state;
  if (iterator.bytesRemaining() < 9) {
    return;
  }
  const { returnToCheckpoint } = iterator.startCheckpoint();
  iterator.discard(3);
  const versionMajor = iterator.getUint8();
  const versionMinor = iterator.getUint8();
  const flags = iterator.getUint8();
  const sizeArr = iterator.getSlice(4);
  const size = combine28Bits(sizeArr[0], sizeArr[1], sizeArr[2], sizeArr[3]);
  if (iterator.bytesRemaining() < size) {
    returnToCheckpoint();
    return;
  }
  const entries = [];
  const initial = iterator.counter.getOffset();
  while (iterator.counter.getOffset() < size + initial) {
    const name = versionMajor === 3 || versionMajor === 4 ? iterator.getByteString(4, true) : iterator.getByteString(3, true);
    if (name === "") {
      iterator.discard(size + initial - iterator.counter.getOffset());
      break;
    }
    const s = versionMajor === 4 ? iterator.getSyncSafeInt32() : versionMajor === 3 ? iterator.getUint32() : iterator.getUint24();
    if (versionMajor === 3 || versionMajor === 4) {
      iterator.getUint16();
    }
    let subtract = 0;
    if (!name.startsWith("W")) {
      iterator.getUint8();
      subtract += 1;
    }
    if (name === "APIC") {
      const { discardRest } = iterator.planBytes(s - subtract);
      const mimeType = iterator.readUntilNullTerminator();
      iterator.getUint16();
      const description = iterator.readUntilNullTerminator();
      iterator.discard(1);
      const data = discardRest();
      state.images.addImage({
        data,
        description,
        mimeType
      });
    } else {
      const information = iterator.getByteString(s - subtract, true);
      entries.push({
        key: name,
        value: information,
        trackId: null
      });
    }
  }
  state.getMp3Structure().boxes.push({
    type: "id3-header",
    flags,
    size,
    versionMajor,
    versionMinor,
    metatags: entries
  });
};

// src/containers/mp3/id3-v1.ts
var parseID3V1 = (iterator) => {
  if (iterator.bytesRemaining() < 128) {
    return;
  }
  iterator.discard(128);
};

// src/containers/mp3/parse-mpeg-header.ts
function getSamplingFrequency({
  bits,
  mpegVersion
}) {
  const samplingTable = {
    0: { MPEG1: 44100, MPEG2: 22050 },
    1: { MPEG1: 48000, MPEG2: 24000 },
    2: { MPEG1: 32000, MPEG2: 16000 },
    3: { MPEG1: "reserved", MPEG2: "reserved" }
  };
  const key = `MPEG${mpegVersion}`;
  const value = samplingTable[bits][key];
  if (value === "reserved") {
    throw new Error("Reserved sampling frequency");
  }
  if (!value) {
    throw new Error("Invalid sampling frequency for MPEG version: " + JSON.stringify({ bits, version: mpegVersion }));
  }
  return value;
}
function getBitrateKB({
  bits,
  mpegVersion,
  level
}) {
  const bitrateTable = {
    0: {
      "V1,L1": "free",
      "V1,L2": "free",
      "V1,L3": "free",
      "V2,L1": "free",
      "V2,L2&L3": "free"
    },
    1: { "V1,L1": 32, "V1,L2": 32, "V1,L3": 32, "V2,L1": 32, "V2,L2&L3": 8 },
    2: {
      "V1,L1": 64,
      "V1,L2": 48,
      "V1,L3": 40,
      "V2,L1": 48,
      "V2,L2&L3": 16
    },
    3: {
      "V1,L1": 96,
      "V1,L2": 56,
      "V1,L3": 48,
      "V2,L1": 56,
      "V2,L2&L3": 24
    },
    4: {
      "V1,L1": 128,
      "V1,L2": 64,
      "V1,L3": 56,
      "V2,L1": 64,
      "V2,L2&L3": 32
    },
    5: {
      "V1,L1": 160,
      "V1,L2": 80,
      "V1,L3": 64,
      "V2,L1": 80,
      "V2,L2&L3": 40
    },
    6: {
      "V1,L1": 192,
      "V1,L2": 96,
      "V1,L3": 80,
      "V2,L1": 96,
      "V2,L2&L3": 48
    },
    7: {
      "V1,L1": 224,
      "V1,L2": 112,
      "V1,L3": 96,
      "V2,L1": 112,
      "V2,L2&L3": 56
    },
    8: {
      "V1,L1": 256,
      "V1,L2": 128,
      "V1,L3": 112,
      "V2,L1": 128,
      "V2,L2&L3": 64
    },
    9: {
      "V1,L1": 288,
      "V1,L2": 160,
      "V1,L3": 128,
      "V2,L1": 144,
      "V2,L2&L3": 80
    },
    10: {
      "V1,L1": 320,
      "V1,L2": 192,
      "V1,L3": 160,
      "V2,L1": 160,
      "V2,L2&L3": 96
    },
    11: {
      "V1,L1": 352,
      "V1,L2": 224,
      "V1,L3": 192,
      "V2,L1": 176,
      "V2,L2&L3": 112
    },
    12: {
      "V1,L1": 384,
      "V1,L2": 256,
      "V1,L3": 224,
      "V2,L1": 192,
      "V2,L2&L3": 128
    },
    13: {
      "V1,L1": 416,
      "V1,L2": 320,
      "V1,L3": 256,
      "V2,L1": 224,
      "V2,L2&L3": 144
    },
    14: {
      "V1,L1": 448,
      "V1,L2": 384,
      "V1,L3": 320,
      "V2,L1": 256,
      "V2,L2&L3": 160
    },
    15: {
      "V1,L1": "bad",
      "V1,L2": "bad",
      "V1,L3": "bad",
      "V2,L1": "bad",
      "V2,L2&L3": "bad"
    }
  };
  let key;
  if (mpegVersion === 2 && (level === 2 || level === 3)) {
    key = "V2,L2&L3";
  } else {
    key = `V${mpegVersion},L${level}`;
  }
  return bitrateTable[bits][key];
}
var parseMpegHeader = async ({
  state
}) => {
  const { iterator } = state;
  const initialOffset = iterator.counter.getOffset();
  if (iterator.bytesRemaining() < 32) {
    return;
  }
  iterator.startReadingBits();
  for (let i = 0;i < 11; i++) {
    const expectToBe1 = iterator.getBits(1);
    if (expectToBe1 !== 1) {
      throw new Error("Expected 1");
    }
  }
  const audioVersionId = iterator.getBits(2);
  if (audioVersionId !== 3 && audioVersionId !== 2) {
    throw new Error("Expected MPEG Version 1 or 2");
  }
  const mpegVersion = audioVersionId === 3 ? 1 : 2;
  const layerBits = iterator.getBits(2);
  if (layerBits === 0) {
    throw new Error("Expected Layer I, II or III");
  }
  const layer = layerBits === 3 ? 1 : layerBits === 2 ? 2 : 3;
  const protectionBit = iterator.getBits(1);
  if (protectionBit !== 1) {
    throw new Error("Does not support CRC yet");
  }
  const bitrateIndex = iterator.getBits(4);
  const bitrateKbit = getBitrateKB({
    bits: bitrateIndex,
    mpegVersion,
    level: audioVersionId
  });
  if (bitrateKbit === "bad") {
    throw new Error("Invalid bitrate");
  }
  if (bitrateKbit === "free") {
    throw new Error("Free bitrate not supported");
  }
  const samplingFrequencyIndex = iterator.getBits(2);
  const sampleRate = getSamplingFrequency({
    bits: samplingFrequencyIndex,
    mpegVersion
  });
  const padding = Boolean(iterator.getBits(1));
  iterator.getBits(1);
  const channelMode = iterator.getBits(2);
  iterator.getBits(2);
  iterator.getBits(1);
  iterator.getBits(1);
  iterator.getBits(2);
  const numberOfChannels = channelMode === 3 ? 1 : 2;
  const samplesPerFrame = getSamplesPerMpegFrame({ mpegVersion, layer });
  const frameLength = getMpegFrameLength({
    bitrateKbit,
    padding,
    samplesPerFrame,
    samplingFrequency: sampleRate,
    layer
  });
  iterator.stopReadingBits();
  const offsetNow = iterator.counter.getOffset();
  iterator.counter.decrement(offsetNow - initialOffset);
  const data = iterator.getSlice(frameLength);
  if (state.callbacks.tracks.getTracks().length === 0) {
    state.mp3Info.setMp3Info({
      layer,
      mpegVersion,
      sampleRate,
      bitrateKbit,
      startOfMpegStream: initialOffset
    });
    await registerTrack({
      container: "mp3",
      state,
      track: {
        type: "audio",
        codec: "mp3",
        codecPrivate: null,
        codecWithoutConfig: "mp3",
        description: undefined,
        numberOfChannels,
        sampleRate,
        timescale: 1e6,
        trackId: 0,
        trakBox: null
      }
    });
    state.callbacks.tracks.setIsDone(state.logLevel);
  }
  const mp3Info = state.mp3Info.getMp3Info();
  if (!mp3Info) {
    throw new Error("No MP3 info by now");
  }
  const avgLength = getAverageMpegFrameLength({
    bitrateKbit,
    layer,
    samplesPerFrame,
    samplingFrequency: sampleRate
  });
  const nthFrame = Math.round((initialOffset - mp3Info.startOfMpegStream) / avgLength);
  const durationInSeconds = samplesPerFrame / sampleRate;
  const timeInSeconds = nthFrame * samplesPerFrame / sampleRate;
  const timestamp = Math.round(timeInSeconds * 1e6);
  const duration2 = Math.round(durationInSeconds * 1e6);
  await state.callbacks.onAudioSample(0, {
    data,
    cts: timestamp,
    dts: timestamp,
    duration: duration2,
    offset: initialOffset,
    timescale: 1e6,
    timestamp,
    trackId: 0,
    type: "key"
  });
};

// src/containers/mp3/parse-mp3.ts
var parseMp3 = async (state) => {
  const { iterator } = state;
  if (iterator.bytesRemaining() < 3) {
    return null;
  }
  const { returnToCheckpoint } = iterator.startCheckpoint();
  const bytes = iterator.getSlice(3);
  returnToCheckpoint();
  if (bytes[0] === 84 && bytes[1] === 65 && bytes[2] === 71) {
    parseID3V1(iterator);
    return null;
  }
  if (bytes[0] === 73 && bytes[1] === 68 && bytes[2] === 51) {
    parseId3({ state });
    return null;
  }
  if (bytes[0] === 255) {
    await parseMpegHeader({
      state
    });
    return null;
  }
  throw new Error("Unknown MP3 header " + JSON.stringify(bytes));
};

// src/containers/riff/is-movi.ts
var isMoviAtom = (iterator, ckId) => {
  if (ckId !== "LIST") {
    return false;
  }
  const listType = iterator.getByteString(4, false);
  iterator.counter.decrement(4);
  return listType === "movi";
};

// src/containers/riff/parse-avih.ts
var parseAvih = ({
  iterator,
  size
}) => {
  const { expectNoMoreBytes } = iterator.startBox(size);
  const dwMicroSecPerFrame = iterator.getUint32Le();
  const dwMaxBytesPerSec = iterator.getUint32Le();
  const paddingGranularity = iterator.getUint32Le();
  const flags = iterator.getUint32Le();
  const totalFrames = iterator.getUint32Le();
  const initialFrames = iterator.getUint32Le();
  const streams = iterator.getUint32Le();
  const suggestedBufferSize = iterator.getUint32Le();
  const width = iterator.getUint32Le();
  const height = iterator.getUint32Le();
  iterator.discard(16);
  expectNoMoreBytes();
  return {
    type: "avih-box",
    microSecPerFrame: dwMicroSecPerFrame,
    maxBytesPerSecond: dwMaxBytesPerSec,
    paddingGranularity,
    flags,
    totalFrames,
    initialFrames,
    streams,
    suggestedBufferSize,
    height,
    width
  };
};

// src/containers/riff/parse-isft.ts
var parseIsft = ({
  iterator,
  size
}) => {
  const { expectNoMoreBytes } = iterator.startBox(size);
  const software = iterator.getByteString(size - 1, false);
  const last = iterator.getUint8();
  if (last !== 0) {
    throw new Error(`Expected 0 byte, got ${last}`);
  }
  expectNoMoreBytes();
  return {
    type: "isft-box",
    software
  };
};

// src/containers/riff/parse-list-box.ts
var parseListBox = async ({
  size,
  state
}) => {
  const { iterator } = state;
  const counter = iterator.counter.getOffset();
  const listType = iterator.getByteString(4, false);
  if (listType === "movi") {
    throw new Error("should not be handled here");
  }
  const boxes = [];
  const maxOffset = counter + size;
  while (iterator.counter.getOffset() < maxOffset) {
    const box = await expectRiffBox(state);
    if (box === null) {
      throw new Error("Unexpected result");
    }
    boxes.push(box);
  }
  return {
    type: "list-box",
    listType,
    children: boxes
  };
};

// src/containers/riff/parse-strf.ts
var parseStrfAudio = ({
  iterator,
  size
}) => {
  const box = iterator.startBox(size);
  const formatTag = iterator.getUint16Le();
  const numberOfChannels = iterator.getUint16Le();
  const samplesPerSec = iterator.getUint32Le();
  const avgBytesPerSec = iterator.getUint32Le();
  const blockAlign = iterator.getUint16Le();
  const bitsPerSample = iterator.getUint16Le();
  const cbSize = iterator.getUint16Le();
  box.expectNoMoreBytes();
  return {
    type: "strf-box-audio",
    avgBytesPerSecond: avgBytesPerSec,
    bitsPerSample,
    blockAlign,
    cbSize,
    formatTag,
    numberOfChannels,
    sampleRate: samplesPerSec
  };
};
var parseStrfVideo = ({
  iterator,
  size
}) => {
  const box = iterator.startBox(size);
  const biSize = iterator.getUint32Le();
  const width = iterator.getInt32Le();
  const height = iterator.getInt32Le();
  const planes = iterator.getUint16Le();
  const bitCount = iterator.getUint16Le();
  const compression = iterator.getByteString(4, false);
  const sizeImage = iterator.getUint32Le();
  const xPelsPerMeter = iterator.getInt32Le();
  const yPelsPerMeter = iterator.getInt32Le();
  const clrUsed = iterator.getUint32Le();
  const clrImportant = iterator.getUint32Le();
  box.expectNoMoreBytes();
  return {
    type: "strf-box-video",
    biSize,
    bitCount,
    clrImportant,
    clrUsed,
    compression,
    height,
    planes,
    sizeImage,
    width,
    xPelsPerMeter,
    yPelsPerMeter
  };
};
var parseStrf = ({
  iterator,
  size,
  fccType
}) => {
  if (fccType === "vids") {
    return parseStrfVideo({ iterator, size });
  }
  if (fccType === "auds") {
    return parseStrfAudio({ iterator, size });
  }
  throw new Error(`Unsupported fccType: ${fccType}`);
};

// src/containers/riff/parse-strh.ts
var parseStrh = ({
  iterator,
  size
}) => {
  const box = iterator.startBox(size);
  const fccType = iterator.getByteString(4, false);
  if (fccType !== "vids" && fccType !== "auds") {
    throw new Error("Expected AVI handler to be vids / auds");
  }
  const handler = fccType === "vids" ? iterator.getByteString(4, false) : iterator.getUint32Le();
  if (typeof handler === "string" && handler !== "H264") {
    throw new Error(`Only H264 is supported as a stream type in .avi, got ${handler}`);
  }
  if (fccType === "auds" && handler !== 1) {
    throw new Error(`Only "1" is supported as a stream type in .avi, got ${handler}`);
  }
  const flags = iterator.getUint32Le();
  const priority = iterator.getUint16Le();
  const language2 = iterator.getUint16Le();
  const initialFrames = iterator.getUint32Le();
  const scale = iterator.getUint32Le();
  const rate = iterator.getUint32Le();
  const start = iterator.getUint32Le();
  const length = iterator.getUint32Le();
  const suggestedBufferSize = iterator.getUint32Le();
  const quality = iterator.getUint32Le();
  const sampleSize = iterator.getUint32Le();
  box.discardRest();
  const ckId = iterator.getByteString(4, false);
  const ckSize = iterator.getUint32Le();
  if (ckId !== "strf") {
    throw new Error(`Expected strf, got ${JSON.stringify(ckId)}`);
  }
  if (iterator.bytesRemaining() < ckSize) {
    throw new Error("Expected strf to be complete");
  }
  const strf = parseStrf({ iterator, size: ckSize, fccType });
  return {
    type: "strh-box",
    fccType,
    handler,
    flags,
    priority,
    initialFrames,
    length,
    quality,
    rate,
    sampleSize,
    scale,
    start,
    suggestedBufferSize,
    language: language2,
    strf
  };
};

// src/containers/riff/parse-riff-box.ts
var parseRiffBox = ({
  size,
  id,
  state
}) => {
  const { iterator } = state;
  if (id === "LIST") {
    return parseListBox({ size, state });
  }
  if (id === "ISFT") {
    return Promise.resolve(parseIsft({ iterator, size }));
  }
  if (id === "avih") {
    return Promise.resolve(parseAvih({ iterator, size }));
  }
  if (id === "strh") {
    return Promise.resolve(parseStrh({ iterator, size }));
  }
  iterator.discard(size);
  const box = {
    type: "riff-box",
    size,
    id
  };
  return Promise.resolve(box);
};

// src/containers/riff/expect-riff-box.ts
var expectRiffBox = async (state) => {
  const { iterator } = state;
  if (state.iterator.bytesRemaining() < 16) {
    return null;
  }
  const checkpoint = iterator.startCheckpoint();
  const ckId = iterator.getByteString(4, false);
  const ckSize = iterator.getUint32Le();
  if (isMoviAtom(iterator, ckId)) {
    iterator.discard(4);
    state.videoSection.setVideoSection({
      start: iterator.counter.getOffset(),
      size: ckSize - 4
    });
    return null;
  }
  if (iterator.bytesRemaining() < ckSize) {
    checkpoint.returnToCheckpoint();
    return null;
  }
  const box = await parseRiffBox({
    id: ckId,
    size: ckSize,
    state
  });
  if (box.type === "strh-box") {
    if (box.strf.type === "strf-box-audio" && state.onAudioTrack) {
      const audioTrack = makeAviAudioTrack({
        index: state.riff.getNextTrackIndex(),
        strf: box.strf
      });
      await registerTrack({
        state,
        track: audioTrack,
        container: "avi"
      });
    }
    if (state.onVideoTrack && box.strf.type === "strf-box-video") {
      const videoTrack = makeAviVideoTrack({
        strh: box,
        index: state.riff.getNextTrackIndex(),
        strf: box.strf
      });
      registerVideoTrackWhenProfileIsAvailable({
        state,
        track: videoTrack,
        container: "avi"
      });
    }
    state.riff.incrementNextTrackIndex();
  }
  return box;
};

// src/containers/avc/key.ts
var getKeyFrameOrDeltaFromAvcInfo = (infos) => {
  const keyOrDelta = infos.find((i) => i.type === "keyframe" || i.type === "delta-frame");
  if (!keyOrDelta) {
    throw new Error("expected avc to contain info about key or delta");
  }
  return keyOrDelta.type === "keyframe" ? "key" : "delta";
};

// src/containers/avc/parse-avc.ts
var Extended_SAR = 255;
var readVuiParameters = (iterator) => {
  let sar_width = null;
  let sar_height = null;
  let overscan_appropriate_flag = null;
  let video_format = null;
  let video_full_range_flag = null;
  let colour_primaries = null;
  let transfer_characteristics = null;
  let matrix_coefficients = null;
  let chroma_sample_loc_type_top_field = null;
  let chroma_sample_loc_type_bottom_field = null;
  const aspect_ratio_info_present_flag = iterator.getBits(1);
  if (aspect_ratio_info_present_flag) {
    const aspect_ratio_idc = iterator.getBits(8);
    if (aspect_ratio_idc === Extended_SAR) {
      sar_width = iterator.getBits(16);
      sar_height = iterator.getBits(16);
    }
  }
  const overscan_info_present_flag = iterator.getBits(1);
  if (overscan_info_present_flag) {
    overscan_appropriate_flag = iterator.getBits(1);
  }
  const video_signal_type_present_flag = iterator.getBits(1);
  if (video_signal_type_present_flag) {
    video_format = iterator.getBits(3);
    video_full_range_flag = Boolean(iterator.getBits(1));
    const colour_description_present_flag = iterator.getBits(1);
    if (colour_description_present_flag) {
      colour_primaries = iterator.getBits(8);
      transfer_characteristics = iterator.getBits(8);
      matrix_coefficients = iterator.getBits(8);
    }
  }
  const chroma_loc_info_present_flag = iterator.getBits(1);
  if (chroma_loc_info_present_flag) {
    chroma_sample_loc_type_top_field = iterator.readExpGolomb();
    chroma_sample_loc_type_bottom_field = iterator.readExpGolomb();
  }
  return {
    sar_width,
    sar_height,
    overscan_appropriate_flag,
    chroma_sample_loc_type_bottom_field,
    chroma_sample_loc_type_top_field,
    colour_primaries,
    matrix_coefficients,
    transfer_characteristics,
    video_format,
    video_full_range_flag
  };
};
var readSps = (iterator) => {
  const profile = iterator.getUint8();
  const compatibility = iterator.getUint8();
  const level = iterator.getUint8();
  iterator.startReadingBits();
  const seq_parameter_set_id = iterator.readExpGolomb();
  let separate_colour_plane_flag = null;
  let bit_depth_luma_minus8 = null;
  let bit_depth_chroma_minus8 = null;
  let qpprime_y_zero_transform_bypass_flag = null;
  let log2_max_frame_num_minus4 = null;
  let log2_max_pic_order_cnt_lsb_minus4 = null;
  let max_num_ref_frames = null;
  let gaps_in_frame_num_value_allowed_flag = null;
  let mb_adaptive_frame_field_flag = null;
  let direct_8x8_inference_flag = null;
  let frame_crop_left_offset = null;
  let frame_crop_right_offset = null;
  let frame_crop_top_offset = null;
  let frame_crop_bottom_offset = null;
  let vui_parameters = null;
  if (!(profile === 100 || profile === 110 || profile === 122 || profile === 244 || profile === 44 || profile === 83 || profile === 86 || profile === 118 || profile === 128 || profile === 138 || profile === 139 || profile === 134 || profile === 135)) {
    throw new Error("Invalid profile");
  }
  const chromaFormat = iterator.readExpGolomb();
  if (chromaFormat === 3) {
    separate_colour_plane_flag = iterator.getBits(1);
  }
  bit_depth_luma_minus8 = iterator.readExpGolomb();
  bit_depth_chroma_minus8 = iterator.readExpGolomb();
  qpprime_y_zero_transform_bypass_flag = iterator.getBits(1);
  const seq_scaling_matrix_present_flag = iterator.getBits(1);
  const seq_scaling_list_present_flag = [];
  if (seq_scaling_matrix_present_flag) {
    for (let i = 0;i < (chromaFormat !== 3 ? 8 : 12); i++) {
      seq_scaling_list_present_flag[i] = iterator.getBits(1);
      if (seq_scaling_list_present_flag[i]) {
        if (i < 6) {
          throw new Error("Not implemented");
        } else {
          throw new Error("Not implemented");
        }
      }
    }
  }
  log2_max_frame_num_minus4 = iterator.readExpGolomb();
  const pic_order_cnt_type = iterator.readExpGolomb();
  if (pic_order_cnt_type === 0) {
    log2_max_pic_order_cnt_lsb_minus4 = iterator.readExpGolomb();
  } else if (pic_order_cnt_type === 1) {
    throw new Error("pic_order_cnt_type = 1 not implemented");
  }
  max_num_ref_frames = iterator.readExpGolomb();
  gaps_in_frame_num_value_allowed_flag = iterator.getBits(1);
  const pic_width_in_mbs_minus1 = iterator.readExpGolomb();
  const pic_height_in_map_units_minus1 = iterator.readExpGolomb();
  const frame_mbs_only_flag = iterator.getBits(1);
  if (!frame_mbs_only_flag) {
    mb_adaptive_frame_field_flag = iterator.getBits(1);
  }
  direct_8x8_inference_flag = iterator.getBits(1);
  const frame_cropping_flag = iterator.getBits(1);
  if (frame_cropping_flag) {
    frame_crop_left_offset = iterator.readExpGolomb();
    frame_crop_right_offset = iterator.readExpGolomb();
    frame_crop_top_offset = iterator.readExpGolomb();
    frame_crop_bottom_offset = iterator.readExpGolomb();
  }
  const vui_parameters_present_flag = iterator.getBits(1);
  if (vui_parameters_present_flag) {
    vui_parameters = readVuiParameters(iterator);
  }
  iterator.stopReadingBits();
  return {
    profile,
    compatibility,
    level,
    bit_depth_chroma_minus8,
    bit_depth_luma_minus8,
    gaps_in_frame_num_value_allowed_flag,
    log2_max_frame_num_minus4,
    log2_max_pic_order_cnt_lsb_minus4,
    max_num_ref_frames,
    pic_height_in_map_units_minus1,
    pic_width_in_mbs_minus1,
    qpprime_y_zero_transform_bypass_flag,
    separate_colour_plane_flag,
    seq_parameter_set_id,
    direct_8x8_inference_flag,
    frame_crop_bottom_offset,
    frame_crop_left_offset,
    frame_crop_right_offset,
    frame_crop_top_offset,
    mb_adaptive_frame_field_flag,
    vui_parameters
  };
};
var findEnd = (buffer) => {
  let zeroesInARow = 0;
  for (let i = 0;i < buffer.length; i++) {
    const val = buffer[i];
    if (val === 0) {
      zeroesInARow++;
      continue;
    }
    if (zeroesInARow >= 2 && val === 1) {
      return i - zeroesInARow;
    }
    zeroesInARow = 0;
  }
  return null;
};
var inspect = (buffer) => {
  const iterator = getArrayBufferIterator(buffer, buffer.byteLength);
  iterator.startReadingBits();
  iterator.getBits(1);
  iterator.getBits(2);
  const type = iterator.getBits(5);
  iterator.stopReadingBits();
  if (type === 7) {
    const end = findEnd(buffer);
    const data = readSps(iterator);
    const sps = buffer.slice(0, end === null ? Infinity : end);
    return {
      spsData: data,
      sps,
      type: "avc-profile"
    };
  }
  if (type === 5) {
    return {
      type: "keyframe"
    };
  }
  if (type === 8) {
    const end = findEnd(buffer);
    const pps = buffer.slice(0, end === null ? Infinity : end);
    return {
      type: "avc-pps",
      pps
    };
  }
  if (type === 1) {
    return {
      type: "delta-frame"
    };
  }
  iterator.destroy();
  return null;
};
var parseAvc = (buffer) => {
  let zeroesInARow = 0;
  const infos = [];
  for (let i = 0;i < buffer.length; i++) {
    const val = buffer[i];
    if (val === 0) {
      zeroesInARow++;
      continue;
    }
    if (zeroesInARow >= 2 && val === 1) {
      zeroesInARow = 0;
      const info = inspect(buffer.slice(i + 1, i + 100));
      if (info) {
        infos.push(info);
        if (info.type === "keyframe" || info.type === "delta-frame") {
          break;
        }
      }
    }
    if (val !== 1) {
      zeroesInARow = 0;
    }
  }
  return infos;
};

// src/containers/riff/parse-movi.ts
var getStrhForIndex = (structure, trackId) => {
  const boxes = getStrlBoxes(structure);
  const box = boxes[trackId];
  if (!box) {
    throw new Error("Expected box");
  }
  const strh = getStrhBox(box.children);
  if (!strh) {
    throw new Error("strh");
  }
  return strh;
};
var handleChunk = async ({
  state,
  ckId,
  ckSize
}) => {
  const { iterator } = state;
  const offset = iterator.counter.getOffset();
  const videoChunk = ckId.match(/^([0-9]{2})dc$/);
  if (videoChunk) {
    const trackId = parseInt(videoChunk[1], 10);
    const strh = getStrhForIndex(state.getRiffStructure(), trackId);
    const samplesPerSecond = strh.rate / strh.scale;
    const nthSample = state.callbacks.getSamplesForTrack(trackId);
    const timeInSec = nthSample / samplesPerSecond;
    const timestamp = timeInSec;
    const data = iterator.getSlice(ckSize);
    const infos = parseAvc(data);
    const keyOrDelta = getKeyFrameOrDeltaFromAvcInfo(infos);
    const avcProfile = infos.find((i) => i.type === "avc-profile");
    const ppsProfile = infos.find((i) => i.type === "avc-pps");
    if (avcProfile && ppsProfile && !state.riff.getAvcProfile()) {
      await state.riff.onProfile({ pps: ppsProfile, sps: avcProfile });
      state.callbacks.tracks.setIsDone(state.logLevel);
    }
    await state.callbacks.onVideoSample(trackId, convertAudioOrVideoSampleToWebCodecsTimestamps({
      cts: timestamp,
      dts: timestamp,
      data,
      duration: undefined,
      timestamp,
      trackId,
      type: keyOrDelta,
      offset,
      timescale: samplesPerSecond
    }, 1));
    return;
  }
  const audioChunk = ckId.match(/^([0-9]{2})wb$/);
  if (audioChunk) {
    const trackId = parseInt(audioChunk[1], 10);
    const strh = getStrhForIndex(state.getRiffStructure(), trackId);
    const samplesPerSecond = strh.rate / strh.scale;
    const nthSample = state.callbacks.getSamplesForTrack(trackId);
    const timeInSec = nthSample / samplesPerSecond;
    const timestamp = timeInSec;
    const data = iterator.getSlice(ckSize);
    await state.callbacks.onAudioSample(trackId, convertAudioOrVideoSampleToWebCodecsTimestamps({
      cts: timestamp,
      dts: timestamp,
      data,
      duration: undefined,
      timestamp,
      trackId,
      type: "key",
      offset,
      timescale: samplesPerSecond
    }, 1));
  }
};
var parseMovi = async ({
  state
}) => {
  const { iterator } = state;
  if (iterator.bytesRemaining() < 8) {
    return Promise.resolve();
  }
  const checkpoint = iterator.startCheckpoint();
  const ckId = iterator.getByteString(4, false);
  const ckSize = iterator.getUint32Le();
  if (iterator.bytesRemaining() < ckSize) {
    checkpoint.returnToCheckpoint();
    return Promise.resolve();
  }
  await handleChunk({ state, ckId, ckSize });
  const videoSection = state.videoSection.getVideoSection();
  const maxOffset = videoSection.start + videoSection.size;
  while (iterator.counter.getOffset() < maxOffset && iterator.bytesRemaining() > 0) {
    if (iterator.getUint8() !== 0) {
      iterator.counter.decrement(1);
      break;
    }
  }
};

// src/containers/riff/parse-video-section.ts
var parseVideoSection = async (state) => {
  await parseMovi({
    state
  });
  const tracks2 = getTracks(state);
  if (!tracks2.videoTracks.some((t) => t.codec === TO_BE_OVERRIDDEN_LATER) && !state.callbacks.tracks.getIsDone()) {
    state.callbacks.tracks.setIsDone(state.logLevel);
  }
};

// src/containers/riff/parse-riff-body.ts
var parseRiffBody = async (state) => {
  if (state.videoSection.isInVideoSectionState(state.iterator) === "in-section") {
    if (maySkipVideoData({
      state
    }) && state.riff.getAvcProfile()) {
      const videoSection = state.videoSection.getVideoSection();
      return Promise.resolve(makeSkip(videoSection.start + videoSection.size));
    }
    await parseVideoSection(state);
    return null;
  }
  const box = await expectRiffBox(state);
  if (box !== null) {
    const structure = state.getRiffStructure();
    structure.boxes.push(box);
  }
  return null;
};

// src/containers/riff/parse-riff-header.ts
var parseRiffHeader = (state) => {
  const riff = state.iterator.getByteString(4, false);
  if (riff !== "RIFF") {
    throw new Error("Not a RIFF file");
  }
  const structure = state.getRiffStructure();
  const size = state.iterator.getUint32Le();
  const fileType = state.iterator.getByteString(4, false);
  if (fileType !== "WAVE" && fileType !== "AVI") {
    throw new Error(`File type ${fileType} not supported`);
  }
  structure.boxes.push({ type: "riff-header", fileSize: size, fileType });
  return null;
};

// src/containers/riff/parse-riff.ts
var parseRiff = (state) => {
  if (state.iterator.counter.getOffset() === 0) {
    return Promise.resolve(parseRiffHeader(state));
  }
  return parseRiffBody(state);
};

// src/containers/transport-stream/discard-rest-of-packet.ts
var discardRestOfPacket = (iterator) => {
  const next188 = 188 - iterator.counter.getOffset() % 188;
  iterator.discard(next188);
};
var getRestOfPacket = (iterator) => {
  const next188 = 188 - iterator.counter.getOffset() % 188;
  return iterator.getSlice(next188);
};

// src/containers/transport-stream/parse-pat.ts
var parsePatTable = (iterator, tableId) => {
  iterator.getUint16();
  iterator.startReadingBits();
  iterator.getBits(7);
  iterator.getBits(1);
  const sectionNumber = iterator.getBits(8);
  const lastSectionNumber = iterator.getBits(8);
  if (tableId !== 0) {
    throw new Error("Invalid table ID: " + tableId);
  }
  const tables = [];
  for (let i = sectionNumber;i <= lastSectionNumber; i++) {
    const programNumber = iterator.getBits(16);
    iterator.getBits(3);
    const programMapIdentifier = iterator.getBits(13);
    tables.push({
      type: "transport-stream-program-association-table",
      programNumber,
      programMapIdentifier
    });
  }
  iterator.stopReadingBits();
  return {
    type: "transport-stream-pat-box",
    tableId: tableId.toString(16),
    pat: tables
  };
};
var parsePat = (iterator) => {
  iterator.startReadingBits();
  const tableId = iterator.getBits(8);
  iterator.getBits(1);
  iterator.getBits(1);
  iterator.getBits(4);
  const sectionLength = iterator.getBits(10);
  if (sectionLength > 1021) {
    throw new Error("Invalid section length");
  }
  iterator.stopReadingBits();
  const tables = parsePatTable(iterator, tableId);
  discardRestOfPacket(iterator);
  return tables;
};

// src/containers/transport-stream/parse-pes.ts
var parsePes = (iterator) => {
  const ident = iterator.getUint24();
  if (ident !== 1) {
    throw new Error(`Unexpected PES packet start code: ${ident.toString(16)}`);
  }
  const streamId = iterator.getUint8();
  iterator.getUint16();
  iterator.startReadingBits();
  const markerBits = iterator.getBits(2);
  if (markerBits !== 2) {
    throw new Error(`Invalid marker bits: ${markerBits}`);
  }
  const scrambled = iterator.getBits(2);
  if (scrambled !== 0) {
    throw new Error(`Only supporting non-scrambled streams`);
  }
  const priority = iterator.getBits(1);
  iterator.getBits(1);
  iterator.getBits(1);
  iterator.getBits(1);
  const ptsPresent = iterator.getBits(1);
  const dtsPresent = iterator.getBits(1);
  if (!ptsPresent && dtsPresent) {
    throw new Error(`DTS is present but not PTS, this is not allowed in the spec`);
  }
  iterator.getBits(1);
  iterator.getBits(1);
  iterator.getBits(1);
  iterator.getBits(1);
  iterator.getBits(1);
  iterator.getBits(1);
  const pesHeaderLength = iterator.getBits(8);
  const offset = iterator.counter.getOffset();
  let pts = null;
  if (!ptsPresent) {
    throw new Error(`PTS is required`);
  }
  const fourBits = iterator.getBits(4);
  if (fourBits !== 3 && fourBits !== 2) {
    throw new Error(`Invalid PTS marker bits: ${fourBits}`);
  }
  const pts1 = iterator.getBits(3);
  iterator.getBits(1);
  const pts2 = iterator.getBits(15);
  iterator.getBits(1);
  const pts3 = iterator.getBits(15);
  iterator.getBits(1);
  pts = pts1 << 30 | pts2 << 15 | pts3;
  let dts = null;
  if (dtsPresent) {
    const _fourBits = iterator.getBits(4);
    if (_fourBits !== 1) {
      throw new Error(`Invalid DTS marker bits: ${_fourBits}`);
    }
    const dts1 = iterator.getBits(3);
    iterator.getBits(1);
    const dts2 = iterator.getBits(15);
    iterator.getBits(1);
    const dts3 = iterator.getBits(15);
    iterator.getBits(1);
    dts = dts1 << 30 | dts2 << 15 | dts3;
  }
  iterator.stopReadingBits();
  iterator.discard(pesHeaderLength - (iterator.counter.getOffset() - offset));
  const packet = {
    dts,
    pts,
    streamId,
    priority
  };
  return packet;
};

// src/containers/transport-stream/parse-pmt.ts
var parsePmtTable = ({
  iterator,
  tableId,
  sectionLength
}) => {
  const start = iterator.counter.getOffset();
  iterator.getUint16();
  iterator.startReadingBits();
  iterator.getBits(7);
  iterator.getBits(1);
  const sectionNumber = iterator.getBits(8);
  const lastSectionNumber = iterator.getBits(8);
  const tables = [];
  for (let i = sectionNumber;i <= lastSectionNumber; i++) {
    iterator.getBits(3);
    iterator.getBits(13);
    iterator.getBits(4);
    const programInfoLength = iterator.getBits(12);
    const streams = [];
    while (true) {
      const streamType = iterator.getBits(8);
      iterator.getBits(3);
      const elementaryPid = iterator.getBits(13);
      iterator.getBits(4);
      const esInfoLength = iterator.getBits(12);
      iterator.getBits(esInfoLength * 8);
      streams.push({ streamType, pid: elementaryPid });
      iterator.getBits(programInfoLength * 8);
      const remaining = sectionLength - (iterator.counter.getOffset() - start);
      if (remaining <= 4) {
        break;
      }
    }
    tables.push({
      type: "transport-stream-program-map-table",
      streams
    });
  }
  if (tables.length !== 1) {
    throw new Error("Does not PMT table with more than 1 entry, uncommon");
  }
  iterator.stopReadingBits();
  return {
    type: "transport-stream-pmt-box",
    tableId,
    streams: tables[0].streams
  };
};
var parsePmt = (iterator) => {
  iterator.startReadingBits();
  const tableId = iterator.getBits(8);
  iterator.getBits(1);
  iterator.getBits(1);
  iterator.getBits(4);
  const sectionLength = iterator.getBits(10);
  if (sectionLength > 1021) {
    throw new Error("Invalid section length");
  }
  iterator.stopReadingBits();
  const tables = parsePmtTable({ iterator, tableId, sectionLength });
  discardRestOfPacket(iterator);
  return tables;
};

// src/containers/transport-stream/adts-header.ts
var readAdtsHeader = (buffer) => {
  if (buffer.byteLength < 9) {
    return null;
  }
  const iterator = getArrayBufferIterator(buffer, buffer.byteLength);
  iterator.startReadingBits();
  const bits = iterator.getBits(12);
  if (bits !== 4095) {
    throw new Error("Invalid ADTS header ");
  }
  const id = iterator.getBits(1);
  if (id !== 0) {
    throw new Error("Only supporting MPEG-4 for .ts");
  }
  const layer = iterator.getBits(2);
  if (layer !== 0) {
    throw new Error("Only supporting layer 0 for .ts");
  }
  const protectionAbsent = iterator.getBits(1);
  const audioObjectType = iterator.getBits(2);
  const samplingFrequencyIndex = iterator.getBits(4);
  const sampleRate = getSampleRateFromSampleFrequencyIndex(samplingFrequencyIndex);
  iterator.getBits(1);
  const channelConfiguration = iterator.getBits(3);
  const codecPrivate2 = createAacCodecPrivate({
    audioObjectType,
    sampleRate,
    channelConfiguration,
    codecPrivate: null
  });
  iterator.getBits(1);
  iterator.getBits(1);
  iterator.getBits(1);
  iterator.getBits(1);
  const frameLength = iterator.getBits(13);
  iterator.getBits(11);
  iterator.getBits(2);
  if (!protectionAbsent) {
    iterator.getBits(16);
  }
  iterator.stopReadingBits();
  iterator.destroy();
  return {
    frameLength,
    codecPrivate: codecPrivate2,
    channelConfiguration,
    sampleRate,
    audioObjectType
  };
};

// src/containers/transport-stream/find-separator.ts
function findSubarrayIndex(array, subarray) {
  const subarrayLength = subarray.length;
  const arrayLength = array.length;
  for (let i = 0;i <= arrayLength - subarrayLength; i++) {
    let match = true;
    for (let j = 0;j < subarrayLength; j++) {
      if (array[i + j] !== subarray[j]) {
        match = false;
        break;
      }
    }
    if (match) {
      if (subarray[i - 1] === 0) {
        i--;
      }
      return i;
    }
  }
  return -1;
}
var findNextSeparator = (restOfPacket, transportStreamEntry) => {
  if (transportStreamEntry.streamType === 27) {
    return findSubarrayIndex(restOfPacket, new Uint8Array([0, 0, 1, 9]));
  }
  throw new Error(`Unsupported stream ID ${transportStreamEntry.streamType}`);
};

// src/containers/avc/interpret-sps.ts
var getDimensionsFromSps = (sps) => {
  const height = sps.pic_height_in_map_units_minus1;
  const width = sps.pic_width_in_mbs_minus1;
  return {
    height: (height + 1) * 16,
    width: (width + 1) * 16
  };
};
var getSampleAspectRatioFromSps = (sps) => {
  if (sps.vui_parameters?.sar_height && sps.vui_parameters.sar_width) {
    return {
      width: sps.vui_parameters.sar_width,
      height: sps.vui_parameters.sar_height
    };
  }
  return {
    width: 1,
    height: 1
  };
};
var getVideoColorFromSps = (sps) => {
  const matrixCoefficients2 = sps.vui_parameters?.matrix_coefficients;
  const transferCharacteristics2 = sps.vui_parameters?.transfer_characteristics;
  const colorPrimaries = sps.vui_parameters?.colour_primaries;
  return {
    matrixCoefficients: matrixCoefficients2 ? getMatrixCoefficientsFromIndex(matrixCoefficients2) : null,
    transferCharacteristics: transferCharacteristics2 ? getTransferCharacteristicsFromIndex(transferCharacteristics2) : null,
    primaries: colorPrimaries ? getPrimariesFromIndex(colorPrimaries) : null,
    fullRange: sps.vui_parameters?.video_full_range_flag ?? null
  };
};

// src/containers/avc/sps-and-pps.ts
var getSpsAndPps = (infos) => {
  const avcProfile = infos.find((i) => i.type === "avc-profile");
  const ppsProfile = infos.find((i) => i.type === "avc-pps");
  if (!avcProfile || !ppsProfile) {
    throw new Error("Expected avcProfile and ppsProfile");
  }
  return { pps: ppsProfile, sps: avcProfile };
};

// src/containers/transport-stream/handle-avc-packet.ts
var MPEG_TIMESCALE = 90000;
var handleAvcPacket = async ({
  streamBuffer,
  programId,
  state,
  offset
}) => {
  const avc = parseAvc(streamBuffer.buffer);
  const isTrackRegistered = state.callbacks.tracks.getTracks().find((t) => {
    return t.trackId === programId;
  });
  if (!isTrackRegistered) {
    const spsAndPps = getSpsAndPps(avc);
    const dimensions = getDimensionsFromSps(spsAndPps.sps.spsData);
    const sampleAspectRatio = getSampleAspectRatioFromSps(spsAndPps.sps.spsData);
    const track = {
      rotation: 0,
      trackId: programId,
      type: "video",
      timescale: MPEG_TIMESCALE,
      codec: getCodecStringFromSpsAndPps(spsAndPps.sps),
      codecPrivate: createSpsPpsData(spsAndPps),
      fps: null,
      codedWidth: dimensions.width,
      codedHeight: dimensions.height,
      height: dimensions.height,
      width: dimensions.width,
      displayAspectWidth: dimensions.width,
      displayAspectHeight: dimensions.height,
      trakBox: null,
      codecWithoutConfig: "h264",
      description: undefined,
      sampleAspectRatio: {
        denominator: sampleAspectRatio.height,
        numerator: sampleAspectRatio.width
      },
      color: getVideoColorFromSps(spsAndPps.sps.spsData)
    };
    await registerTrack({ track, state, container: "transport-stream" });
  }
  const sample = {
    cts: streamBuffer.pesHeader.pts,
    dts: streamBuffer.pesHeader.dts ?? streamBuffer.pesHeader.pts,
    timestamp: streamBuffer.pesHeader.pts,
    duration: undefined,
    data: new Uint8Array(streamBuffer.buffer),
    trackId: programId,
    type: getKeyFrameOrDeltaFromAvcInfo(avc),
    offset,
    timescale: MPEG_TIMESCALE
  };
  await state.callbacks.onVideoSample(programId, convertAudioOrVideoSampleToWebCodecsTimestamps(sample, MPEG_TIMESCALE));
};

// src/containers/transport-stream/handle-aac-packet.ts
var handleAacPacket = async ({
  streamBuffer,
  state,
  programId,
  offset
}) => {
  const adtsHeader = readAdtsHeader(streamBuffer.buffer);
  if (!adtsHeader) {
    throw new Error("Invalid ADTS header - too short");
  }
  const { channelConfiguration, codecPrivate: codecPrivate2, sampleRate, audioObjectType } = adtsHeader;
  const isTrackRegistered = state.callbacks.tracks.getTracks().find((t) => {
    return t.trackId === programId;
  });
  if (!isTrackRegistered) {
    const track = {
      type: "audio",
      codecPrivate: codecPrivate2,
      trackId: programId,
      trakBox: null,
      timescale: MPEG_TIMESCALE,
      codecWithoutConfig: "aac",
      codec: mapAudioObjectTypeToCodecString(audioObjectType),
      description: undefined,
      numberOfChannels: channelConfiguration,
      sampleRate
    };
    await registerTrack({
      track,
      state,
      container: "transport-stream"
    });
  }
  const sample = {
    cts: streamBuffer.pesHeader.pts,
    dts: streamBuffer.pesHeader.dts ?? streamBuffer.pesHeader.pts,
    timestamp: streamBuffer.pesHeader.pts,
    duration: undefined,
    data: new Uint8Array(streamBuffer.buffer),
    trackId: programId,
    type: "key",
    offset,
    timescale: MPEG_TIMESCALE
  };
  await state.callbacks.onAudioSample(programId, convertAudioOrVideoSampleToWebCodecsTimestamps(sample, MPEG_TIMESCALE));
};

// src/containers/transport-stream/process-stream-buffers.ts
var processStreamBuffer = async ({
  streamBuffer,
  state,
  programId,
  structure
}) => {
  const stream = getStreamForId(structure, programId);
  if (!stream) {
    throw new Error("No stream found");
  }
  if (stream.streamType === 27) {
    await handleAvcPacket({
      programId,
      streamBuffer,
      state,
      offset: streamBuffer.offset
    });
  } else if (stream.streamType === 15) {
    await handleAacPacket({
      streamBuffer,
      state,
      programId,
      offset: streamBuffer.offset
    });
  }
  if (!state.callbacks.tracks.hasAllTracks()) {
    const tracksRegistered = state.callbacks.tracks.getTracks().length;
    const { streams } = findProgramMapTableOrThrow(structure);
    if (streams.length === tracksRegistered) {
      state.callbacks.tracks.setIsDone(state.logLevel);
    }
  }
};
var processFinalStreamBuffers = async ({
  state,
  structure
}) => {
  for (const [programId, buffer] of state.transportStream.streamBuffers) {
    if (buffer.buffer.byteLength > 0) {
      await processStreamBuffer({
        streamBuffer: buffer,
        state,
        programId,
        structure
      });
      state.transportStream.streamBuffers.delete(programId);
    }
  }
};

// src/containers/transport-stream/parse-stream-packet.ts
var parseAdtsStream = async ({
  restOfPacket,
  transportStreamEntry,
  state,
  structure,
  offset
}) => {
  const { streamBuffers, nextPesHeaderStore: nextPesHeader } = state.transportStream;
  const streamBuffer = streamBuffers.get(transportStreamEntry.pid);
  if (!streamBuffer) {
    streamBuffers.set(transportStreamEntry.pid, {
      buffer: restOfPacket,
      pesHeader: nextPesHeader.getNextPesHeader(),
      offset
    });
    return;
  }
  const expectedLength = readAdtsHeader(streamBuffer.buffer)?.frameLength ?? null;
  const bytesToTake = expectedLength ? Math.min(restOfPacket.length, expectedLength - streamBuffer.buffer.byteLength) : restOfPacket.length;
  streamBuffer.buffer = combineUint8Arrays([
    streamBuffer.buffer,
    restOfPacket.slice(0, bytesToTake)
  ]);
  if (expectedLength === streamBuffer.buffer.byteLength) {
    await processStreamBuffer({
      streamBuffer,
      programId: transportStreamEntry.pid,
      state,
      structure
    });
    const rest = restOfPacket.slice(bytesToTake);
    streamBuffers.set(transportStreamEntry.pid, {
      buffer: rest,
      pesHeader: nextPesHeader.getNextPesHeader(),
      offset
    });
  }
};
var parseAvcStream = async ({
  restOfPacket,
  transportStreamEntry,
  programId,
  state,
  structure,
  offset
}) => {
  const indexOfSeparator = findNextSeparator(restOfPacket, transportStreamEntry);
  const { streamBuffers, nextPesHeaderStore: nextPesHeader } = state.transportStream;
  const streamBuffer = streamBuffers.get(transportStreamEntry.pid);
  if (indexOfSeparator === -1) {
    if (streamBuffer) {
      streamBuffer.buffer = combineUint8Arrays([
        streamBuffer.buffer,
        restOfPacket
      ]);
      return;
    }
    streamBuffers.set(programId, {
      pesHeader: nextPesHeader.getNextPesHeader(),
      buffer: restOfPacket,
      offset
    });
    return;
  }
  if (streamBuffer) {
    const packet = restOfPacket.slice(0, indexOfSeparator);
    streamBuffer.buffer = combineUint8Arrays([streamBuffer.buffer, packet]);
    await processStreamBuffer({
      state,
      streamBuffer,
      programId,
      structure
    });
    const rest = restOfPacket.slice(indexOfSeparator);
    streamBuffers.set(programId, {
      pesHeader: nextPesHeader.getNextPesHeader(),
      buffer: rest,
      offset
    });
    return;
  }
  if (indexOfSeparator !== 0) {
    throw new Error("No stream buffer found but new separator is not at the beginning");
  }
  streamBuffers.set(programId, {
    pesHeader: nextPesHeader.getNextPesHeader(),
    buffer: restOfPacket.slice(indexOfSeparator),
    offset
  });
};
var parseStream = ({
  transportStreamEntry,
  state,
  programId,
  structure
}) => {
  const { iterator } = state;
  const restOfPacket = getRestOfPacket(iterator);
  if (transportStreamEntry.streamType === 27) {
    return parseAvcStream({
      restOfPacket,
      transportStreamEntry,
      state,
      programId,
      structure,
      offset: iterator.counter.getOffset()
    });
  }
  if (transportStreamEntry.streamType === 15) {
    return parseAdtsStream({
      restOfPacket,
      transportStreamEntry,
      state,
      structure,
      offset: iterator.counter.getOffset()
    });
  }
  throw new Error(`Unsupported stream type ${transportStreamEntry.streamType}`);
};

// src/containers/transport-stream/parse-packet.ts
var parsePacket = async ({
  parserState
}) => {
  const { iterator } = parserState;
  const offset = iterator.counter.getOffset();
  const syncByte = iterator.getUint8();
  if (syncByte !== 71) {
    throw new Error("Invalid sync byte");
  }
  iterator.startReadingBits();
  iterator.getBits(1);
  const payloadUnitStartIndicator = iterator.getBits(1);
  iterator.getBits(1);
  const programId = iterator.getBits(13);
  iterator.getBits(2);
  const adaptationFieldControl1 = iterator.getBits(1);
  iterator.getBits(1);
  iterator.getBits(4);
  iterator.stopReadingBits();
  if (adaptationFieldControl1 === 1) {
    iterator.startReadingBits();
    const adaptationFieldLength = iterator.getBits(8);
    const headerOffset = iterator.counter.getOffset();
    if (adaptationFieldLength > 0) {
      iterator.getBits(1);
      iterator.getBits(1);
      iterator.getBits(1);
      iterator.getBits(1);
      iterator.getBits(1);
      iterator.getBits(1);
      iterator.getBits(1);
      iterator.getBits(1);
    }
    const remaining = adaptationFieldLength - (iterator.counter.getOffset() - headerOffset);
    iterator.stopReadingBits();
    const toDiscard = Math.max(0, remaining);
    iterator.discard(toDiscard);
  }
  const read = iterator.counter.getOffset() - offset;
  if (read === 188) {
    return Promise.resolve(null);
  }
  const structure = parserState.getTsStructure();
  const pat = structure.boxes.find((b) => b.type === "transport-stream-pmt-box");
  const isPes = payloadUnitStartIndicator && pat?.streams.find((e) => e.pid === programId);
  if (isPes) {
    const packetPes = parsePes(iterator);
    parserState.transportStream.nextPesHeaderStore.setNextPesHeader(packetPes);
  } else if (payloadUnitStartIndicator === 1) {
    iterator.getUint8();
  }
  if (programId === 0) {
    return Promise.resolve(parsePat(iterator));
  }
  const program = getProgramForId(structure, programId);
  if (program) {
    const pmt = parsePmt(iterator);
    return Promise.resolve(pmt);
  }
  const stream = getStreamForId(structure, programId);
  if (stream) {
    await parseStream({
      transportStreamEntry: stream,
      state: parserState,
      programId,
      structure
    });
    return Promise.resolve(null);
  }
  throw new Error("Unknown packet identifier");
};

// src/containers/transport-stream/parse-transport-stream.ts
var parseTransportStream = async (state) => {
  const structure = state.getTsStructure();
  const { iterator } = state;
  if (iterator.bytesRemaining() < 188) {
    return Promise.resolve(null);
  }
  const packet = await parsePacket({
    parserState: state
  });
  if (packet) {
    structure.boxes.push(packet);
  }
  if (iterator.bytesRemaining() === 0) {
    await processFinalStreamBuffers({
      state,
      structure
    });
  }
  return Promise.resolve(null);
};

// src/containers/wav/parse-data.ts
var parseData = ({
  state
}) => {
  const { iterator } = state;
  const ckSize = iterator.getUint32Le();
  const box = {
    type: "wav-data",
    dataSize: ckSize
  };
  state.getWavStructure().boxes.push(box);
  state.callbacks.tracks.setIsDone(state.logLevel);
  state.videoSection.setVideoSection({
    size: ckSize,
    start: iterator.counter.getOffset()
  });
  if (maySkipVideoData({ state })) {
    return Promise.resolve(makeSkip(iterator.counter.getOffset() + ckSize));
  }
  return Promise.resolve(null);
};

// src/containers/wav/parse-fmt.ts
var parseFmt = async ({
  state
}) => {
  const { iterator } = state;
  const ckSize = iterator.getUint32Le();
  const box = iterator.startBox(ckSize);
  const audioFormat = iterator.getUint16Le();
  if (audioFormat !== 1) {
    throw new Error(`Only supporting WAVE with PCM audio format, but got ${audioFormat}`);
  }
  const numberOfChannels = iterator.getUint16Le();
  const sampleRate = iterator.getUint32Le();
  const byteRate = iterator.getUint32Le();
  const blockAlign = iterator.getUint16Le();
  const bitsPerSample = iterator.getUint16Le();
  const format = bitsPerSample === 16 ? "pcm-s16" : bitsPerSample === 32 ? "pcm-s32" : bitsPerSample === 24 ? "pcm-s24" : null;
  if (format === null) {
    throw new Error(`Unsupported bits per sample: ${bitsPerSample}`);
  }
  const wavHeader = {
    bitsPerSample,
    blockAlign,
    byteRate,
    numberOfChannels,
    sampleRate,
    type: "wav-fmt"
  };
  state.getWavStructure().boxes.push(wavHeader);
  await registerTrack({
    state,
    track: {
      type: "audio",
      codec: format,
      codecPrivate: null,
      description: undefined,
      codecWithoutConfig: format,
      numberOfChannels,
      sampleRate,
      timescale: 1e6,
      trackId: 0,
      trakBox: null
    },
    container: "wav"
  });
  box.expectNoMoreBytes();
  return Promise.resolve(null);
};

// src/containers/wav/parse-header.ts
var parseHeader = ({
  state
}) => {
  const fileSize = state.iterator.getUint32Le();
  const fileType = state.iterator.getByteString(4, false);
  if (fileType !== "WAVE") {
    throw new Error(`Expected WAVE, got ${fileType}`);
  }
  const header = {
    type: "wav-header",
    fileSize
  };
  state.getWavStructure().boxes.push(header);
  return Promise.resolve(null);
};

// src/containers/wav/parse-id3.ts
var parseId32 = ({
  state
}) => {
  const { iterator } = state;
  const id3Size = iterator.getUint32Le();
  iterator.discard(id3Size);
  const id3Box = {
    type: "wav-id3"
  };
  state.getWavStructure().boxes.push(id3Box);
  return Promise.resolve(null);
};

// src/containers/wav/parse-list.ts
var parseList = ({
  state
}) => {
  const { iterator } = state;
  const ckSize = iterator.getUint32Le();
  const box = iterator.startBox(ckSize);
  const startOffset = iterator.counter.getOffset();
  const type = iterator.getByteString(4, false);
  if (type !== "INFO") {
    throw new Error(`Only supporting LIST INFO, but got ${type}`);
  }
  const metadata = [];
  while (iterator.counter.getOffset() < startOffset + ckSize) {
    const key = iterator.getByteString(4, false);
    const size = iterator.getUint32Le();
    const value = iterator.getByteString(size, true);
    metadata.push({
      key,
      trackId: null,
      value
    });
  }
  const wavList = {
    type: "wav-list",
    metadata
  };
  state.getWavStructure().boxes.push(wavList);
  box.expectNoMoreBytes();
  return Promise.resolve(null);
};

// src/containers/wav/parse-video-section.ts
var parseVideoSection2 = async ({
  state
}) => {
  const { iterator } = state;
  const structure = state.getWavStructure();
  const videoSection = state.videoSection.getVideoSection();
  const maxOffset = videoSection.start + videoSection.size;
  const maxRead = maxOffset - iterator.counter.getOffset();
  const offset = iterator.counter.getOffset();
  const fmtBox = structure.boxes.find((box) => box.type === "wav-fmt");
  if (!fmtBox) {
    throw new Error("Expected fmt box");
  }
  const secondsToRead = 1;
  const toRead = Math.min(maxRead, fmtBox.sampleRate * fmtBox.blockAlign * secondsToRead);
  const duration2 = toRead / (fmtBox.sampleRate * fmtBox.blockAlign);
  const timestamp = (offset - videoSection.start) / (fmtBox.sampleRate * fmtBox.blockAlign);
  const data = iterator.getSlice(toRead);
  await state.callbacks.onAudioSample(0, convertAudioOrVideoSampleToWebCodecsTimestamps({
    cts: timestamp,
    dts: timestamp,
    data,
    duration: duration2,
    timestamp,
    trackId: 0,
    type: "key",
    offset,
    timescale: 1e6
  }, 1));
  return null;
};

// src/containers/wav/parse-wav.ts
var parseWav = (state) => {
  const { iterator } = state;
  const insideVideoSection = state.videoSection.isInVideoSectionState(iterator);
  if (insideVideoSection === "in-section") {
    return parseVideoSection2({ state });
  }
  const type = iterator.getByteString(4, false);
  Log.trace(state.logLevel, `Processing box type ${type}`);
  if (type === "RIFF") {
    return parseHeader({ state });
  }
  if (type === "fmt") {
    return parseFmt({ state });
  }
  if (type === "data") {
    return parseData({ state });
  }
  if (type === "LIST") {
    return parseList({ state });
  }
  if (type === "id3") {
    return parseId32({ state });
  }
  throw new Error(`Unknown WAV box type ${type}`);
};

// src/containers/webm/segments.ts
var expectSegment = async ({
  state,
  isInsideSegment
}) => {
  const { iterator } = state;
  if (iterator.bytesRemaining() === 0) {
    throw new Error("has no bytes");
  }
  const offset = iterator.counter.getOffset();
  const { returnToCheckpoint } = iterator.startCheckpoint();
  const segmentId = iterator.getMatroskaSegmentId();
  if (segmentId === null) {
    returnToCheckpoint();
    return null;
  }
  const offsetBeforeVInt = iterator.counter.getOffset();
  const size = iterator.getVint();
  const offsetAfterVInt = iterator.counter.getOffset();
  if (size === null) {
    returnToCheckpoint();
    return null;
  }
  const bytesRemainingNow = iterator.bytesRemaining();
  Log.trace(state.logLevel, "Segment ID:", ebmlMap[segmentId]?.name, "Size:" + size, bytesRemainingNow);
  if (segmentId === matroskaElements.Segment) {
    state.webm.addSegment({
      start: offset,
      size
    });
    const newSegment = {
      type: "Segment",
      minVintWidth: offsetAfterVInt - offsetBeforeVInt,
      value: []
    };
    return newSegment;
  }
  if (segmentId === matroskaElements.Cluster) {
    if (isInsideSegment === null) {
      throw new Error("Expected to be inside segment");
    }
    state.webm.addCluster({
      start: offset,
      size,
      segment: isInsideSegment.index
    });
    const newSegment = {
      type: "Cluster",
      minVintWidth: offsetAfterVInt - offsetBeforeVInt,
      value: []
    };
    return newSegment;
  }
  if (bytesRemainingNow < size) {
    returnToCheckpoint();
    return null;
  }
  const segment = await parseSegment({
    segmentId,
    length: size,
    state,
    headerReadSoFar: iterator.counter.getOffset() - offset
  });
  return segment;
};
var parseSegment = async ({
  segmentId,
  length,
  state,
  headerReadSoFar
}) => {
  if (length < 0) {
    throw new Error(`Expected length of ${segmentId} to be greater or equal 0`);
  }
  state.iterator.counter.decrement(headerReadSoFar);
  const offset = state.iterator.counter.getOffset();
  const ebml = await parseEbml(state);
  const remapped = await postprocessEbml({ offset, ebml, state });
  return remapped;
};

// src/containers/webm/parse-webm-header.ts
var parseWebm = async (state) => {
  const structure = state.getMatroskaStructure();
  const { iterator } = state;
  const isInsideSegment = state.webm.isInsideSegment(iterator);
  const isInsideCluster = state.webm.isInsideCluster(iterator);
  const results = await expectSegment({
    state,
    isInsideSegment
  });
  if (results === null) {
    return null;
  }
  if (isInsideCluster) {
    const segments = structure.boxes.filter((box) => box.type === "Segment");
    const segment = segments[isInsideCluster.segment];
    if (!segment) {
      throw new Error("Expected segment");
    }
    const clusters = segment.value.find((box) => box.type === "Cluster");
    if (!clusters) {
      throw new Error("Expected cluster");
    }
    if (results.type !== "Block" && results.type !== "SimpleBlock") {
      clusters.value.push(results);
    }
  } else if (isInsideSegment) {
    const segments = structure.boxes.filter((box) => box.type === "Segment");
    const segment = segments[isInsideSegment.index];
    if (!segment) {
      throw new Error("Expected segment");
    }
    segment.value.push(results);
  } else {
    structure.boxes.push(results);
  }
  return null;
};

// src/init-video.ts
var initVideo = ({
  state,
  mimeType,
  name,
  contentLength
}) => {
  const fileType = state.iterator.detectFileType();
  if (fileType.type === "riff") {
    Log.verbose(state.logLevel, "Detected RIFF container");
    state.setStructure({
      type: "riff",
      boxes: []
    });
    return;
  }
  if (fileType.type === "iso-base-media") {
    Log.verbose(state.logLevel, "Detected ISO Base Media container");
    state.setStructure({
      type: "iso-base-media",
      boxes: []
    });
    return;
  }
  if (fileType.type === "webm") {
    Log.verbose(state.logLevel, "Detected Matroska container");
    state.setStructure({
      boxes: [],
      type: "matroska"
    });
    return;
  }
  if (fileType.type === "transport-stream") {
    Log.verbose(state.logLevel, "Detected MPEG-2 Transport Stream");
    state.setStructure({
      boxes: [],
      type: "transport-stream"
    });
    return;
  }
  if (fileType.type === "mp3") {
    Log.verbose(state.logLevel, "Detected MP3");
    const structure = {
      boxes: [],
      type: "mp3"
    };
    state.setStructure(structure);
    return;
  }
  if (fileType.type === "wav") {
    Log.verbose(state.logLevel, "Detected WAV");
    const structure = {
      boxes: [],
      type: "wav"
    };
    state.setStructure(structure);
    return;
  }
  if (fileType.type === "flac") {
    Log.verbose(state.logLevel, "Detected FLAC");
    const structure = {
      boxes: [],
      type: "flac"
    };
    state.setStructure(structure);
    return;
  }
  if (fileType.type === "aac") {
    Log.verbose(state.logLevel, "Detected AAC");
    state.setStructure({
      type: "aac",
      boxes: []
    });
    return;
  }
  if (fileType.type === "gif") {
    return Promise.reject(new IsAGifError({
      message: "GIF files are not yet supported",
      mimeType,
      sizeInBytes: contentLength,
      fileName: name
    }));
  }
  if (fileType.type === "pdf") {
    return Promise.reject(new IsAPdfError({
      message: "GIF files are not supported",
      mimeType,
      sizeInBytes: contentLength,
      fileName: name
    }));
  }
  if (fileType.type === "bmp" || fileType.type === "jpeg" || fileType.type === "png" || fileType.type === "webp") {
    return Promise.reject(new IsAnImageError({
      message: "Image files are not supported",
      imageType: fileType.type,
      dimensions: fileType.dimensions,
      mimeType,
      sizeInBytes: contentLength,
      fileName: name
    }));
  }
  if (fileType.type === "unknown") {
    return Promise.reject(new IsAnUnsupportedFileTypeError({
      message: "Unknown file format",
      mimeType,
      sizeInBytes: contentLength,
      fileName: name
    }));
  }
  return Promise.reject(new Error("Unknown video format " + fileType));
};

// src/run-parse-iteration.ts
var runParseIteration = async ({
  state,
  mimeType,
  contentLength,
  name
}) => {
  if (state.iterator.bytesRemaining() === 0) {
    return Promise.reject(new Error("no bytes"));
  }
  const structure = state.getStructureOrNull();
  if (structure === null) {
    await initVideo({ state, mimeType, name, contentLength });
    return null;
  }
  if (structure.type === "riff") {
    return parseRiff(state);
  }
  if (structure.type === "mp3") {
    return parseMp3(state);
  }
  if (structure.type === "iso-base-media") {
    return parseIsoBaseMedia(state);
  }
  if (structure.type === "matroska") {
    return parseWebm(state);
  }
  if (structure.type === "transport-stream") {
    return parseTransportStream(state);
  }
  if (structure.type === "wav") {
    return parseWav(state);
  }
  if (structure.type === "aac") {
    return parseAac(state);
  }
  if (structure.type === "flac") {
    return parseFlac({ state, iterator: state.iterator });
  }
  return Promise.reject(new Error("Unknown video format " + structure));
};

// src/throttled-progress.ts
var throttledStateUpdate = ({
  updateFn,
  everyMilliseconds,
  controller
}) => {
  let currentState = {
    bytes: 0,
    percentage: null,
    totalBytes: null
  };
  if (!updateFn) {
    return {
      get: () => currentState,
      update: null,
      stopAndGetLastProgress: () => {
      }
    };
  }
  let lastUpdated = null;
  const callUpdateIfChanged = () => {
    if (currentState === lastUpdated) {
      return;
    }
    updateFn(currentState);
    lastUpdated = currentState;
  };
  const interval = setInterval(() => {
    callUpdateIfChanged();
  }, everyMilliseconds);
  const onAbort = () => {
    clearInterval(interval);
  };
  controller._internals.signal.addEventListener("abort", onAbort, { once: true });
  return {
    get: () => currentState,
    update: (fn) => {
      currentState = fn(currentState);
    },
    stopAndGetLastProgress: () => {
      clearInterval(interval);
      controller._internals.signal.removeEventListener("abort", onAbort);
      return currentState;
    }
  };
};

// src/internal-parse-media.ts
var internalParseMedia = async function({
  src,
  fields: _fieldsInReturnValue,
  reader: readerInterface,
  onAudioTrack,
  onVideoTrack,
  controller = mediaParserController(),
  logLevel,
  onParseProgress: onParseProgressDoNotCallDirectly,
  progressIntervalInMs,
  mode,
  onDiscardedData,
  onError,
  acknowledgeRemotionLicense,
  apiName,
  ...more
}) {
  warnIfRemotionLicenseNotAcknowledged({
    acknowledgeRemotionLicense,
    logLevel,
    apiName
  });
  const fieldsInReturnValue = _fieldsInReturnValue ?? {};
  const fields = getFieldsFromCallback({
    fields: fieldsInReturnValue,
    callbacks: more
  });
  const {
    reader: readerInstance,
    contentLength,
    name,
    contentType,
    supportsContentRange
  } = await readerInterface.read({ src, range: null, controller });
  if (contentLength === null) {
    throw new Error('Cannot read media without a content length. This is currently not supported. Ensure the media has a "Content-Length" HTTP header.');
  }
  if (!supportsContentRange) {
    throw new Error('Cannot read media without it supporting the "Content-Range" header. This is currently not supported. Ensure the media supports the "Content-Range" HTTP header.');
  }
  const hasAudioTrackHandlers = Boolean(onAudioTrack);
  const hasVideoTrackHandlers = Boolean(onVideoTrack);
  if (!hasAudioTrackHandlers && !hasVideoTrackHandlers && Object.values(fields).every((v) => !v) && mode === "query") {
    Log.warn(logLevel, new Error("Warning - No `fields` and no `on*` callbacks were passed to `parseMedia()`. Specify the data you would like to retrieve."));
  }
  let timeIterating = 0;
  let timeReadingData = 0;
  let timeSeeking = 0;
  let timeCheckingIfDone = 0;
  let timeFreeingData = 0;
  let errored = null;
  const state = makeParserState({
    hasAudioTrackHandlers,
    hasVideoTrackHandlers,
    controller,
    fields,
    onAudioTrack: onAudioTrack ?? null,
    onVideoTrack: onVideoTrack ?? null,
    contentLength,
    logLevel,
    mode,
    readerInterface,
    src,
    onDiscardedData
  });
  const { iterator } = state;
  let currentReader = readerInstance;
  const returnValue = {};
  const moreFields = more;
  const throttledState = throttledStateUpdate({
    updateFn: onParseProgressDoNotCallDirectly ?? null,
    everyMilliseconds: progressIntervalInMs ?? 100,
    controller,
    totalBytes: contentLength
  });
  const triggerInfoEmit = async () => {
    const availableInfo = getAvailableInfo({
      fieldsToFetch: fields,
      state
    });
    await emitAvailableInfo({
      hasInfo: availableInfo,
      callbacks: moreFields,
      fieldsInReturnValue,
      state,
      returnValue,
      name,
      mimeType: contentType
    });
  };
  const checkIfDone = async () => {
    const startCheck = Date.now();
    const hasAll = hasAllInfo({
      fields,
      state
    });
    timeCheckingIfDone += Date.now() - startCheck;
    if (hasAll && mode === "query") {
      Log.verbose(logLevel, "Got all info, skipping to the end.");
      state.increaseSkippedBytes(contentLength - state.iterator.counter.getOffset());
      return true;
    }
    if (state.iterator.counter.getOffset() === contentLength) {
      Log.verbose(logLevel, "Reached end of file");
      await state.discardReadBytes(true);
      return true;
    }
    if (state.iterator.counter.getOffset() + state.iterator.bytesRemaining() === contentLength && errored) {
      Log.verbose(logLevel, "Reached end of file and errorred");
      return true;
    }
    return false;
  };
  await triggerInfoEmit();
  let iterationWithThisOffset = 0;
  while (!await checkIfDone()) {
    await controller._internals.checkForAbortAndPause();
    const offsetBefore = iterator.counter.getOffset();
    const fetchMoreData = async () => {
      await controller._internals.checkForAbortAndPause();
      const result = await currentReader.reader.read();
      if (result.value) {
        iterator.addData(result.value);
      }
      return result.done;
    };
    const readStart = Date.now();
    while (iterator.bytesRemaining() < 0) {
      const done = await fetchMoreData();
      if (done) {
        break;
      }
    }
    const hasBigBuffer = iterator.bytesRemaining() > 1e5;
    if (iterationWithThisOffset > 0 || !hasBigBuffer) {
      await fetchMoreData();
    }
    await state.eventLoop.eventLoopBreakIfNeeded();
    timeReadingData += Date.now() - readStart;
    throttledState.update?.(() => ({
      bytes: iterator.counter.getOffset(),
      percentage: contentLength ? iterator.counter.getOffset() / contentLength : null,
      totalBytes: contentLength
    }));
    if (!errored) {
      Log.trace(logLevel, `Continuing parsing of file, currently at position ${iterator.counter.getOffset()}/${contentLength} (0x${iterator.counter.getOffset().toString(16)})`);
      if (iterationWithThisOffset > 300) {
        throw new Error("Infinite loop detected. The parser is not progressing. This is likely a bug in the parser. You can report this at https://remotion.dev/report and we will fix it as soon as possible.");
      }
      try {
        await triggerInfoEmit();
        const start = Date.now();
        await controller._internals.checkForAbortAndPause();
        const skip = await runParseIteration({
          state,
          mimeType: contentType,
          contentLength,
          name
        });
        timeIterating += Date.now() - start;
        if (skip !== null) {
          state.increaseSkippedBytes(skip.skipTo - iterator.counter.getOffset());
          if (skip.skipTo === contentLength) {
            Log.verbose(logLevel, "Skipped to end of file, not fetching.");
            break;
          }
          const seekStart = Date.now();
          currentReader = await performSeek({
            seekTo: skip.skipTo,
            currentReader,
            readerInterface,
            src,
            state
          });
          timeSeeking += Date.now() - seekStart;
        }
      } catch (e) {
        const err = await onError(e);
        if (!err.action) {
          throw new Error('onError was used but did not return an "action" field. See docs for this API on how to use onError.');
        }
        if (err.action === "fail") {
          throw e;
        }
        if (err.action === "download") {
          errored = e;
          Log.verbose(logLevel, "Error was handled by onError and deciding to continue.");
        }
      }
      const didProgress = iterator.counter.getOffset() > offsetBefore;
      if (!didProgress) {
        iterationWithThisOffset++;
      } else {
        iterationWithThisOffset = 0;
      }
    }
    const timeFreeStart = Date.now();
    await state.discardReadBytes(false);
    timeFreeingData += Date.now() - timeFreeStart;
  }
  Log.verbose(logLevel, "Finished parsing file");
  await emitAvailableInfo({
    hasInfo: Object.keys(fields).reduce((acc, key) => {
      if (fields?.[key]) {
        acc[key] = true;
      }
      return acc;
    }, {}),
    callbacks: moreFields,
    fieldsInReturnValue,
    state,
    returnValue,
    mimeType: contentType,
    name
  });
  Log.verbose(logLevel, `Time iterating over file: ${timeIterating}ms`);
  Log.verbose(logLevel, `Time fetching data: ${timeReadingData}ms`);
  Log.verbose(logLevel, `Time seeking: ${timeSeeking}ms`);
  Log.verbose(logLevel, `Time checking if done: ${timeCheckingIfDone}ms`);
  Log.verbose(logLevel, `Time freeing data: ${timeFreeingData}ms`);
  currentReader.abort();
  iterator?.destroy();
  state.callbacks.tracks.ensureHasTracksAtEnd(fields);
  if (errored) {
    throw errored;
  }
  return returnValue;
};
// src/download-and-parse-media.ts
var downloadAndParseMedia = async (options) => {
  const logLevel = options.logLevel ?? "info";
  const content = await options.writer.createContent({
    filename: "hmm",
    mimeType: "shouldnotmatter",
    logLevel
  });
  const returnValue = await internalParseMedia({
    fields: options.fields ?? null,
    logLevel,
    mode: "download",
    onAudioCodec: options.onAudioCodec ?? null,
    onAudioTrack: null,
    onContainer: options.onContainer ?? null,
    onDimensions: options.onDimensions ?? null,
    onDiscardedData: async (data) => {
      await content.write(data);
    },
    onDurationInSeconds: options.onDurationInSeconds ?? null,
    onFps: options.onFps ?? null,
    onImages: options.onImages ?? null,
    onInternalStats: options.onInternalStats ?? null,
    onIsHdr: options.onIsHdr ?? null,
    onKeyframes: options.onKeyframes ?? null,
    onLocation: options.onLocation ?? null,
    onMetadata: options.onMetadata ?? null,
    onMimeType: options.onMimeType ?? null,
    onName: options.onName ?? null,
    onNumberOfAudioChannels: options.onNumberOfAudioChannels ?? null,
    onParseProgress: options.onParseProgress ?? null,
    onRotation: options.onRotation ?? null,
    onSampleRate: options.onSampleRate ?? null,
    onSize: options.onSize ?? null,
    onSlowAudioBitrate: options.onSlowAudioBitrate ?? null,
    onSlowDurationInSeconds: options.onSlowDurationInSeconds ?? null,
    onSlowFps: options.onSlowFps ?? null,
    onSlowKeyframes: options.onSlowKeyframes ?? null,
    onSlowNumberOfFrames: options.onSlowNumberOfFrames ?? null,
    onSlowVideoBitrate: options.onSlowVideoBitrate ?? null,
    onStructure: options.onStructure ?? null,
    onTracks: options.onTracks ?? null,
    onUnrotatedDimensions: options.onUnrotatedDimensions ?? null,
    onVideoCodec: options.onVideoCodec ?? null,
    onVideoTrack: null,
    progressIntervalInMs: options.progressIntervalInMs ?? null,
    reader: options.reader ?? fetchReader,
    controller: options.controller ?? undefined,
    src: options.src,
    onError: async (err) => {
      const action = await options.onError?.(err) ?? { action: "fail" };
      if (action.action === "fail") {
        Log.verbose(logLevel, "Removing content");
        await content.finish();
        await content.remove();
      }
      return action;
    },
    acknowledgeRemotionLicense: Boolean(options.acknowledgeRemotionLicense),
    apiName: "parseAndDownloadMedia()"
  });
  await content.finish();
  return returnValue;
};
// src/parse-media.ts
var parseMedia = (options) => {
  return internalParseMedia({
    fields: options.fields ?? null,
    logLevel: options.logLevel ?? "info",
    onAudioCodec: options.onAudioCodec ?? null,
    onAudioTrack: options.onAudioTrack ?? null,
    onContainer: options.onContainer ?? null,
    onDimensions: options.onDimensions ?? null,
    onDurationInSeconds: options.onDurationInSeconds ?? null,
    onFps: options.onFps ?? null,
    onImages: options.onImages ?? null,
    onInternalStats: options.onInternalStats ?? null,
    onIsHdr: options.onIsHdr ?? null,
    onKeyframes: options.onKeyframes ?? null,
    onLocation: options.onLocation ?? null,
    onMetadata: options.onMetadata ?? null,
    onMimeType: options.onMimeType ?? null,
    onName: options.onName ?? null,
    onNumberOfAudioChannels: options.onNumberOfAudioChannels ?? null,
    onParseProgress: options.onParseProgress ?? null,
    onRotation: options.onRotation ?? null,
    onSampleRate: options.onSampleRate ?? null,
    onSize: options.onSize ?? null,
    onSlowAudioBitrate: options.onSlowAudioBitrate ?? null,
    onSlowDurationInSeconds: options.onSlowDurationInSeconds ?? null,
    onSlowFps: options.onSlowFps ?? null,
    onSlowKeyframes: options.onSlowKeyframes ?? null,
    onSlowNumberOfFrames: options.onSlowNumberOfFrames ?? null,
    onSlowVideoBitrate: options.onSlowVideoBitrate ?? null,
    onStructure: options.onStructure ?? null,
    onTracks: options.onTracks ?? null,
    onUnrotatedDimensions: options.onUnrotatedDimensions ?? null,
    onVideoCodec: options.onVideoCodec ?? null,
    onVideoTrack: options.onVideoTrack ?? null,
    progressIntervalInMs: options.progressIntervalInMs ?? null,
    reader: options.reader ?? fetchReader,
    controller: options.controller ?? undefined,
    src: options.src,
    mode: "query",
    onDiscardedData: null,
    onError: () => ({ action: "fail" }),
    acknowledgeRemotionLicense: Boolean(options.acknowledgeRemotionLicense),
    apiName: "parseMedia()"
  });
};
// src/version.ts
var VERSION = "4.0.264";

// src/index.ts
var MediaParserInternals = {
  Log,
  createAacCodecPrivate,
  matroskaElements,
  ebmlMap,
  parseTkhd,
  getArrayBufferIterator,
  parseStsd,
  makeParserState,
  processSample: processIsoFormatBox,
  parseFtyp,
  parseEbml,
  parseMvhd,
  internalParseMedia
};
export {
  parseMedia,
  mediaParserController,
  hasBeenAborted,
  downloadAndParseMedia,
  VERSION,
  MediaParserInternals,
  MediaParserAbortError,
  IsAnUnsupportedFileTypeError,
  IsAnUnsupportedAudioTypeError,
  IsAnImageError,
  IsAPdfError,
  IsAGifError
};
