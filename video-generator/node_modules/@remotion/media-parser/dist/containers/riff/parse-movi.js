"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.parseMovi = exports.handleChunk = void 0;
const convert_audio_or_video_sample_1 = require("../../convert-audio-or-video-sample");
const key_1 = require("../avc/key");
const parse_avc_1 = require("../avc/parse-avc");
const traversal_1 = require("./traversal");
const getStrhForIndex = (structure, trackId) => {
    const boxes = (0, traversal_1.getStrlBoxes)(structure);
    const box = boxes[trackId];
    if (!box) {
        throw new Error('Expected box');
    }
    const strh = (0, traversal_1.getStrhBox)(box.children);
    if (!strh) {
        throw new Error('strh');
    }
    return strh;
};
const handleChunk = async ({ state, ckId, ckSize, }) => {
    const { iterator } = state;
    const offset = iterator.counter.getOffset();
    const videoChunk = ckId.match(/^([0-9]{2})dc$/);
    if (videoChunk) {
        const trackId = parseInt(videoChunk[1], 10);
        const strh = getStrhForIndex(state.getRiffStructure(), trackId);
        const samplesPerSecond = strh.rate / strh.scale;
        const nthSample = state.callbacks.getSamplesForTrack(trackId);
        const timeInSec = nthSample / samplesPerSecond;
        const timestamp = timeInSec;
        const data = iterator.getSlice(ckSize);
        const infos = (0, parse_avc_1.parseAvc)(data);
        const keyOrDelta = (0, key_1.getKeyFrameOrDeltaFromAvcInfo)(infos);
        const avcProfile = infos.find((i) => i.type === 'avc-profile');
        const ppsProfile = infos.find((i) => i.type === 'avc-pps');
        if (avcProfile && ppsProfile && !state.riff.getAvcProfile()) {
            await state.riff.onProfile({ pps: ppsProfile, sps: avcProfile });
            state.callbacks.tracks.setIsDone(state.logLevel);
        }
        // We must also NOT pass a duration because if the the next sample is 0,
        // this sample would be longer. Chrome will pad it with silence.
        // If we'd pass a duration instead, it would shift the audio and we think that audio is not finished
        await state.callbacks.onVideoSample(trackId, (0, convert_audio_or_video_sample_1.convertAudioOrVideoSampleToWebCodecsTimestamps)({
            cts: timestamp,
            dts: timestamp,
            data,
            duration: undefined,
            timestamp,
            trackId,
            type: keyOrDelta,
            offset,
            timescale: samplesPerSecond,
        }, 1));
        return;
    }
    const audioChunk = ckId.match(/^([0-9]{2})wb$/);
    if (audioChunk) {
        const trackId = parseInt(audioChunk[1], 10);
        const strh = getStrhForIndex(state.getRiffStructure(), trackId);
        const samplesPerSecond = strh.rate / strh.scale;
        const nthSample = state.callbacks.getSamplesForTrack(trackId);
        const timeInSec = nthSample / samplesPerSecond;
        const timestamp = timeInSec;
        const data = iterator.getSlice(ckSize);
        // In example.avi, we have samples with 0 data
        // Chrome fails on these
        // We must also NOT pass a duration because if the the next sample is 0,
        // this sample would be longer. Chrome will pad it with silence.
        // If we'd pass a duration instead, it would shift the audio and we think that audio is not finished
        await state.callbacks.onAudioSample(trackId, (0, convert_audio_or_video_sample_1.convertAudioOrVideoSampleToWebCodecsTimestamps)({
            cts: timestamp,
            dts: timestamp,
            data,
            duration: undefined,
            timestamp,
            trackId,
            type: 'key',
            offset,
            timescale: samplesPerSecond,
        }, 1));
    }
};
exports.handleChunk = handleChunk;
const parseMovi = async ({ state, }) => {
    const { iterator } = state;
    if (iterator.bytesRemaining() < 8) {
        return Promise.resolve();
    }
    const checkpoint = iterator.startCheckpoint();
    const ckId = iterator.getByteString(4, false);
    const ckSize = iterator.getUint32Le();
    if (iterator.bytesRemaining() < ckSize) {
        checkpoint.returnToCheckpoint();
        return Promise.resolve();
    }
    await (0, exports.handleChunk)({ state, ckId, ckSize });
    const videoSection = state.videoSection.getVideoSection();
    const maxOffset = videoSection.start + videoSection.size;
    // Discard added zeroes
    while (iterator.counter.getOffset() < maxOffset &&
        iterator.bytesRemaining() > 0) {
        if (iterator.getUint8() !== 0) {
            iterator.counter.decrement(1);
            break;
        }
    }
};
exports.parseMovi = parseMovi;
