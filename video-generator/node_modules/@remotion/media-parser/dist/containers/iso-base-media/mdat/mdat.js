"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.parseMdatSection = void 0;
const convert_audio_or_video_sample_1 = require("../../../convert-audio-or-video-sample");
const get_tracks_1 = require("../../../get-tracks");
const skip_1 = require("../../../skip");
const cached_sample_positions_1 = require("../../../state/iso-base-media/cached-sample-positions");
const may_skip_video_data_1 = require("../../../state/may-skip-video-data");
const get_moov_atom_1 = require("../get-moov-atom");
const parseMdatSection = async (state) => {
    const videoSection = state.videoSection.getVideoSection();
    const endOfMdat = videoSection.size + videoSection.start;
    // don't need mdat at all, can skip
    if ((0, may_skip_video_data_1.maySkipVideoData)({ state })) {
        return (0, skip_1.makeSkip)(endOfMdat);
    }
    const alreadyHas = (0, get_tracks_1.getHasTracks)(state);
    if (!alreadyHas) {
        const moov = await (0, get_moov_atom_1.getMoovAtom)({
            endOfMdat,
            state,
        });
        state.iso.moov.setMoovBox(moov);
        state.callbacks.tracks.setIsDone(state.logLevel);
        state.getIsoStructure().boxes.push(moov);
        return (0, exports.parseMdatSection)(state);
    }
    if (!state.iso.flatSamples.getSamples(videoSection.start)) {
        state.iso.flatSamples.setSamples(videoSection.start, (0, cached_sample_positions_1.calculateFlatSamples)(state));
    }
    const flatSamples = state.iso.flatSamples.getSamples(videoSection.start);
    const { iterator } = state;
    const samplesWithIndex = flatSamples.find((sample) => {
        return sample.samplePosition.offset === iterator.counter.getOffset();
    });
    if (!samplesWithIndex) {
        // There are various reasons why in mdat we find weird stuff:
        // - iphonevideo.hevc has a fake hoov atom which is not mapped
        // - corrupted.mp4 has a corrupt table
        const nextSample_ = flatSamples
            .filter((s) => s.samplePosition.offset > iterator.counter.getOffset())
            .sort((a, b) => a.samplePosition.offset - b.samplePosition.offset)[0];
        if (nextSample_) {
            iterator.discard(nextSample_.samplePosition.offset - iterator.counter.getOffset());
            return null;
        }
        // guess we reached the end!
        // iphonevideo.mov has extra padding here, so let's make sure to jump ahead
        return (0, skip_1.makeSkip)(endOfMdat);
    }
    if (iterator.bytesRemaining() < samplesWithIndex.samplePosition.size) {
        return null;
    }
    const bytes = iterator.getSlice(samplesWithIndex.samplePosition.size);
    const { cts, dts, duration, isKeyframe, offset } = samplesWithIndex.samplePosition;
    if (samplesWithIndex.track.type === 'audio') {
        await state.callbacks.onAudioSample(samplesWithIndex.track.trackId, (0, convert_audio_or_video_sample_1.convertAudioOrVideoSampleToWebCodecsTimestamps)({
            data: bytes,
            timestamp: cts,
            duration,
            cts,
            dts,
            trackId: samplesWithIndex.track.trackId,
            type: isKeyframe ? 'key' : 'delta',
            offset,
            timescale: samplesWithIndex.track.timescale,
        }, samplesWithIndex.track.timescale));
    }
    if (samplesWithIndex.track.type === 'video') {
        // https://remotion-assets.s3.eu-central-1.amazonaws.com/example-videos/sei_checkpoint.mp4
        // Position in file 0x0001aba615
        // https://github.com/remotion-dev/remotion/issues/4680
        // In Chrome, we may not treat recovery points as keyframes
        // otherwise "a keyframe is required after flushing"
        const nalUnitType = bytes[4] & 0b00011111;
        let isRecoveryPoint = false;
        // SEI (Supplemental enhancement information)
        if (nalUnitType === 6) {
            const seiType = bytes[5];
            isRecoveryPoint = seiType === 6;
        }
        await state.callbacks.onVideoSample(samplesWithIndex.track.trackId, (0, convert_audio_or_video_sample_1.convertAudioOrVideoSampleToWebCodecsTimestamps)({
            data: bytes,
            timestamp: cts,
            duration,
            cts,
            dts,
            trackId: samplesWithIndex.track.trackId,
            type: isKeyframe && !isRecoveryPoint ? 'key' : 'delta',
            offset,
            timescale: samplesWithIndex.track.timescale,
        }, samplesWithIndex.track.timescale));
    }
    return null;
};
exports.parseMdatSection = parseMdatSection;
